- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Preparing Our First Vulnerable Cloud Lab Environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In *[Chapter 1](B19755_01.xhtml)*, *Getting Started with Penetration Testing
    Labs in the Cloud*, we discussed several key topics that are essential to building
    intentionally vulnerable lab environments in the cloud. At this point, you are
    probably eager to get your feet wet and very excited to start working on some
    hands-on exercises. The good news is that we won’t have to wait much longer since
    we will be working on our first penetration testing cloud lab environment in this
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: We will start the hands-on section of this chapter by creating an empty Amazon
    **Simple Storage Service** (**S3**) bucket and configuring it for static website
    hosting. We will then make the bucket misconfigured by modifying its access control
    settings accordingly. We will complete the setup by uploading a few sample files
    into our S3 bucket and make the setup a bit more realistic. Of course, setting
    up the vulnerable cloud lab environment is just the first part! The second part
    involves testing the security configuration of our lab environment by simulating
    the attack process from an attacker’s point of view. Once we are done with the
    tests, we will proceed with the cleanup step by deleting the bucket, along with
    the files stored inside it.
  prefs: []
  type: TYPE_NORMAL
- en: 'That said, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Designing our first cloud penetration testing lab environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preparing our first vulnerable environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing and hacking our first vulnerable environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cleaning up
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While working on the hands-on solutions of this chapter, we will cover relevant
    security concepts and mechanisms that can be used to manage access control in
    S3 buckets. Having a good understanding of how these security mechanisms work
    will help you prepare different variations of misconfigured S3 buckets that can
    be part of more complex penetration testing lab environments.
  prefs: []
  type: TYPE_NORMAL
- en: With this in mind, let’s get started!
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we start, we must have the following ready:'
  prefs: []
  type: TYPE_NORMAL
- en: An AWS account, which will serve as the *target account* that contains the vulnerable
    environment and resources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A second AWS account, which will serve as the *attacker’s account*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feel free to create these AWS accounts by going to [https://aws.amazon.com/free/](https://aws.amazon.com/free/).
    You may proceed with the next steps once these accounts are ready.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: This chapter primarily focuses on building a sample vulnerable lab environment
    on AWS. Of course, we need to have our **Microsoft Azure** and **Google Cloud
    Platform** (**GCP**) accounts ready once we reach the hands-on portion of the
    succeeding chapters of this book. In the meantime, setting up two AWS accounts
    should do the trick for now.
  prefs: []
  type: TYPE_NORMAL
- en: Designing our first cloud penetration testing lab environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In *[Chapter 1](B19755_01.xhtml)*, *Getting Started with Penetration Testing
    Labs in the Cloud*, we discussed how modern cloud applications are designed, developed,
    and deployed. We took a closer look at how distributed multi-tier architectures
    and horizontal scaling strategies make it possible to independently scale specific
    tiers to handle increased user traffic:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image/B19755_02_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1 – Generic multi-tiered architecture diagram from Chapter 1
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we have designed the system to have separate tiers for the web servers,
    application servers, and databases. Given that this is one of the common cloud
    architecture implementations, you might be wondering, *how* *would this look like
    when implemented on a cloud platform such as AWS?* The answer to this question
    is simple! It would look more or less the same when implemented on AWS! For one
    thing, the resources in *Figure 2**.1* would simply have their own corresponding
    set of resources and services on AWS (similar to what is shown in *Figure 2**.2*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image/B19755_02_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.2 – How a distributed multi-tiered architecture can be implemented
    on AWS
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 2**.2*, we can see that the generic load balancer resource from *Figure
    2**.1* would be replaced with an **Amazon Elastic Load Balancing** (**ELB**) cloud
    resource. Similarly, the web servers would be replaced with several **Amazon Elastic
    Compute Cloud** (**EC2**) instances. The generic database server resource would
    then be replaced with a managed **Amazon Relational Database Service** (**RDS**)
    database resource.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, you might be wondering why we have an extra resource box (that
    is, a box that represents an Amazon S3 bucket) in *Figure 2**.2*! Well, even if
    Amazon EC2 instances have storage volumes attached to them, cloud engineers generally
    decouple the application architecture further by storing files and objects inside
    **Amazon S3** buckets and database records inside **Amazon RDS** database instances.
    This allows the application implementation deployed inside the fleet of EC2 instances
    (virtual machines) to be stateless (making auto-scaling easier to implement) since
    the *state* is stored inside the S3 buckets and the RDS database instances.
  prefs: []
  type: TYPE_NORMAL
- en: What’s Amazon S3?
  prefs: []
  type: TYPE_NORMAL
- en: '**Amazon S3** is an object storage service built to store and retrieve a variety
    of files. We can think of Amazon S3 as an online service where we can create *file
    storage containers* (also known as S3 buckets) that can store any number of files
    uploaded through the web interface, a CLI utility, an SDK, or the API. Of course,
    we can also download files from these buckets using a similar set of options.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Amazon S3 plays an important role in modern applications deployed on AWS. Many
    cloud applications and systems running on AWS make use of S3 buckets to store
    files of various file types and formats. This includes data engineering and machine
    learning systems, similar to what we have in *Figure 2**.3*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image/B19755_02_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.3 – Where machine learning and data engineering systems store data
  prefs: []
  type: TYPE_NORMAL
- en: Here, we have a machine learning engineering system that utilizes managed machine
    learning and data engineering services such as **Amazon SageMaker** (a managed
    machine learning service) and **Amazon Athena** (a serverless, interactive analytics
    service) to process data stored inside Amazon S3 buckets. *Where does the cloud
    data reside before and after the data processing operations?* In most cases, the
    data would be stored inside Amazon S3 buckets, especially when dealing with data
    engineering and machine learning engineering workloads. As we can see, Amazon
    S3 is one of the most used services on AWS. An application deployed on AWS would
    most likely store files inside an S3 bucket (or in multiple S3 buckets). Its versatility
    and scalability make it a go-to choice for storing various types of files and
    data in the cloud. When deploying an application on AWS, it is a common practice
    to leverage S3 buckets for efficient and secure file storage, whether it involves
    hosting static website assets, storing user-uploaded content, or even serving
    as a data lake for large-scale analytics.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, files stored in Amazon S3 may contain **personally identifiable
    information** (**PII**), along with other sensitive information that must be protected
    at all costs. This could involve details such as names, addresses, social security
    numbers, or financial information, which can pose a significant risk if accessed
    by unauthorized individuals. Safeguarding this information is essential to maintain
    privacy and comply with data protection regulations. It is important to note that
    S3 buckets can be attacked by malicious actors directly without them having to
    go through the load balancer and web application tiers in *Figure 2**.2*. This
    means that if the S3 bucket is misconfigured (for example, the sensitive files
    stored in the bucket are publicly accessible), the S3 files and data can be stolen
    by attackers no matter how secure the load balancer and web application tiers
    are.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the past couple of years, misconfigured S3 buckets have led to a significant
    number of data breaches that leaked millions of records containing PII, sensitive
    corporate information, and even credentials. Here are some of the highlights from
    the previous years:'
  prefs: []
  type: TYPE_NORMAL
- en: In 2017, a significant number of S3 buckets were found to be misconfigured,
    resulting in the exposure of sensitive information, including PII, credit reports,
    and even government and military data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In 2018, an IT firm exposed data from several Fortune 100 companies, leading
    to the exposure of various types of sensitive information and proprietary data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In 2019, a vendor for half the Fortune 100 companies inadvertently exposed a
    terabyte of backups, while a healthcare provider’s misconfigured S3 bucket exposed
    medical records and patient-doctor records.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In 2020, a consumer ratings and reviews website had a misconfigured S3 bucket
    that exposed senior citizens’ data, and a global technology company experienced
    an incident where unauthorized individuals broke into its unsecured AWS S3 silo.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In 2022, a misconfigured S3 bucket leaked around 3 TB (terabytes!) of sensitive
    airport data, which exposed the PII of the airline employees.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These incidents, along with other reported leaks during the past few years,
    highlighted the widespread nature of S3 bucket misconfigurations and the potential
    risks associated with them.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'For more information about this topic, feel free to check out the following
    link: [https://github.com/nagwww/s3-leaks](https://github.com/nagwww/s3-leaks).'
  prefs: []
  type: TYPE_NORMAL
- en: Why are attacks on S3 buckets so prevalent?
  prefs: []
  type: TYPE_NORMAL
- en: Cloud engineers and developers generally have a poor understanding of how the
    different access control mechanisms work together when securing S3 buckets. In
    addition to this, the complexity of managing access control policies and permissions
    within S3 buckets adds another layer of challenge. The multitude of options and
    settings available can overwhelm inexperienced users, increasing the likelihood
    of misconfigurations and accidental exposure of sensitive information. This can
    lead to misconfigured S3 buckets leaking and exposing private and sensitive information
    to unauthorized users.
  prefs: []
  type: TYPE_NORMAL
- en: 'That said, having a solid understanding of what security measures are available
    would help us secure files inside S3 buckets better. At the same time, this would
    allow us to design and build realistic penetration testing labs involving S3\.
    If you are wondering what security mechanisms are available to secure the files
    stored inside these S3 buckets, here’s a quick list:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Identity and Access Management (IAM) policies**: By configuring IAM policies,
    organizations can define granular permissions and access controls for users, groups,
    and roles within their AWS accounts. This allows for fine-grained control over
    who can perform actions on S3 buckets, such as read, write, or delete operations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bucket policies**: Bucket policies provide an additional layer of access
    control at the bucket level. With bucket policies, organizations can define rules
    and conditions that govern access to specific S3 buckets. This includes allowing
    or denying access based on various factors such as IP addresses, user agents,
    or specific AWS accounts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Access Control Lists (ACLs)**: ACLs offer another mechanism for managing
    access to S3 buckets and objects. ACLs allow organizations to specify permissions
    for individual objects within a bucket, providing more fine-grained control over
    file-level access. By setting appropriate ACLs, organizations can grant read or
    write access to specific users or groups while restricting access to others.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Virtual Private Cloud (VPC) endpoint policies**: VPC endpoint policies allow
    organizations to control access to S3 buckets from within their VPC environments.
    By defining endpoint policies, organizations can specify which VPCs or subnets
    can access specific S3 buckets. This helps prevent unauthorized access from outside
    the VPC and enhances the security of files stored in S3 buckets by limiting access
    to trusted network environments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AWS Organizations Service Control Policies (SCPs)**: SCPs are part of AWS
    Organizations and enable organizations to set fine-grained permissions across
    multiple AWS accounts. By defining SCPs, organizations can enforce centralized
    security policies that apply to all member accounts. This includes controlling
    access to S3 buckets and ensuring that consistent security measures are applied
    across the organization. By leveraging SCPs, organizations can strengthen the
    overall security posture of their S3 buckets, ensuring that files are protected
    uniformly across an enterprise.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: While new S3 buckets created after April 2023 have ACLs disabled by default
    during the bucket creation process, it is still possible to enable them through
    a configuration change while the S3 bucket is being configured and created. At
    the same time, S3 buckets with ACLs disabled can be modified and have ACLs enabled
    and restored after bucket creation. Despite this enforcement of secure defaults,
    a significant number of S3 buckets created before April 2023 continue to rely
    on ACLs, along with the other discussed S3 security mechanisms. Therefore, having
    a thorough comprehension of these security mechanisms is crucial for both setting
    up cloud-based penetration testing lab environments and ensuring the correct configuration
    of S3 security settings.
  prefs: []
  type: TYPE_NORMAL
- en: Even with the security mechanisms and guardrails available alongside the security
    upgrades released by the cloud platform, misconfigurations are still present in
    a significant number of existing S3 buckets. In addition to this, no matter how
    secure the other components of the cloud architecture are, a misconfigured S3
    bucket would still result in a data leak since the files stored in the S3 buckets
    can be accessed directly in a significant number of cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will focus on preparing a misconfigured S3 bucket in our
    AWS account. Before building our first cloud penetration testing lab environment
    (that is, a single misconfigured S3 bucket), we must have a good idea of what
    the most common S3 bucket misconfigurations are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Guest/anonymous users can perform operations on the objects stored in the
    bucket**: This misconfiguration enables attackers or unauthorized individuals
    to access and manipulate the files and folders stored in the bucket. Unauthorized
    users can list the contents of the bucket, retrieve objects from it, and even
    upload their own files, potentially leading to unauthorized data exposure, modification,
    or deletion.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**“Authenticated users” (anyone with an AWS account) can list files and read
    and write objects to the S3 bucket**: This misconfiguration allows *any user with
    an AWS account* to have the ability to list, read, and write objects stored in
    the bucket. This means that any individual or user with AWS credentials can access
    and modify the bucket’s contents.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The ACL configuration of the S3 bucket can be read by an external user**:
    This misconfiguration helps attackers gain additional information about the security
    configuration of the bucket.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The S3 bucket access logging setup is disabled in CloudTrail**: This misconfiguration
    prevents AWS users from auditing the event history for the S3 bucket(s) (including
    the actions performed by an entity or resource on our S3 buckets).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: If this is your first time encountering **CloudTrail**, it is simply an AWS
    service that helps monitor and record AWS account activity. This service plays
    an important role in helping enable governance, compliance, operational auditing,
    and risk auditing in AWS accounts. Disabling access logging for an S3 bucket in
    CloudTrail means that no logs will be generated to track and record the bucket’s
    access activity. This can limit the ability to detect unauthorized access attempts,
    troubleshoot problems, and maintain a complete record of bucket activity for compliance
    and security purposes.
  prefs: []
  type: TYPE_NORMAL
- en: 'With a clearer understanding of the typical misconfigurations that can occur
    in S3 buckets, we can now move forward and design and build our first cloud penetration
    testing lab environment. Specifically, our focus will be on designing a lab environment
    that involves a single S3 bucket that’s been intentionally misconfigured to simulate
    real-world vulnerabilities. Our misconfigured S3 bucket will store a few sample
    files, similar to what is shown in *Figure 2**.4*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image/B19755_02_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.4 – How our S3 bucket will be configured
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in *Figure 2**.4*, we will configure the S3 bucket to have the following
    properties and configuration settings:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Static website hosting** – **ENABLED**: This configuration enables static
    website hosting for the specified S3 bucket, allowing it to serve static web pages
    and assets directly from the bucket.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Block public access** – **DISABLED**: This configuration (when enabled) helps
    prevent accidental exposure of sensitive data by enforcing restrictions on public
    access. However, when this configuration setting is disabled, anonymous users
    and unauthorized entities may be able to access the bucket and the objects stored
    inside it (especially with a misconfigured S3 bucket).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bucket policy** – **AUTHENTICATED USERS CAN RETRIEVE OBJECTS**: This configuration
    allows authenticated users (that is, *anyone* with an AWS account) to retrieve
    objects from the S3 bucket, granting them access to the stored data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Access control list (ACL)** – **AUTHENTICATED USERS CAN LIST OBJECTS**: This
    allows authenticated users to list the objects within the S3 bucket.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition to these, we will be uploading a few sample files we might see in
    a typical S3 bucket. Now that we’ve discussed how our vulnerable lab environment
    will be (mis)configured, we can proceed with the hands-on portion of this chapter!
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: It is important to note that while we’re focusing on Amazon S3 in this chapter,
    similar issues and incidents have affected companies using Azure Blob Storage
    and Google Cloud Storage. These services, similar to Amazon S3, have encountered
    comparable security challenges and vulnerabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing our first vulnerable environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As discussed in the previous section, our first vulnerable environment will
    be composed of a single misconfigured Amazon S3 bucket containing a few sample
    files. There are a variety of ways to create an empty S3 bucket. In this chapter,
    we’ll use the AWS Management Console to create our bucket.
  prefs: []
  type: TYPE_NORMAL
- en: 'This section is composed of four subparts:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating an empty S3 bucket
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring the S3 bucket to host a static website
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Updating the S3 bucket configuration settings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uploading files to the S3 bucket
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Since we’ll be preparing an intentionally vulnerable S3 bucket, make sure you
    *don’t* use this S3 bucket to store production data (or files that contain sensitive
    information).
  prefs: []
  type: TYPE_NORMAL
- en: Creating an empty S3 bucket
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will start by creating an empty S3 bucket. Make sure that you are logged
    in using the “target account” (the first AWS account).
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: You may also opt to choose **N. Virginia** as the region where the S3 bucket
    will be created. Feel free to update the current region using the dropdown located
    in the top-left corner of the page before proceeding.
  prefs: []
  type: TYPE_NORMAL
- en: 'With this in mind, let’s proceed with creating the empty S3 bucket from the
    AWS Management Console:'
  prefs: []
  type: TYPE_NORMAL
- en: Type **s3** in the search bar:![](image/B19755_02_05.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 2.5 – Navigating to the S3 console
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select **S3** from the list of results (as highlighted in *Figure 2**.5*).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Next, click the **Create bucket** button, as highlighted in *Figure 2**.6*:![](image/B19755_02_06.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 2.6 – Locating the Create bucket button
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You should see the **Create bucket** button near the top right-hand corner of
    the page.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: It is important to note that the user interface may change once every few years.
    However, this shouldn’t prevent us from proceeding with creating the required
    resources as the attributes and properties to be configured pretty much stay the
    same (except for a few new properties and options).
  prefs: []
  type: TYPE_NORMAL
- en: Under **Bucket name**, specify a bucket name that is globally unique across
    all AWS users:![](image/B19755_02_07.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 2.7 – Creating an S3 bucket
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you are having a hard time naming your S3 bucket, you may name your S3 bucket
    **sample-web-bucket-<6-8 random alphanumeric characters>**. It may take you a
    few tries to come up with a valid and globally unique S3 bucket name.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'For guidelines on how to name S3 buckets, feel free to check the following
    link: [https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html](https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html).'
  prefs: []
  type: TYPE_NORMAL
- en: In addition to this, choose **US East (N. Virginia) us-east-1** from the list
    of options in the **AWS Region** select box.
  prefs: []
  type: TYPE_NORMAL
- en: Select the **ACLs enabled** option, similar to what is shown in *Figure 2**.8*:![](image/B19755_02_08.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 2.8 – Configuring the Object Ownership settings
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Setting the **Object Ownership** configuration value to **Object writer** will
    make the objects owned by the AWS account that uploads them. This means that the
    AWS account that owns the object can use ACLs to grant access to other users (even
    if that AWS account that uploaded the objects is not the owner of the bucket).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that AWS regularly updates and improves the user experience when using
    the AWS Management Console. In some cases, the default configuration settings
    are changed when creating resources after a certain date. For example, AWS has
    a new set of default settings for S3 Block Public Access and S3 Object Ownership
    when creating new S3 buckets after April 2023\. That said, you might have to click
    a few additional buttons and see a few differences when using the AWS Management
    Console by the time you read this book. Feel free to check the following link
    for more information about this topic: [https://docs.aws.amazon.com/AmazonS3/latest/userguide/create-bucket-faq.html](https://docs.aws.amazon.com/AmazonS3/latest/userguide/create-bucket-faq.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Uncheck the **Block all public access** checkbox, similar to what is shown in
    *Figure 2**.9*:![](image/B19755_02_09.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 2.9 – Turning off Block all public access
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In addition to this, make sure you toggle the **I acknowledge that the current
    settings might result in this bucket and the objects within becoming public**.
    checkbox *ON*. This will allow you to specify a bucket or access point policy
    that grants public access.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You should see a success notification, similar to what is shown in *Figure 2**.10*:![](image/B19755_02_10.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 2.10 – Locating the View details button
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click the **View details** button to navigate to the specific S3 bucket page
    of the bucket we just created.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Wasn’t that easy? Of course, we’re just getting started – we’ll have to configure
    this S3 bucket in the next few sections of this chapter!
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Configuring the S3 bucket to host a static website
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Continuing where we left off in the previous section, let’s proceed by configuring
    our S3 bucket for static website hosting. You would be surprised how easy it is
    to set this up! That said, let’s proceed:'
  prefs: []
  type: TYPE_NORMAL
- en: Click **Properties** to navigate to the **Properties** tab, as highlighted in
    *Figure 2**.11*:![](image/B19755_02_11.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 2.11 – Navigating to the Properties tab
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We should see the following under the **Properties** tab: (1) **Bucket overview**,
    (2) **Bucket versioning**, (3) **Tags**, (4) **Default encryption**, (5) **Intelligent-Tiering
    Archive configurations**, (6) **Server access logging**, (7) **AWS CloudTrail
    data events**, (8) **Event notifications**, (9) **Amazon EventBridge**, (10) **Transfer
    acceleration**, (11) **Object Lock**, (12) **Requester pays**, and (13) **Static**
    **website hosting**.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Scroll down to the bottom of the page until you reach the **Static website**
    **hosting** pane:![](image/B19755_02_12.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 2.12 – Editing the Static website hosting settings
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click the **Edit** button, as highlighted in *Figure 2**.12*.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Enable static website hosting by selecting the **Enable** option (refer to *Figure
    2**.13*):![](image/B19755_02_13.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 2.13 – Enabling static website hosting for the S3 bucket
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: After that, make sure you specify **index.html** in the **Index** **document**
    field.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Scroll down to the bottom of the page and click the **Save** **changes** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At this point, the bucket is still empty, so clicking the **Bucket website endpoint**
    link provided (after clicking the **Save changes** button) would give us a **404
    Not Found** error response. Do not worry – we will upload a custom **index.html**
    file later after we have updated the access control settings of the bucket in
    the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Updating the S3 bucket configuration settings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we’ve configured our S3 bucket for static website hosting, the next
    part involves configuring the bucket to allow anyone with an AWS account to list
    and access objects stored inside the bucket. That said, we will update the bucket
    policy and the ACL configuration settings in the next set of steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Click the **Permissions** tab (next to the **Properties** tab). We should see
    the following under the **Permissions** tab: (1) **Permissions overview**, (2)
    **Block public access (bucket settings)**, (3) **Bucket policy**, (4) **Object
    Ownership**, (5) **Access control list (ACL)**, and (6) **Cross-origin resource**
    **sharing (CORS)**.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, click the **Edit** button (as highlighted in *Figure 2**.14*) to specify
    a new bucket policy:![](image/B19755_02_14.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 2.14 – Editing Bucket policy
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In *Figure 2**.14*, we can see that no bucket policy is specified at the moment.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'After clicking the **Edit** button, specify the following bucket policy in
    the text area:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Make sure you replace **<BUCKET NAME>** with the bucket name of the S3 bucket
    you created. This should give you a bucket policy similar to what we have in *Figure
    2**.15*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](image/B19755_02_15.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 2.15 – Specifying a bucket policy
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This S3 bucket policy enables *any* AWS account to retrieve objects from the
    **sample-web-bucket-abc123** S3 bucket. You might be surprised that what we have
    in *Figure 2**.15* is a relatively common misconfiguration found across S3 buckets
    around the world!
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: It is important to note that changing the **"Action"** parameter value from
    **"s3:GetObject"** to **"*"** would allow *any* AWS account to perform unwanted
    actions (for example, uploading files) to our S3 bucket. We don’t want other users
    having write access to our bucket! Why? For one thing, malicious authenticated
    users would be able to upload multiple large files into our S3 bucket (which would
    impact our AWS bill). That said, the use of a wildcard or asterisk (**"*"**) should
    be avoided when working with policies whenever possible, even if we’re designing
    an intentionally vulnerable S3 bucket.
  prefs: []
  type: TYPE_NORMAL
- en: Scroll down to the bottom of the page and click the **Save** **changes** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, let’s modify the **Access control list (ACL)** configuration settings.
    Click the **Edit** button, as highlighted in *Figure 2**.16*:![](image/B19755_02_16.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 2.16 – Editing the ACL configuration
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Here, we can see the current ACL configuration of our S3 bucket. By default,
    only the bucket owner (you) can perform operations on the bucket.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Under **Edit access control list (ACL)** | **Access control list (ACL)**, toggle
    the **List** checkbox *ON* under the **Objects** column for the **Authenticated
    users group** grantee, similar to what we have in *Figure 2**.17*:![](image/B19755_02_17.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 2.17 – Allowing Authenticated users group to list objects inside the
    bucket
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This should allow anyone with an AWS account to list the objects in our S3 bucket.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Feel free to check out [https://aws.amazon.com/blogs/security/iam-policies-and-bucket-policies-and-acls-oh-my-controlling-access-to-s3-resources/](https://aws.amazon.com/blogs/security/iam-policies-and-bucket-policies-and-acls-oh-my-controlling-access-to-s3-resources/)
    for more information on how permission control works when multiple access control
    mechanisms are in place.
  prefs: []
  type: TYPE_NORMAL
- en: Make sure to toggle the **I understand the effects of these changes on my objects
    and buckets**. checkbox *ON*:![](image/B19755_02_18.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 2.18 – Confirming the ACL modifications to be applied
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Given that this configuration change may have unintended consequences (from
    a security standpoint), AWS requires us to review and confirm the changes being
    applied.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: AWS recommends that ACLs are disabled since we can rely on S3 bucket policies,
    IAM policies, VPC endpoint policies, and AWS Organizations SCPs when managing
    access control in S3 in most scenarios and use cases. However, despite the warnings
    and guardrails available, a lot of existing S3 buckets are still misconfigured
    and vulnerable since only new S3 buckets are protected by the latest set of guardrails
    enforced by AWS.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve modified the bucket policy along with the ACL configuration settings,
    we’ll proceed with uploading files to our S3 bucket in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Uploading files to the S3 bucket
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our setup would not be complete without files inside our vulnerable S3 bucket.
    That said, we will upload a few sample files we might see in a typical S3 bucket.
    There are a variety of ways to upload files to an S3 bucket. One option would
    be to upload files using the AWS Management Console. Another option would be to
    use the **AWS CLI** to upload files via the command line.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next set of steps, we’ll use the AWS CLI to upload files to our S3 bucket:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new browser tab and navigate to the AWS console. Type **shell** in the
    search bar and select **CloudShell** from the list of results, similar to what
    we have in *Figure 2**.19*:![](image/B19755_02_19.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 2.19 – Navigating to the CloudShell console
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you have not used **AWS CloudShell** before, it is simply a browser-based
    command-line terminal where we can run different commands to manage our resources.
    You’ll be surprised how convenient it is to use CloudShell in the succeeding set
    of steps!
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'It is important to note that AWS CloudShell may not be supported in other AWS
    regions. For more information, feel free to check the following link: [https://docs.aws.amazon.com/cloudshell/latest/userguide/supported-aws-regions.html](https://docs.aws.amazon.com/cloudshell/latest/userguide/supported-aws-regions.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Click the **Close** button when you see the **Welcome to AWS CloudShell** pop-up
    window:![](image/B19755_02_20.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 2.20 – Closing the welcome popup
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In *Figure 2**.20*, we can see that **AWS CloudShell** comes pre-installed with
    the AWS CLI, Python, and Node.js, along with other tools. In addition to this,
    we have 1 GB of free storage available (per AWS region) where we can manage, upload,
    and download the files that will be used for resource management and creation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Once you close the pop-up window, you should see a terminal where you can type
    and run bash commands.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In the terminal of our CloudShell environment (right after the **$** sign),
    run the following bash commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The **mkdir** command is used to create a new directory named **files**. After
    that, the **cd** command is used to navigate to the newly created directory.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, let’s run the following commands to download the **sample_website.zip**
    file into the **files** directory we just created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will generate a set of logs, similar to what we have in *Figure 2**.21*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](image/B19755_02_21.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 2.21 – Running commands on AWS CloudShell
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: What’s inside the **sample_website.zip** file we just downloaded? As we’ll see
    in the next set of steps, the **sample_website.zip** file contains an **index.html**
    file, along with a directory containing a backup copy of the backend code of the
    application.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'List all the files in the current directory using the **ls** command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: At this point, we should only have the **sample_website.zip** file in our current
    directory.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let’s extract the contents of the **sample_website.zip** file using the **unzip**
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should give us a set of logs, similar to what we have in the following
    block:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Before performing the upload command, let’s delete the **sample_website.zip**
    file from the **files** directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s upload the files to the S3 bucket using the **aws s3 cp** command
    (this should take around 10 to 15 seconds to complete):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Make sure you replace **<INSERT S3 BUCKET NAME>** with the name of your S3 bucket.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'In this step, we used the **AWS CLI** to upload files from a directory inside
    our AWS CloudShell environment to our S3 bucket. If this is your first time using
    the AWS CLI, it is simply a command-line tool for managing AWS resources, which
    includes creating and configuring resources, deploying applications, and managing
    security settings. For more information about the AWS CLI, feel free to check
    out the following video: [https://www.youtube.com/watch?v=EAFRKMe6j08](https://www.youtube.com/watch?v=EAFRKMe6j08).'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate back to the S3 console and locate the **Static website hosting** configuration
    settings under the **Properties** tab. Click the **Bucket website endpoint** link
    (as highlighted in *Figure 2**.22*):![](image/B19755_02_22.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 2.22 – Locating the Bucket website endpoint link
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We should see a maintenance page, similar to what is shown in *Figure 2**.23*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](image/B19755_02_23.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 2.23 – Verifying that the files have been uploaded to S3
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note that the **index.html** page we uploaded to the S3 bucket is returned and
    rendered when the request is made since it is the configured index document of
    the static website.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: With that, our setup is complete! In the next section, we’ll test our vulnerable
    environment and check if our current setup works and is configured as expected.
  prefs: []
  type: TYPE_NORMAL
- en: Testing and hacking our first vulnerable environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we’ll try to emulate how an attacker might behave when trying
    to hack our vulnerable S3 bucket. Attackers might use a specialized set of automated
    tools, but we should do just fine without those tools in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Inspecting and verifying the S3 bucket’s security
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will start by verifying the security configuration of the S3 bucket we created
    using a series of manual checks.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: It is unethical and illegal to attack cloud resources owned by another user
    or company. Before we start, make sure you read the *Examining the considerations
    when building penetration testing lab environments in the cloud* section of *[Chapter
    1](B19755_01.xhtml)*, *Getting Started with Penetration Testing Labs in the Cloud*,
    since we will be simulating the attack process to validate whether the misconfigurations
    and vulnerabilities and present are exploitable.
  prefs: []
  type: TYPE_NORMAL
- en: 'With that out of the way, we can proceed with testing and hacking our vulnerable
    cloud lab setup:'
  prefs: []
  type: TYPE_NORMAL
- en: Continuing where we left off in the previous section, right-click on the center
    of the maintenance page and select **View Page Source** from the list of options
    available. This should let us see the frontend HTML code of the maintenance page,
    similar to what we have in *Figure 2**.24*:![](image/B19755_02_24.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 2.24 – View Page Source
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Since this is a static page, we shouldn’t be able to find other links or references
    to resources we can inspect further.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Next, navigate to **http://<S3 BUCKET URL>.s3-website-us-east-1.amazonaws.com/.git**
    to check whether (1) a **.git** directory exists and (2) the **.git** directory
    is public. Make sure you replace **<S3 BUCKET URL>** with the name of the bucket
    you created. You should see an error message similar to what is shown in *Figure
    2**.25*:![](image/B19755_02_25.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 2.25 – 404 Not Found
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: As shown in *Figure 2**.25*, no such file or directory exists inside the bucket.
    You may check for other files such as **README.md** but since we have a good idea
    of what is inside the bucket, we can skip these additional steps for now.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Let’s also check whether the files and directories inside the S3 bucket will
    be listed by navigating to **https://<S3 BUCKET URL>.s3.amazonaws.com/**. Make
    sure you replace **<S3 BUCKET URL>** with the name of your S3 bucket:![](image/B19755_02_26.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 2.26 – Checking whether we can list the contents of the bucket
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This should give us an **Access Denied** error message, similar to what is shown
    in *Figure 2**.26*. Would this mean that we won’t be able to access the files
    as a guest user (public access) inside the bucket? Not necessarily! We’ll see
    that this is the case in the very next step.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Make sure you’re familiar with the different URLs that are available when working
    with S3 buckets. In addition to the URLs we checked in the previous step, you
    may also want to check **https://s3.amazonaws.com/<S3 BUCKET URL>/** (after replacing
    **<S3 BUCKET URL>** with the name of the S3 bucket).
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s check whether we can access some of the known files inside the bucket.
    Since the S3 bucket is configured to host a static website, it will probably have
    an **index.html** file (unless the bucket is configured to have a different index
    document). That said, let’s navigate to **https://<S3 BUCKET URL>.s3.amazonaws.com/index.html**.
    Similar to the previous step, make sure you replace **<S3 BUCKET URL>** with the
    name of your S3 bucket:![](image/B19755_02_27.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 2.27 – Checking whether we can access the index.html file
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This should render the maintenance page, similar to what we have in *Figure
    2**.27*. Note that we should be able to access the other files stored in this
    bucket since the S3 bucket is most likely configured to allow reads from unauthenticated
    users. However, since we do not know about the existence of certain files from
    the point of view of a guest user, we’ll skip any similar or related steps for
    now. Of course, checking all possible keys through brute-force methods inside
    the S3 bucket using an automated script is an option (but not recommended).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Open a private browsing window. Navigate to [https://aws.amazon.com/console/](https://aws.amazon.com/console/)
    and sign in to your second AWS account:![](image/B19755_02_28.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 2.28 – Opening a private browsing window
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You may decide to use a different browser altogether when signing in to your
    second AWS account. Note that we are simulating the experience from an attacker’s
    point of view.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Type **shell** in the search bar. Select **CloudShell** from the list of results,
    as highlighted in *Figure 2**.29*:![](image/B19755_02_29.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 2.29 – Navigating to the CloudShell console
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click the **Close** button if you see the **Welcome to AWS CloudShell** pop-up
    window.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set the **S3_BUCKET** variable value to the name of the S3 bucket we created
    earlier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Make sure you replace the value of **<INSERT S3 BUCKET NAME>** with the name
    of the S3 bucket we created earlier.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'List the contents of the S3 bucket using the **aws s3 ls** command with the
    **--no-sign-request** flag enabled:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This should yield an error message stating **An error occurred (AccessDenied)
    when calling the ListObjectsV2 operation:** **Access Denied**.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Using the **--no-sign-request** flag with the **aws s3 ls** command disables
    the requirement for AWS request signing. By default, AWS CLI requests are signed
    with AWS credentials to ensure authentication and authorization. However, when
    **--no-sign-request** is used, the command skips the signing process and allows
    unauthenticated and unsigned requests to be made to list the objects or files
    in the specified S3 bucket.
  prefs: []
  type: TYPE_NORMAL
- en: 'List the contents of the S3 bucket using the **aws s3 ls** command, this time
    without the **--****no-sign-request** flag:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This should successfully return the contents of the bucket (that is, the **index.html**
    file, along with the **backup** folder).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let’s check whether we can download the **index.html** file from the S3 bucket
    to the CloudShell environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should log a message similar to the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This means that we can list and download files as an authenticated user!
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Take note that this is *not* the same account we used to create the bucket.
    Of course, since we intentionally configured the S3 bucket to have this behavior,
    this should not be a surprise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s check whether we can upload a sample file from the CloudShell environment
    to the S3 bucket:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should return a message similar to the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This means that we cannot upload files to the S3 bucket as an authenticated
    user.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Note that attackers may also check whether they can retrieve and set the ACL
    of the bucket by using the **aws s3api get-bucket-acl** and **aws s3api put-bucket-acl**
    commands. For more information about this topic, feel free to check out [https://bit.ly/3mbwlb5](https://bit.ly/3mbwlb5)
    and [https://bit.ly/3SAPq2o](https://bit.ly/3SAPq2o).
  prefs: []
  type: TYPE_NORMAL
- en: It is important to note that we intentionally configured the S3 bucket to allow
    read-only access to authenticated users since we do not want other authenticated
    users to upload files to our S3 bucket.
  prefs: []
  type: TYPE_NORMAL
- en: Downloading and inspecting the files stored in the S3 bucket
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the previous section, we confirmed that we can download files from the S3
    bucket as an authenticated user using the **aws s3 cp** command. In this section,
    we’ll proceed with downloading and inspecting all the files stored in the vulnerable
    S3 bucket:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by using the **mkdir** command to create the **downloaded** directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, navigate to the **downloaded** directory using the **cd** command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the **aws s3 cp** command to download all the files stored in the target
    S3 bucket to the CloudShell local directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here, we used the **--recursive** flag to recursively download all the files
    stored in the S3 bucket:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](image/B19755_02_30.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 2.30 – Logs generated after executing the aws s3 cp command
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Here, we’re using a different AWS account to download the files stored inside
    the S3 bucket. *Scary, right?*
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: What this means is that *any* user with an AWS account, hypothetically including
    unauthorized users, could potentially access and download the files stored in
    the S3 bucket. Here, we demonstrated that we can download the contents of the
    misconfigured bucket with just a few commands using a different and completely
    unrelated AWS account.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s use the following command to install the **tree** command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With the **tree** command installed, let’s use it to generate a file tree of
    the current directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should generate and print a file tree similar to what we have in *Figure
    2**.31*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](image/B19755_02_31.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 2.31 – File tree generated using the tree command
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Using the **tree** command without **arguments/flags** would recursively list
    all files and give us a very long list of files and directories.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, let’s run the following command to limit the results (the tree depth)
    and display the hidden files as well:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should return a file tree similar to what we have in *Figure 2**.32*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](image/B19755_02_32.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 2.32 – Results after running the tree command
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: From the tree results shown in *Figure 2**.32*, we can infer that the backend
    web framework that’s being used is **Hapi.js** ([https://hapi.dev/](https://hapi.dev/)).
    In addition to this, the **dotenv** **npm** package is used to manage and load
    environment variables. *Figure 2**.23* also shows that there’s a **.env** file
    stored inside the **/****backup/backend** directory.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To avoid hardcoding secrets, variables, and configuration settings inside the
    application code, development teams may utilize packages such as **dotenv** to
    load credentials and environment variables from **.env** files. Alternatively,
    development and engineering teams may utilize YAML or JSON files as well. One
    of the common mistakes developers make involves forgetting to exclude these in
    the code repository. This means that anyone with access to the repository (or
    the backup of a repository) would be able to get a copy of the file containing
    the credentials and variables used in the application as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s run the following command to see what’s inside the **.****env** file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should give us placeholder values for **AWS_ACCESS_KEY_ID** and **AWS_SECRET_ACCESS_KEY**,
    similar to what we have in the following configuration block:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that in a more realistic scenario, we might find other credentials and
    keys here as well. It is also worth noting that credentials may be found hardcoded
    inside the repository’s code base.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: '*What will an attacker do once these credentials have been obtained?* The attacker
    can now perform malicious actions using the accounts associated with these credentials.
    For example, attackers may use the credentials of an email service (for example,
    **SendGrid**) to send phishing emails to attack other individuals or organizations.
    Attackers may also be able to access databases after getting access to the *.env*,
    *YAML*, or *JSON* files since these files will most likely contain database credentials
    as well.'
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we should have a good idea of how to prepare and test a relatively
    simple vulnerable cloud resource. Of course, production environments would most
    likely have other resources deployed in the same account. Do not worry – we’ll
    see the complexity of our vulnerable cloud environments grow as we work on the
    hands-on examples of the succeeding chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Cleaning up the cloud resources we created or deployed is a crucial step when
    working with vulnerable cloud applications and environments. If we don’t clean
    up the resources we created right away, we might end up having our resources attacked
    by malicious users. That said, let’s proceed with deleting the resources we created
    in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by logging in to the AWS Management Console using the account we
    used to create the S3 bucket. Remember that we have two accounts – the “target”
    AWS account and the “attacker” AWS account. We’ll proceed with signing in to the
    “target” AWS account as we used that account to create the S3 bucket.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Type **shell** in the search bar and select **CloudShell** from the list of
    results, as shown in *Figure 2**.33*:![](image/B19755_02_33.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 2.33 – Navigating to the CloudShell console
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click the **Close** button when you see the **Welcome to AWS CloudShell** pop-up
    window.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In the terminal of our CloudShell environment (right after the **$** sign),
    run the following bash command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we are setting the **S3_BUCKET** variable’s value with the name of the
    S3 bucket we created earlier. Make sure you replace the value of **<INSERT S3
    BUCKET NAME>** with the name of your S3 bucket.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, let’s use the **aws s3 rb** (remove bucket) command to delete the bucket,
    along with all the objects inside it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should yield a set of logs, similar to what we have in *Figure 2**.34*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](image/B19755_02_34.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 2.34 – Logs generated after running the aws s3 rb command
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The command we executed will delete all the objects inside the bucket and then
    delete the S3 bucket once it’s empty.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that we should be careful when using the **aws s3 rb** command in production
    since we will lose all files inside the bucket when object versioning is disabled.
    We must have a backup of the files stored inside the bucket before running this
    command. Feel free to check out the following link for more details: [https://docs.aws.amazon.com/AmazonS3/latest/userguide/delete-bucket.html](https://docs.aws.amazon.com/AmazonS3/latest/userguide/delete-bucket.html).'
  prefs: []
  type: TYPE_NORMAL
- en: That’s pretty much it! Since we’re only dealing with a relatively simple setup,
    the cleanup process is expected to be straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we designed and prepared our first intentionally vulnerable
    lab environment in the cloud. We started by creating an empty S3 bucket using
    the AWS Management Console. After that, we configured the bucket for static website
    hosting. We also modified the access control settings of the S3 bucket and allowed
    other authenticated AWS users to list and retrieve objects from our bucket. To
    complete the setup, we uploaded sample files to our S3 bucket.
  prefs: []
  type: TYPE_NORMAL
- en: We proceeded by testing our setup by inspecting and verifying the S3 bucket’s
    security configuration using a series of steps, which included several terminal
    commands. After confirming that we could download files from the S3 bucket using
    a second AWS account (not used to create the bucket), we proceeded with downloading
    and inspecting all the files stored in the bucket. Finally, we wrapped things
    up by cleaning up and deleting the resources we created in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will focus on how to use **Infrastructure as Code**
    (**IaC**) tools and strategies to help us build and manage complex vulnerable
    lab environments in the cloud. If you’re wondering whether or not we can automate
    the steps we have performed in this chapter, then the next chapter is for you!
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For more information on the topics covered in this chapter, feel free to check
    out the following resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '*IAM Policies and Bucket Policies and* *ACLs* ([https://aws.amazon.com/blogs/security/iam-policies-and-bucket-policies-and-acls-oh-my-controlling-access-to-s3-resources/](https://aws.amazon.com/blogs/security/iam-policies-and-bucket-policies-and-acls-oh-my-controlling-access-to-s3-resources/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*S3 – Managing access with* *ACLs* ([https://docs.aws.amazon.com/AmazonS3/latest/userguide/acls.html](https://docs.aws.amazon.com/AmazonS3/latest/userguide/acls.html))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Heads-Up: Amazon S3 Security Changes Are Coming in April of* *2023* ([https://aws.amazon.com/blogs/aws/heads-up-amazon-s3-security-changes-are-coming-in-april-of-2023/](https://aws.amazon.com/blogs/aws/heads-up-amazon-s3-security-changes-are-coming-in-april-of-2023/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Controlling ownership of objects and disabling ACLs for your* *bucket* ([https://docs.aws.amazon.com/AmazonS3/latest/userguide/about-object-ownership.html](https://docs.aws.amazon.com/AmazonS3/latest/userguide/about-object-ownership.html))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Default settings for new S3 buckets* *FAQ* ([https://docs.aws.amazon.com/AmazonS3/latest/userguide/create-bucket-faq.html](https://docs.aws.amazon.com/AmazonS3/latest/userguide/create-bucket-faq.html))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
