<html><head></head><body>
		<div id="_idContainer010">
			<h1 id="_idParaDest-51" class="chapter-number"><a id="_idTextAnchor050"/>3</h1>
			<h1 id="_idParaDest-52"><a id="_idTextAnchor051"/>Key Concepts for Pentesting Today’s Cloud Networks</h1>
			<p>Before you perform your first cloud pentest or red team engagement, there are some concepts you need <span class="No-Break">to learn.</span></p>
			<p>Cloud platforms have policies for pentesting that you and your organization must abide by. It’s also important to understand and verify network performance with benchmark checks. Services enumeration is a way an attacker can learn things about your organization’s public cloud services that can help them <span class="No-Break">cyber-attack it.</span></p>
			<p>Assure that your organization’s public cloud has performed vulnerability assessments and that common cloud misconfigurations are addressed before <span class="No-Break">you pentest.</span></p>
			<p>Resources provided by MITRE’s <strong class="bold">Common Vulnerabilities and Exposures</strong> (<strong class="bold">CVE</strong>) database, the <strong class="bold">National Institute of Standards and Technology’s</strong> (<strong class="bold">NIST’s</strong>) <strong class="bold">National Vulnerability Database</strong> (<strong class="bold">NVD</strong>) database, and the <strong class="bold">Forum of Incident Response and Security Teams’</strong> (<strong class="bold">FIRST’s</strong>) <strong class="bold">Exploit Prediction Scoring System</strong> (<strong class="bold">EPSS</strong>) database help pentesters and red teamers define and understand specific <span class="No-Break">known vulnerabilities.</span></p>
			<p>You also must understand how to communicate and cooperate with your organization’s defensive security <span class="No-Break">specialists effectively.</span></p>
			<p>In this chapter, we’ll cover the following <span class="No-Break">main topics:</span></p>
			<ul>
				<li>Cloud platform policies, benchmark checks, and <span class="No-Break">services enumeration</span></li>
				<li>Exposed services, permissions, <span class="No-Break">and integrations</span></li>
				<li>CVE, the <strong class="bold">Common Vulnerability Scoring System</strong> (<strong class="bold">CVSS</strong>), <span class="No-Break">and vulnerabilities</span></li>
				<li>Purple teaming and writing <span class="No-Break">pentest reports</span></li>
			</ul>
			<p>Let’s <span class="No-Break">get started!</span></p>
			<h1 id="_idParaDest-53"><a id="_idTextAnchor052"/>Cloud platform policies, benchmark checks, and services enumeration</h1>
			<p>Pentesting cloud networks<a id="_idIndexMarker152"/> on public cloud platforms is fundamentally different from pentesting on your organization’s own premises and its <span class="No-Break">own infrastructure.</span></p>
			<p>If your organization owns the premises and infrastructure, it has the legal right to determine everything you’re allowed and forbidden to do to its network for your pentest. If I buy a house, as long as the laws in my municipality and country don’t forbid it, I could allow building contractors to replace walls, redo my roof, install new doors, and <span class="No-Break">so on.</span></p>
			<p>If I rent my house from a landlord, I don’t own my house. I would need my landlord’s permission if I wanted to pay building contractors to make those sorts of modifications to <span class="No-Break">my house.</span></p>
			<p>On <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>), Azure, and <strong class="bold">Google Cloud Platform</strong> (<strong class="bold">GCP</strong>), your organization<a id="_idIndexMarker153"/> is “renting its house” from its “landlord”—Amazon, Microsoft, or<a id="_idIndexMarker154"/> Google. Amazon, Microsoft, and Google make the rules for what you’re allowed to do as <span class="No-Break">a pentester.</span></p>
			<p>If the organization you work for asks you to do something in its AWS-, Azure-, and GCP-hosted networks that Amazon, Microsoft, and Google forbid in their policies, you absolutely shouldn’t do it. It is important to locate the penetration testing policies for cloud providers on their respective websites and share them with your employer to clarify any restrictions or limitations on conducting penetration testing. We list <span class="No-Break">them here:</span></p>
			<ul>
				<li><em class="italic">AWS Customer Support Policy for Penetration </em><span class="No-Break"><em class="italic">Testing</em></span><span class="No-Break">: </span><a href="https://aws.amazon.com/security/penetration-testing/&#13;"><span class="No-Break">https://aws.amazon.com/security/penetration-testing/</span></a></li>
				<li><em class="italic">Amazon EC2 Testing </em><span class="No-Break"><em class="italic">Policy</em></span><span class="No-Break">: </span><a href="https://aws.amazon.com/ec2/testing/&#13;"><span class="No-Break">https://aws.amazon.com/ec2/testing/</span></a></li>
				<li><em class="italic">AWS DDoS Simulation Testing </em><span class="No-Break"><em class="italic">Policy</em></span><span class="No-Break">: </span><a href="https://aws.amazon.com/security/ddos-simulation-testing/&#13;"><span class="No-Break">https://aws.amazon.com/security/ddos-simulation-testing/</span></a></li>
				<li><em class="italic">Microsoft Online Subscription </em><span class="No-Break"><em class="italic">Agreement</em></span><span class="No-Break">: </span><a href="https://azure.microsoft.com/en-us/support/legal/subscription-agreement/&#13;"><span class="No-Break">https://azure.microsoft.com/en-us/support/legal/subscription-agreement/</span></a></li>
				<li><em class="italic">Microsoft Cloud Penetration Testing Rules of </em><span class="No-Break"><em class="italic">Engagement</em></span><span class="No-Break">: </span><a href="https://www.microsoft.com/en-us/msrc/pentest-rules-of-engagement&#13;"><span class="No-Break">https://www.microsoft.com/en-us/msrc/pentest-rules-of-engagement</span></a></li>
				<li><em class="italic">Google Cloud Platform Terms of </em><span class="No-Break"><em class="italic">Service</em></span><span class="No-Break">: </span><a href="https://cloud.google.com/terms/&#13;"><span class="No-Break">https://cloud.google.com/terms/</span></a></li>
				<li><em class="italic">Google Cloud Platform Acceptable Use </em><span class="No-Break"><em class="italic">Policy</em></span><span class="No-Break">: </span><a href="https://cloud.google.com/terms/aup&#13;"><span class="No-Break">https://cloud.google.com/terms/aup</span></a></li>
			</ul>
			<p>I recommend reading <a id="_idIndexMarker155"/>the cloud provider’s policies carefully before your organization<a id="_idIndexMarker156"/> proposes a pentest or red team engagement of its public cloud networks. Then, read your organization’s proposal and pentesting scope to verify that what you are being asked to do is compliant with Amazon’s, Microsoft’s, or Google’s policies. Depending on what your organization is asking you to do, you might only have to make minor modifications to your scope and simulated cyber attacks in order to <span class="No-Break">be policy-compliant.</span></p>
			<p>I mentioned AWS, Azure, and GCP pentesting policies in <a href="B18672_01.xhtml#_idTextAnchor014"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>. But for your reference, here are links to official policies and a brief summary of each. That’s how important <span class="No-Break">it is!</span></p>
			<ul>
				<li><strong class="bold">AWS</strong>: General pentesting is permitted<a id="_idIndexMarker157"/> on most AWS services. DNS zone<a id="_idIndexMarker158"/> walking, DNS hijacking, and DNS pharming<a id="_idIndexMarker159"/> are forbidden on Route 53. Most <strong class="bold">Denial-of-Service</strong> (<strong class="bold">DoS</strong>) and <strong class="bold">Distributed Denial-of-Service</strong> (<strong class="bold">DDoS</strong>) simulations are forbidden. Protocol flooding and request flooding are forbidden. Pentesting with <strong class="bold">Command and Control</strong> (<strong class="bold">C2</strong>) servers requires direct approval<a id="_idIndexMarker160"/> from Amazon. You must also ask Amazon for approval for network stress testing, using the iPerf tool, simulated<a id="_idIndexMarker161"/> phishing, and using malware in your pentesting. <span class="No-Break">See </span><a href="https://aws.amazon.com/security/penetration-testing/"><span class="No-Break">https://aws.amazon.com/security/penetration-testing/</span></a><span class="No-Break">.</span></li>
				<li><strong class="bold">Azure and Microsoft Cloud in general</strong>: Most pentesting without prior<a id="_idIndexMarker162"/> authorization<a id="_idIndexMarker163"/> is permitted. However, scanning and testing other customers’ assets and accessing their data is forbidden. Automated testing that generates too much traffic is forbidden. All DoS and DDoS simulations are forbidden. Network-intensive fuzzing against anything but your organization’s own Azure Virtual Machines is forbidden. Moving beyond <strong class="bold">proof-of-concept</strong> (<strong class="bold">PoC</strong>) reproduction steps for infrastructure <a id="_idIndexMarker164"/>execution issues is forbidden. Attempting social engineering against Microsoft<a id="_idIndexMarker165"/> employees<a id="_idIndexMarker166"/> <span class="No-Break">is forbidden.</span></li>
				<li><strong class="bold">GCP</strong>: Pentesting the GCP infrastructure <a id="_idIndexMarker167"/>your organization<a id="_idIndexMarker168"/> uses is subject to Google’s Acceptable Use Policy (<a href="https://cloud.google.com/terms/aup">https://cloud.google.com/terms/aup</a> <span class="No-Break">and </span><a href="https://cloud.google.com/terms/"><span class="No-Break">https://cloud.google.com/terms/</span></a><span class="No-Break">).</span></li>
			</ul>
			<p>Now, let’s get into <span class="No-Break">benchmark checks!</span></p>
			<p>A benchmark<a id="_idIndexMarker169"/> is defined as a standard with which to measure performance. Your organization may have certain expectations for how its public cloud networks perform on a day-to-day or hour-to-hour basis. In the cloud, benchmarks are often based on application and server availability defined as uptime, responsiveness from application slowdowns, and how long it may take to remediate network <span class="No-Break">functionality problems.</span></p>
			<p>If your organization<a id="_idIndexMarker170"/> wants to conduct benchmark checks on its public cloud networks, I recommend basing them on AWS, Azure, or GCP’s <strong class="bold">service-level agreements</strong> (<strong class="bold">SLAs</strong>). Those are the network and infrastructure-related performance standards that the cloud providers guaranteed your organization when you signed up for <span class="No-Break">their services.</span></p>
			<p>For AWS services, Amazon guarantees a certain amount of monthly uptime. If these benchmarks aren’t met, your organization may be entitled to a 10%, 25%, or 100% <span class="No-Break">Service Credit.</span></p>
			<p>For Azure and Microsoft Online Services in general, their SLAs are conceptually similar to AWS. If certain monthly uptime benchmarks aren’t met, your organization may be entitled to a 10%, 25%, or 100% Service Credit. Microsoft’s SLAs are updated at least a couple of times <span class="No-Break">per year.</span></p>
			<p>For GCP services, their SLAs are also similar. But they generally offer a 10%, 25%, or 50% Service Credit for uptime benchmarks <span class="No-Break">not met.</span></p>
			<p>Beyond benchmarking for uptime, your organization<a id="_idIndexMarker171"/> may also want to benchmark its public cloud networks for security. The <strong class="bold">Center for Internet Security</strong> (<strong class="bold">CIS</strong>) offers a set of cybersecurity benchmarks<a id="_idIndexMarker172"/> for AWS, Azure, and GCP, <span class="No-Break">as follows:</span></p>
			<ul>
				<li><a href="https://www.cisecurity.org/benchmark/amazon_web_services"><span class="No-Break">https://www.cisecurity.org/benchmark/amazon_web_services</span></a></li>
				<li><a href="https://www.cisecurity.org/benchmark/azure"><span class="No-Break">https://www.cisecurity.org/benchmark/azure</span></a></li>
				<li><a href="https://www.cisecurity.org/benchmark/google_cloud_computing_platform"><span class="No-Break">https://www.cisecurity.org/benchmark/google_cloud_computing_platform</span></a></li>
			</ul>
			<p>Enumerating cloud services is a way for an outsider to determine which cloud services your organization has, how they’re used, their permissions, and which access tokens are for <span class="No-Break">which service.</span></p>
			<p>MITRE ATT&amp;CK defines cloud enumeration<a id="_idIndexMarker173"/> as <span class="No-Break">follows (</span><a href="https://attack.mitre.org/techniques/T1526/"><span class="No-Break">https://attack.mitre.org/techniques/T1526/</span></a><span class="No-Break">):</span></p>
			<p class="author-quote">“An adversary may attempt to enumerate the cloud services running on a system after gaining access. These methods can differ from platform-as-a-service (PaaS), to infrastructure-as-a-service (IaaS), or software-as-a-service (SaaS). Many services exist throughout the various cloud providers and can include Continuous Integration and Continuous Delivery (CI/CD), Lambda Functions, Azure AD, etc.</p>
			<p class="author-quote">Adversaries may attempt to discover information about the services enabled throughout the environment. Azure tools and APIs, such as the Azure AD Graph API and Azure Resource Manager API, can enumerate resources and services, including applications, management groups, resources, and policy definitions, and their relationships that are accessible by an identity.”</p>
			<p>Now, let’s look at some of the more common security problems public cloud services <span class="No-Break">can have.</span></p>
			<h1 id="_idParaDest-54"><a id="_idTextAnchor053"/>Exposed services, permissions, and integrations</h1>
			<p>Every network should undergo vulnerability assessments before they’re pentested. Make sure the organization whose cloud network you’re pentesting has had some vulnerability assessments <span class="No-Break">conducted recently.</span></p>
			<p>A vulnerability assessment (sometimes called a vulnerability audit) is a systematic process <a id="_idIndexMarker174"/>where a checklist<a id="_idIndexMarker175"/> is used to identify common security weaknesses, misconfigurations, and other vulnerabilities pertaining to a type of computer system. A vulnerability assessment is a systematic process of identifying, analyzing, and prioritizing vulnerabilities in a system, network, or application. It involves scanning the system to identify existing weaknesses, flaws, or vulnerabilities that could be exploited by attackers. An old-fashioned vulnerability assessment may have a human network security specialist use a manual list of common vulnerabilities in a particular operating system or application and look through the software, hardware, and networking settings and configurations to make sure none of them makes the computer system more susceptible to cyber attacks. That can be tedious work, but relatively practical in a 20<span class="superscript">th</span>-century on-premises network that doesn’t change <span class="No-Break">very often.</span></p>
			<p>But 21<span class="superscript">st</span>-century cloud networks change very frequently. This especially pertains to containerization through platforms such as Kubernetes and Docker where a single container (virtualized application or operating system) might only live for a few days. Modern cloud networks can also be a lot more complicated, with a lot greater variety of applications and services to be concerned about. Multi-cloud, hybrid cloud, and hybrid multi-cloud environments can be especially diverse <span class="No-Break">and complex.</span></p>
			<p>So, it’s usually impractical to conduct old-fashioned manual vulnerability assessments<a id="_idIndexMarker176"/> in cloud networks. There’s no way a few human beings would be able to keep up with everything proper cloud vulnerability assessments entail. That’s why we use automated vulnerability scanners in <span class="No-Break">the cloud.</span></p>
			<p>There are a variety of different cloud vulnerability scanners that you <span class="No-Break">can use.</span></p>
			<p>AWS has its own<a id="_idIndexMarker177"/> Amazon Inspector (<a href="https://aws.amazon.com/inspector/">https://aws.amazon.com/inspector/</a>). Microsoft recommends Microsoft Defender<a id="_idIndexMarker178"/> for Cloud (<a href="https://www.microsoft.com/en-ca/security/business/cloud-security/microsoft-defender-cloud">https://www.microsoft.com/en-ca/security/business/cloud-security/microsoft-defender-cloud</a>) (a component of Microsoft Defender for Servers) for Azure. Google recommends<a id="_idIndexMarker179"/> Rapid Vulnerability Detection (<a href="https://cloud.google.com/security-command-center/docs/concepts-rapid-vulnerability-detection-overview">https://cloud.google.com/security-command-center/docs/concepts-rapid-vulnerability-detection-overview</a>), and for GCP, it depends on what kinds of service tiers your organization is subscribed to and which GCP services your <span class="No-Break">organization uses.</span></p>
			<p>There are also some third-party vulnerability scanners<a id="_idIndexMarker180"/> you could use if they suit your needs. Some of the most popular ones are Astra Pentest, Qualys Cloud Platform, and <span class="No-Break">Aqua Security.</span></p>
			<p class="callout-heading">Information</p>
			<p class="callout">Astra Pentest<a id="_idIndexMarker181"/> automates vulnerability scanning and has tools to automate some of your pentesting work, but it shouldn’t replace your job as a <span class="No-Break">cloud pentester.</span></p>
			<p>Before you start your first cloud pentest, make sure your organization has used some cloud vulnerability scanners recently. Make sure it has fixed or remediated the problems the scanners detected, and make sure you can see the results of recent vulnerability scans. The reason for doing this is if your organization’s cloud networks have a lot of common vulnerabilities that can be detected<a id="_idIndexMarker182"/> by vulnerability scanners, then your pentest will probably <span class="No-Break">be wasteful.</span></p>
			<p>This section is about some<a id="_idIndexMarker183"/> of the most common types of cloud security problems—exposed services, permissions problems (ineffective <strong class="bold">identity and access management</strong>, or <strong class="bold">IAM</strong>), and poorly configured cloud integrations. These issues should be remediated as much as possible before <span class="No-Break">you pentest!</span></p>
			<p>First, let’s examine <span class="No-Break">exposed services.</span></p>
			<h2 id="_idParaDest-55"><a id="_idTextAnchor054"/>Exposed services</h2>
			<p>An exposed service<a id="_idIndexMarker184"/> is a service in your cloud network that’s unguarded from unauthorized access. Think of all of the various types of services and protocols you can find in the cloud and on the internet—HTTPS web servers, FTP file servers, SSH-encrypted remote access servers, RDP Windows remote access services, SMB services such as Samba—the list goes on. All of these potential vectors in your cloud network should have strong authentication protection, and they should also be well monitored through your cloud network’s logs. It’s all too common for these connections from your cloud network to the public internet to be easy ways for a cyber attacker to <span class="No-Break">break in.</span></p>
			<p>Cloud vulnerability scanners are often very good at finding whichever exposed services your cloud network may have, so you can remediate the problem by either improving the encryption and authentication access on the service or disabling the service altogether if your organization doesn’t <span class="No-Break">use it.</span></p>
			<p>Another way to find exposed services is to use Shodan. Shodan<a id="_idIndexMarker185"/> offers service plans with monthly fees to continuously monitor and scan your cloud network’s IP addresses for <span class="No-Break">exposed services.</span></p>
			<p>Security researchers have studied the immense problem of exposed services in cloud networks. In 2021, Palo Alto Networks’ Unit 42 conducted a research study. It deployed 320 honeypots into a cloud network. A honeypot is a computer or server that’s made to be deliberately insecure in order to tempt cyber threat actors to attack it. The purpose of using honeypots is usually to distract attackers away from the servers an organization must keep secure and to monitor cyber-attack activity in order to better <span class="No-Break">understand it.</span></p>
			<p>The 320 honeypots Unit 42 deployed used a combination of SSH, Samba, Postgres, and RDP. It set up each honeypot with very weak credentials such as “<strong class="source-inline">username: admin</strong>, <strong class="source-inline">password: admin</strong>” and monitored the honeypots to see how often they’d be attacked. All of the honeypots were attacked in less than two days. Some of the honeypots were attacked within 30 seconds of deployment! Most of the honeypots were attacked multiple times per day; the most frequently attacked honeypot was compromised 169 times in a <span class="No-Break">single day.</span></p>
			<p>This is why your organization must be very careful to avoid having any exposed services in your cloud network. One of the many kinds of cyber attacks exposed services can make your cloud network susceptible to is data breaches. According to IBM’s 2023 Cost of a Data Breach Report (<a href="https://www.ibm.com/reports/data-breach">https://www.ibm.com/reports/data-breach</a>), data breaches cost an organization an average of $4.35 million per incident! And that’s just one of the kinds of cyber attacks that exposed<a id="_idIndexMarker186"/> services are <span class="No-Break">vulnerable to.</span></p>
			<p>Now let’s explore permissions and IAM in <span class="No-Break">the cloud.</span></p>
			<h2 id="_idParaDest-56"><a id="_idTextAnchor055"/>Permissions</h2>
			<p>In a secure computer<a id="_idIndexMarker187"/> system, all data assets are only accessible to authorized users and entities. According<a id="_idIndexMarker188"/> to Gartner (<a href="https://www.gartner.com/en/information-technology/glossary/identity-and-access-management-iam">https://www.gartner.com/en/information-technology/glossary/identity-and-access-management-iam</a>), IAM is a “<em class="italic">security and business discipline that includes multiple technologies and business processes to help the right people or machines to access the right assets at the right times for the right reasons.</em>” Each entity that’s allowed at least some access to a computer system requires an identity and means of authentication such as passwords, biometrics, and <span class="No-Break">access tokens.</span></p>
			<p>Permissions are what users are allowed to do within a computer system. For instance, on my own personal laptop, I have full administrative access in my Windows 11 installation. I can install, uninstall, and configure all of my applications. I can create as many new user accounts as I want and give them whichever permissions I want. I can alter the Windows Registry. I can change all of the Windows settings. I can read, write, and access absolutely everything in my filesystem on my data storage. But when I log in to my employer’s cloud network, my permissions are a lot more limited. I can only access the applications that I need to use for my job. I cannot create new user accounts. I can only access data that I need to have in my role in the company. That’s because I own my laptop, but I don’t own my employer’s cloud<a id="_idIndexMarker189"/> network. As with many networks with good cybersecurity, my employer’s cloud network uses a <strong class="bold">role-based access control</strong> (<span class="No-Break"><strong class="bold">RBAC</strong></span><span class="No-Break">) system.</span></p>
			<p>In RBAC, permissions are assigned to user groups within a filesystem. The groups correlate with a user’s role in a company. There might be a payroll department group that has access to the company’s payroll servers and applications, a research and development group that has access to the company’s research and development data, a web administrators group that can make changes to the company’s web servers, and so on. Permissions<a id="_idIndexMarker190"/> aren’t directly assigned to users; permissions are assigned to groups. It’s a more streamlined access control system that avoids the tedium of managing permissions user <span class="No-Break">by user.</span></p>
			<p><strong class="bold">Mandatory Access Control</strong> (<strong class="bold">MAC</strong>) is the strictest access control model. Resource objects in a system<a id="_idIndexMarker191"/> can be assigned a confidentiality level such as high, medium, low, and categories according to departments and specific projects. Then, permissions to those objects are very carefully configured for each user. It can be a tedious sort of access control model to maintain, which is why MAC is most often seen in use cases with highly classified data such as <span class="No-Break">government agencies.</span></p>
			<p>In <strong class="bold">Discretionary Access Control</strong> (<strong class="bold">DAC</strong>), users assign permissions to the data objects they<a id="_idIndexMarker192"/> create. It’s the default access control system in the Windows operating system and other local operating systems on computers that people <span class="No-Break">own themselves.</span></p>
			<p>The major cloud providers<a id="_idIndexMarker193"/> have their own tools your organization can use to improve <span class="No-Break">your IAM.</span></p>
			<p>Amazon recommends its own AWS Identity and Access Management for AWS. You can use it to manage <strong class="bold">attribute-based access control </strong>(<strong class="bold">ABAC</strong>), which is similar to RBAC. You can also use it to implement guardrails to prevent privilege escalation attacks and unauthorized access to user accounts. You can also manage user and machine identities across single or multiple <span class="No-Break">AWS accounts.</span></p>
			<p>Microsoft recommends<a id="_idIndexMarker194"/> its own Microsoft Entra ID (formerly known as Azure Active Directory) for Azure, which is similar<a id="_idIndexMarker195"/> to Active Directory in Windows Server. Azure Active Directory has the advantage of also being able to control IAM in multi-cloud and hybrid-cloud environments. So, for instance, if your organization has a hybrid cloud with some Windows Server machines in your on-premises network, all of your IAM from your premises to your public cloud can be harmonized through the same Active <span class="No-Break">Directory system.</span></p>
			<p>Google also has its own GCP IAM. Some of its key features include automated access control recommendations, flexible roles, and <span class="No-Break">context-aware access.</span></p>
			<p>Penetration testing<a id="_idIndexMarker196"/> can be used to ensure that the IAM in your organization’s cloud network is properly configured. That includes only assigning necessary permissions to each user (the <strong class="bold">principle of least privilege</strong>, or <strong class="bold">PoLP</strong>) and making sure users have strong passwords<a id="_idIndexMarker197"/> and multiple factors of authentication (such as one-time password multiple-factor authentication applications, biometrics, and <span class="No-Break">access tokens).</span></p>
			<p>Now, let’s look at cloud integrations. It’s essential that cloud integrations are configured and deployed securely because insecure integrations are a common cloud <span class="No-Break">security problem.</span></p>
			<h2 id="_idParaDest-57"><a id="_idTextAnchor056"/>Cloud integration</h2>
			<p>Cloud integration<a id="_idIndexMarker198"/> is all about connecting multiple cloud networks together. In a hybrid cloud network, integration also means connecting your on-premises servers to your cloud network. Unless your organization only has endpoints on-premises and a single public cloud, cloud integration <span class="No-Break">is inevitable.</span></p>
			<p>Security problems with cloud integration occur when there’s poor network visibility, when security solutions are incompatible between cloud platforms, and when APIs between cloud applications are <span class="No-Break">poorly secured.</span></p>
			<p>Your organization cannot secure what it cannot see. So, poor network visibility means parts of your hybrid-cloud or multi-cloud network could have vulnerabilities your organization is unaware of. To address this problem, it’s vital that as many applications and services are logged as possible and that security monitoring solutions are compatible and deployed throughout your integrated <span class="No-Break">cloud environment.</span></p>
			<p>Poorly secured APIs between integrated cloud applications and services are especially susceptible to code injection (SQL injection, command injection) and query injection attacks, as well as malicious requests that exploit poor access control and outdated components. Just as it’s prudent to eliminate exposed services in general, it’s also prudent to eliminate <span class="No-Break">exposed APIs.</span></p>
			<p>Vulnerability scanners may not detect visibility problems, but some vulnerability scanners are good at detecting <span class="No-Break">insecure APIs.</span></p>
			<p>Visibility problems can be mitigated by using data mapping solutions to maintain a thorough data asset inventory. It’s also crucial to have robust logging throughout your multi-cloud or hybrid cloud<a id="_idIndexMarker199"/> and to feed those logs into security <span class="No-Break">monitoring applications.</span></p>
			<p>Now, let’s get into what your work as a cloud pentester is supposed to <span class="No-Break">find—security vulnerabilities!</span></p>
			<h1 id="_idParaDest-58"><a id="_idTextAnchor057"/>CVE, CVSS, and vulnerabilities</h1>
			<p>In cybersecurity, we have formal<a id="_idIndexMarker200"/> systems for classifying security vulnerabilities in networks and applications. Known vulnerabilities are recorded in MITRE’s Common Vulnerabilities and Exposures<a id="_idIndexMarker201"/> database, or CVE for short (<a href="https://www.cve.org/">https://www.cve.org/</a>). CVE records are classified according<a id="_idIndexMarker202"/> to MITRE’s CVSS (<a href="https://nvd.nist.gov/vuln-metrics/cvss">https://nvd.nist.gov/vuln-metrics/cvss</a>). Also, known exploits<a id="_idIndexMarker203"/> are classified<a id="_idIndexMarker204"/> with EPSS (<a href="https://www.first.org/epss/">https://www.first.org/epss/</a>). MITRE ATT&amp;CK is a database for classifying known exploits to computer systems and <span class="No-Break">networks (</span><a href="https://attack.mitre.org/"><span class="No-Break">https://attack.mitre.org/</span></a><span class="No-Break">).</span></p>
			<p>So, MITRE is the organization that helps cybersecurity<a id="_idIndexMarker205"/> professionals of all kinds understand vulnerabilities and exploits. The knowledge in MITRE’s databases grows constantly, every day. MITRE’s databases are on the web, freely available for anyone to use as a reference. As a cloud pentester, your job is to discover vulnerabilities and exploits in the cloud networks you test so that the organization you work for can better understand how to improve the security of its networks and applications. Let’s explore MITRE and how it maintains knowledge that’s useful for pentesters and <span class="No-Break">red teamers.</span></p>
			<h2 id="_idParaDest-59"><a id="_idTextAnchor058"/>Vulnerabilities</h2>
			<p>A vulnerability<a id="_idIndexMarker206"/> is a bug, flaw, or mistake in a computer system that cyber attackers can exploit to harm your organization’s data. For example, if someone from the general public can access customers’ credit card numbers through your organization’s cloud platform-hosted e-commerce web application by clicking on a button, that’s definitely a major security vulnerability. That would be a vulnerability to the confidentiality of sensitive data, according to the CIA Triad <span class="No-Break">of cybersecurity.</span></p>
			<p>If no one in the cybersecurity community knows about a vulnerability and a cyber criminal exploits it in a cyber attack, we call it a zero-day vulnerability. If we’re lucky, a security researcher or bug bounty hunter discovers a previously unknown vulnerability before a cyber attacker gets to exploit it. That’s a zero-day vulnerability as well. If a vulnerability is recorded in MITRE’s CVE database, it’s not a zero-day vulnerability; it’s a <span class="No-Break">known vulnerability.</span></p>
			<p>An exploit is a method or technique used to conduct a cyber attack. For example, here’s a description of an FTP exploit in MITRE’s ATT&amp;CK <span class="No-Break">database (</span><a href="https://attack.mitre.org/techniques/T1071/002/"><span class="No-Break">https://attack.mitre.org/techniques/T1071/002/</span></a><span class="No-Break">):</span></p>
			<p>“<em class="italic">Adversaries may communicate using application layer protocols associated with transferring files to avoid detection/network filtering by blending in with existing traffic. Commands to the remote system, and often the results of those commands, will be embedded within the protocol traffic between the client </em><span class="No-Break"><em class="italic">and server.</em></span></p>
			<p><em class="italic">Protocols such as FTP, FTPS, and TFTP that transfer files may be very common in environments. Packets produced from these protocols may have many fields and headers in which data can </em><span class="No-Break"><em class="italic">be concealed.</em></span><span class="No-Break">”</span></p>
			<p>When you conduct <a id="_idIndexMarker207"/>cloud pentests for your organization, you may find many vulnerabilities in its cloud network that are in MITRE’s CVE database. You might possibly discover a zero-day vulnerability, but that’s rare! Usually, zero-day vulnerabilities are discovered by bug bounty hunters, or by defensive security specialists once a cyber attacker has exploited it. Don’t be hard on yourself if you never discover a zero-day vulnerability as a red teamer or pentester. Your job is to find vulnerabilities in your organization’s computer systems, and those vulnerabilities will be known to the cybersecurity community most of <span class="No-Break">the time.</span></p>
			<p>And as a red teamer especially, you may be simulating cyber exploits according to what’s in <span class="No-Break">MITRE ATT&amp;CK.</span></p>
			<p>So, looking stuff up in MITRE’s databases will certainly be a part of your job you’ll do <span class="No-Break">quite frequently.</span></p>
			<p>Let’s understand MITRE <a id="_idIndexMarker208"/>as an organization and how it maintains cybersecurity information for <span class="No-Break">the public.</span></p>
			<h2 id="_idParaDest-60"><a id="_idTextAnchor059"/>The MITRE database</h2>
			<p>MITRE was founded in 1958 as a private, not-for-profit<a id="_idIndexMarker209"/> organization to work with the US Air Force. Decades before cloud networks and before the internet became a part of our everyday lives, MITRE<a id="_idIndexMarker210"/> collaborated with the US government through departments such as the <strong class="bold">Federal Aviation Administration</strong> (<strong class="bold">FAA</strong>) to develop air traffic control systems and conduct research and development in areas including computer programming and data processing. In the 1990s, MITRE helped the US government prepare for the “Y2K bug.” The “Y2K bug” was a problem many computer systems around the world had. Many databases, applications, and operating systems only had two characters for the year in computer timestamps and time-keeping. So, when the year 2000 came, those systems might think it was the year 1900, therefore causing serious operational problems. Many organizations, MITRE included, worked very hard in the 1990s to fix the “Y2K bug.” And that’s why there weren’t many problems when the year 2000 <span class="No-Break">finally happened.</span></p>
			<p>MITRE started its CVE database in 1999. In that year, only 321 vulnerabilities were recorded. However, the CVE database steadily grew, not only by adding more vulnerability records each year but also in terms of the rate at which vulnerabilities were recorded. The year 2003 added 1,223 records. The year 2008 added 5,673 records. 14,645 records were added in 2017. And a whopping 25,059 records were added in 2022. Applications might not be less secure these days. Maybe applications have gotten more complex and the routines the cybersecurity community engages in to find vulnerabilities <span class="No-Break">have improved.</span></p>
			<p>In 2013, MITRE launched ATT&amp;CK, their database<a id="_idIndexMarker211"/> for exploits that they describe as “<em class="italic">globally-accessible knowledge base of adversary tactics and techniques based on </em><span class="No-Break"><em class="italic">real-world observations</em></span><span class="No-Break">”(</span><a href="https://attack.mitre.org/"><span class="No-Break">https://attack.mitre.org/</span></a><span class="No-Break">).</span></p>
			<p>Let’s examine the <span class="No-Break">CVE database.</span></p>
			<h2 id="_idParaDest-61"><a id="_idTextAnchor060"/>How do vulnerabilities get recorded in the CVE database?</h2>
			<p>MITRE works<a id="_idIndexMarker212"/> with a large number of <strong class="bold">CVE Numbering Authorities</strong> (<strong class="bold">CNAs</strong>). As of April 2023, there are 285 CNAs. The vast majority of CNAs<a id="_idIndexMarker213"/> are tech companies that produce software, hardware, and infrastructure that could have security vulnerabilities. Some examples of CNAs are Qualcomm (a producer of semiconductor chips), Airbus (an aircraft manufacturer), and FreeBSD (an operating system developer). Also, many of the big names most people are familiar with are CNAs: Microsoft, Apple, and Google, <span class="No-Break">for example.</span></p>
			<p>Some large tech companies have bug bounty programs. A bug bounty program lets members of the general public (outsiders who don’t work for the tech company) report security vulnerabilities they’ve discovered. They must abide by the company’s responsible disclosure policies, which generally means they report their vulnerability discovery to a certain individual or department within the company, and they’re not supposed to make their discovery public knowledge. This gives the company an opportunity to fix the vulnerability without cybercriminals finding out and using that knowledge to conduct a <span class="No-Break">cyber attack.</span></p>
			<p>If the bug bounty<a id="_idIndexMarker214"/> hunter abides by the rules of the company’s bug bounty program and the company considers the bug bounty hunter’s discovery to be legitimate and useful, they may pay the bug bounty hunter anywhere from a few hundred dollars to over $100,000. The payout depends on how much the company has decided to reward for vulnerabilities and how important they consider the vulnerability to be. <em class="italic">HackerOne</em> maintains a database<a id="_idIndexMarker215"/> of most of the bug bounty programs out <span class="No-Break">there (</span><a href="https://hackerone.com/bug-bounty-programs"><span class="No-Break">https://hackerone.com/bug-bounty-programs</span></a><span class="No-Break">).</span></p>
			<p>Being a bug bounty hunter is very different from being a pentester or a red teamer. Pentesters and red teamers are given specific pentesting assignments with well-defined scopes. Bug bounty hunters are outsiders who may find whatever kind of vulnerabilities they’re interested in or good at finding, as long as they work according to the rules of a company’s bug bounty program and don’t engage in any cyber attacks. Pentesting and red teaming is like being a chef in a restaurant; being a bug bounty hunter is like donating food to a food bank. And only bug bounty hunters have to find zero-day vulnerabilities, whereas pentesters and red teamers have to find whichever vulnerabilities they discover within the scope the organization they work for assigns them by simulating <span class="No-Break">cyber attacks.</span></p>
			<p>Quite often, records enter the CVE database through bug bounty programs. If, for example, a bug bounty hunter finds a vulnerability in Windows 11, the bug bounty hunter must abide by Microsoft’s bug bounty program. Then, Microsoft enters the vulnerability into the CVE database in its role as <span class="No-Break">the CNA.</span></p>
			<p>Sometimes, employees and contractors for particular tech companies that are CNAs discover zero-day vulnerabilities. The tech company as a CNA will record the vulnerability in the CVE in the same way as if it came from a bug <span class="No-Break">bounty hunter.</span></p>
			<p>It’s the responsibility of the CNAs to make sure the vulnerabilities they discover in their products and services or the vulnerabilities in their products and services that are reported to them are recorded in the CVE database. CNAs usually won’t record vulnerabilities that don’t pertain to their own products and services. For instance, it’s not Apple’s responsibility to record vulnerabilities in the Android version of Mozilla Firefox, but it may be Apple’s responsibility to record vulnerabilities in the iOS version of Firefox. Or, it might be Mozilla’s responsibility. Or, it might be both Apple’s and Mozilla’s responsibility, depending on which parts of their products <span class="No-Break">are affected.</span></p>
			<p>CVE records usually aren’t made as soon as a CNA discovers a vulnerability. CVE records are public knowledge, and a tech company might need a few months or a year to address the vulnerability privately. When it’s safe to make the vulnerability public knowledge, that’s often when a CVE record <span class="No-Break">is published.</span></p>
			<p>Quite often as a pentester, you might<a id="_idIndexMarker216"/> find that your organization’s network has vulnerabilities that are a few years old. For instance, you might find a vulnerability that has a CVE record from 2018. The CNA may have a security patch for the vulnerability, but your organization hasn’t installed it, or the vulnerability might be public knowledge but very difficult to patch or mitigate. As a pentester, finding zero-day vulnerabilities isn’t really your job, and many of the vulnerabilities you discover may have been known by the technology vendor <span class="No-Break">for years!</span></p>
			<p>Here’s an example of a real-life <span class="No-Break">CVE record.</span></p>
			<p>CVE-2022-3349 is a vulnerability in Sony’s PS4 and PS5 video game consoles. That’s the format each CVE record uses for identification: CVE, then a four-digit year, then a four-digit number that’s unique to <span class="No-Break">the year.</span></p>
			<p>The record contains a basic description of <span class="No-Break">the vulnerability:</span></p>
			<p class="author-quote">“A vulnerability was found in Sony PS4 and PS5. It has been classified as critical. This affects the function <strong class="source-inline">UVFAT_readupcasetable</strong> of the component <strong class="source-inline">exFAT</strong> Handler. The manipulation of the argument <strong class="source-inline">dataLength</strong> leads to heap-based buffer overflow. It is possible to launch the attack on the physical device. It is recommended to upgrade the affected component. The associated identifier of this vulnerability is VDB-209679.”</p>
			<p>Then, a list of references to the vulnerability is shown, usually as web hyperlinks to published reports external to the <span class="No-Break">CVE database.</span></p>
			<p>Next, the assigning CNA is named. In this record, it’s VulDB. VulDB is a third-party vulnerability database. For whatever reason, Sony isn’t a CNA. So, third-party Sony trusts handle the responsibility of adding vulnerabilities in Sony products and services to the <span class="No-Break">CVE database.</span></p>
			<p>Next, the date the record was created is shown. In this record, it’s 20220928. That means September 28th, 2022. This disclaimer is mentioned: “<em class="italic">The record creation date may reflect when the CVE ID was allocated or reserved, and does not necessarily indicate when this vulnerability was discovered, shared with the affected vendor, publicly disclosed, or updated in CVE.</em>” As I mentioned, there may be a few months or a year or so between when the vulnerability was discovered and when it was added to the CVE database. That’s usually to give the vendor (the tech company the vulnerability impacts) time to address the vulnerability before it becomes public knowledge, in order to prevent <span class="No-Break">cyber attacks.</span></p>
			<p>For more information about <em class="italic">CVE-2022-3349</em> (and other CVE records), you need to go to NIST’s NVD. The NVD has web pages for most of CVE’s records. See <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-3349">https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-3349</a> <span class="No-Break">and</span><span class="No-Break"><span class="hidden"> </span></span><a href="https://nvd.nist.gov/vuln/detail/CVE-2022-3349"><span class="No-Break">https://nvd.nist.gov/vuln/detail/CVE-2022-3349</span></a><span class="No-Break">.</span></p>
			<p>Here’s the information NVD has about CVE-2022-3349 (<a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-3349">https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-3349</a>). There’s a CVSS score. CVSS rates vulnerabilities<a id="_idIndexMarker217"/> between 0.0 and 10.0. Lower numbers are less critical, which means the vulnerabilities are less dangerous if a cyber attacker exploits them. Higher numbers are more critical and more dangerous if a cyber attacker exploits them! <em class="italic">CVE-2022-3349</em> is rated 6.8 (medium) under the CVSS version 3.X <span class="No-Break">rating scale.</span></p>
			<p>Then, NVD lists “<em class="italic">References to Advisories, Solutions, and Tools</em>.” This is similar to the web hyperlink references in CVE’s own database. In fact, CVE and NVD often cross-reference the references—they might be the same hyperlinks in both versions of <span class="No-Break">the record.</span></p>
			<p>Finally, the NVD lists “<em class="italic">Weakness Enumeration</em>.” Those are links to MITRE’s <strong class="bold">Common Weakness Enumeration</strong> (<strong class="bold">CWE</strong>) database, what MITRE calls “<em class="italic">a community-developed list of software and hardware weakness types</em>.” Weaknesses are the types of flaws a vulnerability<a id="_idIndexMarker218"/> may have. NVD’s record for <em class="italic">CVE-2022-3349</em> lists <span class="No-Break">these CWEs:</span></p>
			<ul>
				<li>CWE-787, <span class="No-Break">Out-of-bounds Write</span></li>
				<li>CWE-122, Heap-based <span class="No-Break">Buffer Overflow</span></li>
				<li>CWE-119, Improper Restriction of Operations within the Bounds of a <span class="No-Break">Memory Buffer</span></li>
			</ul>
			<p>Let’s look at the two frequently<a id="_idIndexMarker219"/> used CVSS <span class="No-Break">scoring scales.</span></p>
			<p>CVSS v2.0 is the older scale. Vulnerabilities scored 0.0 to 3.9 are classified as “low,” 4.0 to 6.9 are classified as “medium,” and 7.0 to 10.0 are classified as “high.” The newer CVSS v3.0 has more categories. 0.0 always means that a vulnerability isn’t at all dangerous. I don’t think any vulnerabilities have a CVSS v3.0 score of 0.0; the number just exists as a concept to help quantify the rest of the scale. Vulnerabilities rated 0.1 to 3.9 are “low,” 4.0 to 6.9 are “medium.” 7.0 to 8.9 are “high,” and 9.0 to 10.0 are “critical.” Whichever CVSS version is used, higher numbers are more dangerous vulnerabilities and lower numbers are less dangerous vulnerabilities. You will be expected to help write pentest reports as a pentester or red teamer. You should mention CVSS scores in your report, and the CVSS scores will help your organization determine which vulnerabilities are most important to <span class="No-Break">address first.</span></p>
			<p>Finally, there’s EPSS. The EPSS is maintained by FIRST. In its words, FIRST “<em class="italic">aspires to bring together incident response and security teams from every country across the world to ensure a safe internet </em><span class="No-Break"><em class="italic">for all.</em></span><span class="No-Break">”</span></p>
			<p>FIRST uses EPSS<a id="_idIndexMarker220"/> to describe the likelihood or probability that a vulnerability will be exploited by cyber attackers. FIRST recognizes that there are too many vulnerabilities to fix immediately, and vulnerabilities are often recorded in the CVE database before a vulnerability is completely addressed. Some vulnerabilities are extremely difficult to fix completely. So, FIRST uses EPSS to determine whether a known vulnerability is likely to be exploited, and how likely it will be exploited. FIRST says that only 2% to 7% of known vulnerabilities are “<em class="italic">exploited in </em><span class="No-Break"><em class="italic">the wild</em></span><span class="No-Break">.”</span></p>
			<p>EPSS scores are given a percentage number, from 0% to 100%. 0% is a vulnerability that will never be exploited, and 100% is a vulnerability that will definitely be exploited and probably has been exploited lots of times already. According to FIRST, the vast majority of vulnerabilities score below 25%, and many <span class="No-Break">below 10%.</span></p>
			<p>FIRST recommends that pentesters and defensive security specialists triage vulnerabilities according to both CVSS and EPSS. So, a vulnerability with a CVSS score of 9.8 and EPSS score of 97% should definitely be addressed right away, as soon as possible, and given the absolute top priority. If a vulnerability has a CVSS score of 9.9 but an EPSS score of 2%, you may want to wait until vulnerabilities with higher EPSS scores are addressed first, even though exploiting the vulnerability would be <span class="No-Break">very dangerous.</span></p>
			<p>So, now that we know how information about vulnerabilities and exploits is recorded in public databases, we’re ready to understand how to write effective pentest reports and how to engage in purple<a id="_idIndexMarker221"/> teaming. Purple teaming<a id="_idIndexMarker222"/> is when the red team works with the blue team—the defensive <span class="No-Break">security specialists.</span></p>
			<h1 id="_idParaDest-62"><a id="_idTextAnchor061"/>Purple teaming and writing pentest reports</h1>
			<p>As a cloud pentester, you will spend<a id="_idIndexMarker223"/> anywhere from a few days to multiple months on a single<a id="_idIndexMarker224"/> engagement, whether you’re a third-party contractor to the organization you’re working for or a part of the organization’s internal red team. Your objective is to work within your organization’s contractually defined scope to find as many security vulnerabilities as you can while performing simulated cyber attacks your organization and the cloud providers (AWS, Azure, GCP) permit you <span class="No-Break">to do.</span></p>
			<p>So, over the course of those days, weeks, or months, you may have found several vulnerabilities. Most of them are vulnerabilities that the cybersecurity community is familiar with, with extensive records in the CVE database, NIST’s NVD, and in the security alerts and patch notes of the vendors (tech companies that provide products and services to your organization) to which the vulnerabilities you’ve found pertain. Maybe some of the vulnerabilities you’ve discovered are simply common examples of poor security configuration, such as leaving Windows’ RDP enabled when it’s never used. That should have been found in a vulnerability assessment. But at least you were able to catch it! Or, maybe you’ve found a number of other commonly found cybersecurity problems in <span class="No-Break">the enterprise.</span></p>
			<p>That’s great! You’ve worked very hard over a period of time, and you and your team have found a bunch of terrible cybersecurity problems that can only be found by performing effective and appropriate penetration tests. (Well, except for the unnecessarily enabled RDP. Why didn’t your organization find that in a <span class="No-Break">vulnerability assessment?)</span></p>
			<p>Now, you can go back home, play some video games, or treat your romantic partner to a delicious gourmet meal to celebrate your accomplishments <span class="No-Break">at work.</span></p>
			<p>Hey, wait a second. What was the point of all that pentesting? Was it to show off your clever hacking skills? That’s great, and the company you work for was very impressed. You simulated cyber attacks<a id="_idIndexMarker225"/> that it thought only an APT could pull off. (<strong class="bold">APT</strong> stands for <strong class="bold">advanced persistent threat</strong>. It refers to a cybercrime group that can attack their targets for an extended period of time. They’re the most advanced type of cyber attackers, and they <span class="No-Break">are persistent!)</span></p>
			<p>But ultimately, the real reason why organizations hire pentesters and assemble red teams is that they need to find security vulnerabilities that a vulnerability assessment might miss so that they can <em class="italic">improve the security posture of </em><span class="No-Break"><em class="italic">their networks</em></span><span class="No-Break">.</span></p>
			<p>In order for them to be able to use the information you’ve found to improve the security posture of their networks, you’ll need to be able to communicate the information you’ve found effectively. That means engaging in purple teaming and writing a pentest report that’s easy for the defensive security specialists in your organization <span class="No-Break">to understand.</span></p>
			<p>Chances are that at some point in your life, you’ve seen a brilliant person trying to communicate their genius ideas in a way that no one around them <span class="No-Break">could understand.</span></p>
			<p>In order for your pentest to benefit<a id="_idIndexMarker226"/> the organization you work for, your goal should be to avoid being<a id="_idIndexMarker227"/> like that brilliant person who couldn’t communicate properly. You need to help the organization you work for understand the security problems that you’ve found, and perhaps even suggest some tips on how to <span class="No-Break">fix them.</span></p>
			<p>I’ve worked with many other pentesters over the years. There are a lot of very knowledgeable and highly skilled professional hackers out there. But only a minority of those people can purple team effectively and write good quality pentest reports. Anecdotally, I’ve found that the pentesters who are effective communicators have had successful careers for decades, whereas the pentesters who were ineffective communicators were more likely to lose <span class="No-Break">their jobs.</span></p>
			<p>If you can show your organization that you’ve found information about the security vulnerabilities in their network that they can use to measurably improve their security posture, you will be highly valued by them and you’ll probably have a <span class="No-Break">successful career.</span></p>
			<p>This book has lots of knowledge <a id="_idIndexMarker228"/>about pentesting tools and techniques that are effective<a id="_idIndexMarker229"/> for pentesting AWS, Azure, and GCP, and being familiar with those tools and techniques is crucial to being a successful cloud pentester in your red team. But well-written pentest reports and effective purple teaming are just <span class="No-Break">as important.</span></p>
			<p>First, let’s learn about purple teaming and why it’s a practice that your organization <span class="No-Break">will require.</span></p>
			<h2 id="_idParaDest-63"><a id="_idTextAnchor062"/>Purple teaming</h2>
			<p>Purple teaming <a id="_idIndexMarker230"/>is a relatively recent concept <span class="No-Break">in cybersecurity.</span></p>
			<p>The red team is a group of <em class="italic">offensive</em> security specialists. Their job is to replicate the particular tools and techniques that specific threat actors may engage in, which they may use to attack your organization. Their engagements may last months at a time. They are engaging in offensive cybersecurity, playing the simulated cyber attacker role for the benefit of your organization. Unlike an ordinary pentest, they have to be particular to mimic a specific attacker, such as a recognized <span class="No-Break">APT group.</span></p>
			<p>The blue team is a group of <em class="italic">defensive</em> security specialists. Their job is to look for new ways to improve the security posture<a id="_idIndexMarker231"/> of their organization, each and every day that they work. <strong class="bold">Security operations center</strong> (<strong class="bold">SOC</strong>) analysts, digital forensics specialists, and the <strong class="bold">incident response</strong> (<strong class="bold">IR</strong>) group in general all work in areas<a id="_idIndexMarker232"/> of defensive cybersecurity. But a proper blue team is always curious about the latest cyber threats and techniques, and it designs its security hardening work according to what it learns <span class="No-Break">that way.</span></p>
			<p>If you’ve ever had fun with mixing paint and color theory, you know that mixing red and blue pigment makes purple. So, purple teaming is a combination of what the red team does and what the blue <span class="No-Break">team does.</span></p>
			<p>My friend Daniel Miessler is one of the top thought leaders in the area of purple teaming, and a pioneer of the concept. According to Miessler, a purple team is created when red team members and blue team members collaborate with each other effectively. Some organizations might consider creating a dedicated purple team as an alternative to encouraging their red teams and blue teams to communicate and cooperate better. That probably wouldn’t work <span class="No-Break">very well.</span></p>
			<p>Miessler’s analogies for why dedicated purple teams are a bad idea are based on a professional restaurant kitchen. If a restaurant finds its waitstaff has trouble getting food from the kitchen to its diners, the solution isn’t to hire a new team of “kitchen-to-table coordinators.” The solution is to find ways to get the waitstaff to serve food effectively. If a restaurant has an elite chef who thinks their meal creations are too exquisite for diners to appreciate, no amount of culinary skill will make the restaurant popular. The chef may keep their dishes in the kitchen, and restaurants fail if diners aren’t served. So, if you’re a red team member who doesn’t value cooperating with the blue team, your skill and talent will benefit <span class="No-Break">no one.</span></p>
			<p>So, the craft of purple<a id="_idIndexMarker233"/> teaming is all about effective teamwork and communication skills. These aren’t really technical skills; they’re people skills. It’s also crucial to be humble as a red team member and be willing to listen and learn from your blue team. I’ve seen a lot of huge egos in this industry—don’t become one <span class="No-Break">of them!</span></p>
			<p>GitLab conducts a lot of purple teaming engagements. Their workflow goes <span class="No-Break">like this.</span></p>
			<p>First, there’s the attack planning phase, in which both the red team and the blue team have equal ownership. They have a brainstorming<a id="_idIndexMarker234"/> session where they propose and discuss a possible cyber threat, perhaps using <strong class="bold">threat intelligence</strong> (<strong class="bold">TI</strong>) or new threat detection capabilities for inspiration. Next, they’ll discuss the logistics of the operation (responsibilities, timelines, and so on) and profile the attacker they plan to replicate. What sort of C2 servers might they have? Which tactics and techniques might they use? What are the attacker’s goals? Then, they’ll conduct a tabletop scenario, which is a popular activity for defensive security specialists. It’s kind of like playing a tabletop roleplaying <a id="_idIndexMarker235"/>game, except they’ll use it to review real-world threat actor <strong class="bold">tactics, techniques, and procedures</strong> (<strong class="bold">TTPs</strong>). If the attacker uses those TTPs, how would the blue team react in IR? How could those TTPs harm their organization’s network <span class="No-Break">and data?</span></p>
			<p>The attack emulation<a id="_idIndexMarker236"/> phase is where the red teams and blue teams focus on their duties separately. The red team will test the infrastructure and tooling required to execute its TTPs. The red team will then simulate cyber attacks using those TTPs, like a targeted pentest. While the red team simulates attacks, the blue team will validate the expected outcomes of those (<span class="No-Break">simulated) attacks.</span></p>
			<p>The final phase is the conclusion of the operation. The red team prepares and shares its pentest report. And then, the red team and blue team come together to discuss the details of what happened. What worked? What could’ve been <span class="No-Break">done better?</span></p>
			<p>There are many ways<a id="_idIndexMarker237"/> to conduct purple teaming. GitLab’s workflow is one model. SCYTHE has publicly shared its own model, the <strong class="bold">Purple Team Exercise </strong><span class="No-Break"><strong class="bold">Framework</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">PTEF</strong></span><span class="No-Break">).</span></p>
			<p>The workflow of SCYTHE’s framework goes like this. Under the direction of an exercise coordinator, the red team and blue team come together to discuss a particular threat actor, the threat actor’s TTPs, and the associated technical details. Then, the red team and the blue team are equal collaborators in a tabletop simulation or discussion of the TTPs and your organization’s security controls. If the offensive side does something specific, how would the defensive side respond? Then, the red team simulates the attacker’s TTP while the blue team watches carefully. The blue team probably should be taking notes. Then, the blue team detects and responds to the red team’s TTP simulations; everything it’s doing should be viewable by the red team. The detection engineering step has the blue team tweaking its security controls and improving its network security event logging to increase its visibility of the simulated attack from the red team. Finally, the red team and blue team come together to repeat their procedure, record their results, and then move on to the next TTP simulation—a new purple <span class="No-Break">team exercise.</span></p>
			<p>If you’re simply working for your organization in the capacity of being a pentester, purple teaming workflows aren’t really relevant to you. However, you must still be mindful of respecting the needs of your organization’s defensive security specialists and communicating effectively <span class="No-Break">with them.</span></p>
			<p>If you are a part of a proper red team, those examples of how purple teaming is done in organizations can serve as a model for your work. If your company doesn’t already have purple teaming procedures in place and agreed upon with the blue team, encourage purple teaming procedures to become established. If you can explain the importance of effective collaboration with the defensive security group with the leaders of your security team, your efforts will be well worth it. You may need to make a strong case about the importance of proper purple teaming to your supervisors, but your initiative will probably<a id="_idIndexMarker238"/> <span class="No-Break">be rewarded.</span></p>
			<p>Now, on to something you’ll probably be expected to do, whether or not you’re part of a red team. Let’s learn about writing effective <span class="No-Break">pentest reports!</span></p>
			<h2 id="_idParaDest-64"><a id="_idTextAnchor063"/>Writing pentest reports</h2>
			<p>If you’re not good<a id="_idIndexMarker239"/> at creative writing, your pentesting team will be okay if at least one of your pentesting colleagues is good at it. As long as everyone in your pentesting team can communicate with each other effectively in other ways, you can simply delegate the task of writing the pentest report to the best writer on your team. Of course, if you’re pentesting as a team, your pentest report is a group effort. Findings from everyone should be included in the report. The writer of your pentest report will need all of your findings, and you’ll need to be able to explain what you did and what happened when the writer asks you about it. You should also take good care of the logs from whatever tools you used during your pentest because you’ll need to use them as a reference in <span class="No-Break">your report.</span></p>
			<p>But if you’re a solo pentester, then the responsibility for writing the pentest report is entirely yours! This is an example of how pentesters need more than technical skills; they also need creative and <span class="No-Break">communications skills.</span></p>
			<p>So, let’s examine what your organization will expect from your <span class="No-Break">pentest report.</span></p>
			<p>All good pentest reports must include <span class="No-Break">the following:</span></p>
			<ul>
				<li>An executive summary at the beginning of <span class="No-Break">the report.</span></li>
				<li>A definition of the scope of your pentest. This is the “what” of your test. What exactly was the subject of <span class="No-Break">your test?</span></li>
				<li>A thorough and detailed explanation of the methodology of your pentest. This is the “how” of <span class="No-Break">your test.</span></li>
				<li>A list of the vulnerabilities your pentest discovered. These should probably be triaged with the most critical vulnerabilities at the beginning and the least critical vulnerabilities at <span class="No-Break">the end.</span></li>
				<li>An analysis of the impact the vulnerabilities you discovered could have on your organization if they’re exploited. This part is absolutely crucial, because if your organization doesn’t understand the harm that could occur if the vulnerabilities aren’t addressed, then why should <span class="No-Break">they care?</span></li>
				<li>Advice for how to remediate the specific vulnerabilities your pentest discovered. Go one by one, vulnerability <span class="No-Break">by vulnerability.</span></li>
			</ul>
			<p>Recommend how your organization’s security<a id="_idIndexMarker240"/> strategies can be improved. This goes beyond remediating specific vulnerabilities. You need to make recommendations for how your organization can improve its security posture as a whole. For instance, if most of the vulnerabilities you successfully exploited have been in the CVE database for more than a decade, you could recommend that it improves its patch management and works on replacing legacy tech with more modern hardware <span class="No-Break">and software.</span></p>
			<p>There’s a good reason why the executive summary should be at the beginning of your report rather than the end. The executive summary is for the <em class="italic">executives</em>. They’re usually people with a lot of power and influence in your organization, but they aren’t <span class="No-Break">particularly technical.</span></p>
			<p>They’re also very busy people. On their list of priorities, reading your pentest report is probably number 27 for the day. They’re not going to spend hours reading your report. If you’re lucky, they’ll give it 5 minutes. Therefore, the executive summary needs to be at the beginning, and it needs to be concise. The executive summary should be a page or two, and that’s it. If you go by word count, aim for 300 to 600 words. It’s unlikely the executives will read more <span class="No-Break">than that.</span></p>
			<p>In your executive summary, just explain what you pentested and what patterns you found in the results of your pentest or what the most significant problems you discovered were. Here’s <span class="No-Break">an example:</span></p>
			<p>“<em class="italic">We tried to see if we could access the organization’s microservices that are hosted on Amazon EC2 instances through code injection exploits in the e-commerce web interface. It worked and we acquired unauthorized access through these APIs and we were able to access sensitive data. This is how those vulnerabilities could harm the company if they’re exploited. And this is how much money the company could lose in a successful real-world </em><span class="No-Break"><em class="italic">cyber attack.</em></span><span class="No-Break">”</span></p>
			<p>Replace each instance of “<em class="italic">this</em>” with some of your actual pentest findings. And I’m a strong believer in mentioning estimated dollar figures of the harm those cyber attacks could do to the company. That’s what your executives care about the most—money. Getting credible financial risk data is easier than you might think. For instance, if the likely impact of vulnerability exploitation<a id="_idIndexMarker241"/> is data breaches, you can get approximate dollar figures from IBM’s <em class="italic">Cost of a Data Breach Report</em> (<a href="https://www.ibm.com/reports/data-breach">https://www.ibm.com/reports/data-breach</a>). For ransomware, you could cite the following <span class="No-Break">report: </span><a href="https://www.cybereason.com/ransomware-the-true-cost-to-business-2022"><span class="No-Break">https://www.cybereason.com/ransomware-the-true-cost-to-business-2022</span></a><span class="No-Break">.</span></p>
			<p>The rest of your report<a id="_idIndexMarker242"/> is for the cybersecurity specialists in your organization to read. As long as the executive summary is short, the rest of your report can be however long it needs to be in order to include all of the important technical details. The length of your report will vary depending on how much you did during your pentest. But pentest reports are rarely over 100 pages. Most are between 20 and <span class="No-Break">70 pages.</span></p>
			<p>Explain the scope of your pentest. “<em class="italic">We tested this particular DevOps network.</em>” “<em class="italic">We tested this particular web application.</em>” “<em class="italic">We tested this particular network segment.</em>” But of course, you’ll need to provide more detail for the scope of your test. Cite network addresses, IP addresses, or whichever identifiers are applicable so that the security team knows exactly what <span class="No-Break">you tested.</span></p>
			<p>The methodology section also should be detailed and specific. You should explain step by step the exact actions you conducted in your test in chronological order. Name the tools you used, the exploits you simulated, and the techniques you attempted. When in doubt, err on the side of being more detailed rather than less. You may want to cite MITRE’s ATT&amp;CK database (<a href="https://attack.mitre.org/">https://attack.mitre.org/</a>) to name specific exploitation techniques. It’s a freely and publicly available resource on <span class="No-Break">the web.</span></p>
			<p>Next, you need to present the vulnerabilities your pentest discovered. Every single vulnerability you discovered must be included. Cite specific CVEs wherever they’re applicable. I recommend presenting the vulnerabilities in order from most critical to least critical. Mention both CVSS scores and EPSS scores. Weigh the criticality of each vulnerability according to a combination of both CVSS and EPSS. For instance, if there are several vulnerabilities with CVSS scores of 7.0 to 9.0, the ones with an EPSS of 30% should go first, and the ones<a id="_idIndexMarker243"/> with an EPSS of 10% should go after. MITRE’s CVE database (<a href="https://cve.org">https://cve.org</a>), NIST’s NVD<a id="_idIndexMarker244"/> database (<a href="https://nvd.nist.gov/">https://nvd.nist.gov/</a>), and FIRST’s EPSS database (<a href="https://www.first.org/epss/">https://www.first.org/epss/</a>) are all freely and publicly<a id="_idIndexMarker245"/> available on the web for you to find CVE numbers, CVSS scores, and <span class="No-Break">EPSS scores.</span></p>
			<p>Next, you need to provide<a id="_idIndexMarker246"/> remediation advice. Be specific. Mention patches that need to be installed, configurations and settings that need to be changed, and so on. This will vary according to the nature of <span class="No-Break">the vulnerabilities.</span></p>
			<p>You know the phrase “can’t see the forest for the trees”? It means someone is too focused on the details of a situation that they lose sight of the “big picture.” But in the case of your pentest report, your organization will have to see both the forest <em class="italic">and</em> the trees. The remediation advice section is the “trees,” and the security strategy improvement advice section is the “forest.” “<em class="italic">Upgrade and replace legacy tech.</em>” “<em class="italic">Hire a security operations center team.</em>” “<em class="italic">Improve your incident response plan.</em>” Those are the sorts of things that pertain to security strategy, but use details that apply to your particular organization and your <span class="No-Break">particular pentest.</span></p>
			<p>I recommend looking at some publicly available real-world pentest reports before you write one for the first time. Check out the collection of real pentest reports juliocesarfort maintains on GitHub (<a href="https://github.com/juliocesarfort/public-pentesting-reports">https://github.com/juliocesarfort/public-pentesting-reports</a>). There’s also a large collection on the pentestreports.com website (<a href="https://pentestreports.com/reports/">https://pentestreports.com/reports/</a>). If you want to go further than that, I gave a talk about writing effective pentest reports for <em class="italic">SANS Pen Test HackFest Summit 2021</em> titled <em class="italic">Writing Reports: The Overlooked Pen Testing Skill</em>. You can watch it on <span class="No-Break">YouTube (</span><a href="https://www.youtube.com/watch?v=r-6LBjlM14Y"><span class="No-Break">https://www.youtube.com/watch?v=r-6LBjlM14Y</span></a><span class="No-Break">).</span></p>
			<p>And there you have it. That’s why your pentest is conducted<a id="_idIndexMarker247"/> in the first place. You do it to find security vulnerability information, recommend a course of action, and help the defensive security team improve your organization’s <span class="No-Break">security posture.</span></p>
			<h1 id="_idParaDest-65"><a id="_idTextAnchor064"/>Summary</h1>
			<p>AWS, Azure, and GCP have pentesting policies that you and your organization must abide by. Benchmark checks verify the performance of your organization’s cloud services. Cloud provider SLAs are a good source of general benchmarks. CIS also has specific benchmarks for cybersecurity. Cloud service enumeration is a way that an attacker can find out information about how your organization uses cloud services. There are scripts you can execute to test your organization’s susceptibility <span class="No-Break">to vulnerabilities.</span></p>
			<p>Vulnerability assessments can be performed by vulnerability scanning applications. Before pentesting, it’s important to have a recent history of vulnerability assessments and mitigation for the findings of those assessments. Common security misconfigurations must be addressed first before your organization is ready <span class="No-Break">to pentest.</span></p>
			<p>Exposed services are internet services and ports in your organization’s cloud network that an attacker can use to cyber-attack it through the internet. It’s vital to make sure that proper access control measures are on all of these points in your public cloud so that no services are exposed. Permissions are an access control component—what are users and machines permitted to do in each application and service your organization has? Cloud integrations are when different cloud platforms in your network (AWS, Azure, GCP) connect with each other, or when any of those parts also connect with an on-premises network. It’s essential to secure cloud integrations because they can be especially vulnerable to <span class="No-Break">cyber attacks.</span></p>
			<p>Publicly known security vulnerabilities are recorded in MITRE’s CVE database. NIST records the same CVEs in its NVD database and assigns CVSS scores to them that determine how critical they are. FIRST assigns EPSS ratings to those same CVEs that indicate how likely it is that an attacker may <span class="No-Break">exploit them.</span></p>
			<p>As a pentester or red teamer, it’s essential for you to communicate and cooperate well with the defensive security team or blue team. Purple teaming is operations the red team and blue team perform together to find security vulnerabilities. Pentest reports should always be written for each and every pentest. They should effectively explain your vulnerability discoveries, their impact, and remediation advice for your organization’s executives and defensive <span class="No-Break">security team.</span></p>
			<p>In the next chapter, I’ll introduce you to AWS, Amazon’s cloud platform. You’ll learn about various AWS applications and services and why they’re used. We’ll also explore Amazon’s own built-in AWS security tools, and some third-party tools <span class="No-Break">as well.</span></p>
			<p>AWS is one of the most popular cloud platforms around. You may be surprised by how many different use cases AWS can support. AWS also has many very useful security controls that are important for cloud pentesters <span class="No-Break">to understand.</span></p>
			<h1 id="_idParaDest-66"><a id="_idTextAnchor065"/>Further reading</h1>
			<p>To learn more on the topics covered in this chapter, you can visit the <span class="No-Break">following links:</span></p>
			<ul>
				<li><em class="italic">Official AWS penetration testing </em><span class="No-Break"><em class="italic">policies</em></span><span class="No-Break">: </span><a href="https://aws.amazon.com/security/penetration-testing/"><span class="No-Break">https://aws.amazon.com/security/penetration-testing/</span></a></li>
				<li><em class="italic">Official Microsoft pentesting rules of </em><span class="No-Break"><em class="italic">engagement</em></span><span class="No-Break">: </span><a href="https://www.microsoft.com/en-us/msrc/pentest-rules-of-engagement"><span class="No-Break">https://www.microsoft.com/en-us/msrc/pentest-rules-of-engagement</span></a></li>
				<li><em class="italic">Official Google pentesting </em><span class="No-Break"><em class="italic">policies</em></span><span class="No-Break">: </span><a href="https://cloud.google.com/terms/aup"><span class="No-Break">https://cloud.google.com/terms/aup</span></a></li>
				<li><em class="italic">MITRE’s </em><span class="No-Break"><em class="italic">CVE database</em></span><span class="No-Break">:</span><ul><li><a href="https://cve.mitre.org/cve/"><span class="No-Break">https://cve.mitre.org/cve/</span></a></li><li><a href="https://www.cve.org/"><span class="No-Break">https://www.cve.org/</span></a></li></ul></li>
				<li><em class="italic">A full list of bug bounty programs through </em><span class="No-Break"><em class="italic">HackerOne</em></span><span class="No-Break">: </span><a href="https://hackerone.com/bug-bounty-programs"><span class="No-Break">https://hackerone.com/bug-bounty-programs</span></a></li>
				<li><em class="italic">NIST’s CVSS </em><span class="No-Break"><em class="italic">system</em></span><span class="No-Break">: </span><a href="https://nvd.nist.gov/vuln-metrics/cvss"><span class="No-Break">https://nvd.nist.gov/vuln-metrics/cvss</span></a></li>
				<li><em class="italic">FIRST’s EPSS </em><span class="No-Break"><em class="italic">system</em></span><span class="No-Break">: </span><a href="https://www.first.org/epss/"><span class="No-Break">https://www.first.org/epss/</span></a></li>
			</ul>
		</div>
	

		<div id="_idContainer011" class="Content">
			<h1 id="_idParaDest-67" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor066"/>Part 2:Pentesting AWS</h1>
			<p>Amazon’s AWS is one of the most popular cloud platforms. In this part, we will learn about AWS’s various software-as-a-service, platform-as-a-service, and infrastructure-as-a-service applications. We will deploy our own AWS instance in which to test our pentesting skills. We will use AWS Security Hub to check the security posture of our AWS deployment. We will also try out some pentesting tools in AWS, step by step. Then, we’ll deploy Docker and Kubernetes containers and test those <span class="No-Break">as well.</span></p>
			<p>This section has the <span class="No-Break">following chapters:</span></p>
			<ul>
				<li><a href="B18672_04.xhtml#_idTextAnchor067"><em class="italic">Chapter 4</em></a>, <em class="italic">Security Features in AWS</em></li>
				<li><a href="B18672_05.xhtml#_idTextAnchor080"><em class="italic">Chapter 5</em></a>, <em class="italic">Pentesting AWS Features through Serverless Applications and Tools</em></li>
				<li><a href="B18672_06.xhtml#_idTextAnchor101"><em class="italic">Chapter 6</em></a>, <em class="italic">Pentesting Containerized Applications in AWS</em></li>
			</ul>
		</div>
		<div>
			<div id="_idContainer012">
			</div>
		</div>
		<div>
			<div id="_idContainer013" class="Basic-Graphics-Frame">
			</div>
		</div>
	</body></html>