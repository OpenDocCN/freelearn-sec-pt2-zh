- en: '12'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pentesting Containerized Applications in GCP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If the organization you work for engages in DevOps or CI/CD application development,
    there’s an excellent chance that they have Docker or Kubernetes clusters in GCP.
    Let’s learn how to pentest them.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, I will explain what containerization is, why containerization
    is used, and how containerization works in general. We’ll learn how Docker and
    Kubernetes work in GCP and how to use Trivy with Docker- and Kubernetes-based
    applications in GCP.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: How containerization works
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How Docker works in GCP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How Kubernetes works in GCP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker and Kubernetes pentesting techniques in GCP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, let’s explore containerization in GCP!
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will work with Microsoft’s infrastructure. Massive Azure data centers will
    do the bulk of the computer processing work for the exercises in this chapter.
    So, fortunately, you don’t need to have a top-of-the-line workstation. You will
    need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A web browser
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A desktop or laptop PC
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An Android or iPhone mobile
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A good, reliable internet connection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Check out the following video to view the Code in Action: [https://bit.ly/404CEg8](https://bit.ly/404CEg8)'
  prefs: []
  type: TYPE_NORMAL
- en: How containerization works
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Virtualization in computing is all about software simulating the functions of
    hardware. For example, my laptop is one computer. But on my computer, I can run
    software that pretends to be several different computers at the same time. (Thank
    goodness I expanded the RAM in my laptop to 64 GB, because each of those simulated
    computers could need 4 GB of memory!) The CPU, RAM, disk drive, and I/O device
    interfaces for each of those computers are simulated in the software. The software
    uses my laptop’s real CPU, RAM, disk drive, and I/O interfaces and allocates their
    capacity to make several imaginary computers. When operating systems and applications
    are installed in those imaginary computers, as far as the operating systems and
    applications know, they are each running on their own physical computer.
  prefs: []
  type: TYPE_NORMAL
- en: There are two common ways to deploy virtualization on cloud networks—VMs and
    containers.
  prefs: []
  type: TYPE_NORMAL
- en: VMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: VMs are simulated computers, as I described in my example. Instead of directly
    running on PC or server machine hardware, a VM imitates all of the hardware components
    that are needed to run an operating system. In this model, my laptop runs a hypervisor
    that acts as a layer between the VMs and my physical computer.
  prefs: []
  type: TYPE_NORMAL
- en: You can use an application on your own PC, such as Oracle VirtualBox or VMware
    Workstation Player, to work as a hypervisor for your VMs. All you need is a disk
    image file of an operating system you’d like to run in your VM, and then to configure
    it in your hypervisor. The operating systems don’t have to match your host operating
    system, and very often they don’t. I could run a Kali Linux VM on my Windows 11
    PC. You could run a Windows 11 VM on your MacBook. And I could run a macOS VM
    on my Kubuntu Linux desktop.
  prefs: []
  type: TYPE_NORMAL
- en: VMs can also be run on cloud platforms such as GCP. Then, the virtualized computer
    is running on one of Google’s computers, not on a computer you can physically
    touch on your own premises. VMs are a common use case for GCP, and they’re a good
    solution when a company wants to run single computers on GCP for a long time,
    such as to use as a web server or an email server. A lot of the websites you visit
    every day are hosted on VMs run on cloud platforms such as GCP!
  prefs: []
  type: TYPE_NORMAL
- en: But VMs aren’t the best option when companies deploy massive dynamic applications,
    such as with DevOps or CI/CD methodologies that require them to be very scalable
    and responsive. The amount of computer processing power, memory, and network bandwidth
    a DevOps or CI/CD application requires could halve one day and double the next,
    whereas you can’t grow or shrink a VM’s hardware capacity as quickly or to the
    same extent. The hardware resources allocated to a VM are relatively static.
  prefs: []
  type: TYPE_NORMAL
- en: Enter containerization.
  prefs: []
  type: TYPE_NORMAL
- en: Containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Docker and Kubernetes are two containerization orchestration platforms commonly
    used by companies today. A containerization orchestration platform will automatically
    launch and kill containers without needing direct human interaction. These platforms
    manage how containers are deployed, and also handle the load balancing within
    the virtualized hardware, allocating hardware resources such as CPU and memory
    only as much as is needed.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud platforms have made containerized applications possible for companies
    and other sorts of enterprises. Google has massive computer networks and computer
    hardware resources in its various data centers around the world, a lot of which
    is dedicated to deploying GCP to its business customers all over the world.
  prefs: []
  type: TYPE_NORMAL
- en: How Docker works in GCP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker isn’t the first containerization technology to exist, but it’s probably
    the first to be widely used by companies and organizations around the world. It
    also serves as the foundation for Kubernetes, the other popular way to deploy
    containers. Docker and Kubernetes aren’t competitors like Coca-Cola and Pepsi.
    Rather, Kubernetes is kind of a fork of Docker, like comparing Debian Linux to
    Ubuntu Linux (which is based on Debian).
  prefs: []
  type: TYPE_NORMAL
- en: Here’s the basic architecture of a Docker containerization orchestration system
    (you can refer to [*Chapter 6*](B18672_06.xhtml#_idTextAnchor101) for the architecture
    diagram).
  prefs: []
  type: TYPE_NORMAL
- en: The Docker host runs directly on your computer or on the computer you manage
    on a cloud service (such as **Google Compute Engine**, or **GCE**). In the Docker
    host, the Docker daemon stores Docker images and makes and manages containers
    based on those images. Docker images are very much like disk image ISO files for
    operating systems that you can use to make VMs. In fact, many Docker images are
    made with ordinary operating systems such as Ubuntu Linux. However, the images
    and their containers may not have all of the operating system components, but
    only as much as is needed to run your containerized application.
  prefs: []
  type: TYPE_NORMAL
- en: The Docker host connects to a registry, which is usually (but not always) hosted
    on an external network that’s most often the internet. The registry makes Docker
    images available for your Docker host to download. The registry also maintains
    those images and updates them like any other internet-hosted software, kind of
    like a Git repository.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, a Docker client running in a place such as your GCP console or on your
    endpoint in Docker Desktop is where you can execute commands to your Docker daemon
    (under the umbrella of your Docker host) in order to manage it. That’s how you
    send instructions to your Docker containerization orchestration system. We will
    be executing commands that way to a Docker system in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The default way to deploy a Docker containerization system in GCP uses Cloud
    Build to simplify the Docker build steps, and Cloud Run to help run containerized
    apps, all while your Docker host runs in GCE.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s Google’s description of Cloud Build ([https://cloud.google.com/build](https://cloud.google.com/build)):'
  prefs: []
  type: TYPE_NORMAL
- en: “*Cloud Build scales up and down with no infrastructure to set up, upgrade,
    or scale. Run builds in a fully managed environment in Google Cloud with connectivity
    to your own private network*.”
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Build is a system that runs in the background when you deploy Docker containerization
    in GCP in the usual way. It spares developers the tedium of having to manage the
    servers that run your Docker containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'And here’s Google’s description of Cloud Run ([https://cloud.google.com/run/docs/overview/what-is-cloud-run](https://cloud.google.com/run/docs/overview/what-is-cloud-run)):'
  prefs: []
  type: TYPE_NORMAL
- en: “*Cloud Run allows developers to spend their time writing their code, and very
    little time operating, configuring, and scaling their Cloud Run service. You don’t
    have to create a cluster or manage infrastructure in order to be productive with
    Cloud Run*.”
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Run is another system that runs in the background when you deploy Docker
    containerization in the usual way in GCP. It spares developers from having to
    tweak the computer processing configurations that execute their Docker containers.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve looked at Docker in GCP, it’s time to learn about how Kubernetes
    works in GCP.
  prefs: []
  type: TYPE_NORMAL
- en: How Kubernetes works in GCP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes can be used to deploy containerized applications in AWS and Azure.
    In *Chapters 6* and *9*, I walked you through deploying Kubernetes on those platforms,
    and we pentested them. But GCP is arguably the home of Kubernetes. Here’s why.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes was originally developed by a team at Google. The Kubernetes project
    was announced by Google cloud computing specialist Eric Brewer in 2014 ([https://web.archive.org/web/20150910171929/http:/www.wired.com/2014/06/google-kubernetes](https://web.archive.org/web/20150910171929/http:/www.wired.com/2014/06/google-kubernetes)).
    Kubernetes was inspired by some of the containerization innovations pioneered
    by Docker. But Kubernetes was mainly influenced by Borg ([https://web.archive.org/web/20160701040235/http:/www.wired.com/2015/06/google-kubernetes-says-future-cloud-computing/](https://web.archive.org/web/20160701040235/http:/www.wired.com/2015/06/google-kubernetes-says-future-cloud-computing/)),
    which was proprietary in-house cloud computing middleware that Google wanted to
    keep for its own purposes. Borg helps to run the backend for Gmail, Google Search,
    Google Maps, and a number of other popular Google services.
  prefs: []
  type: TYPE_NORMAL
- en: Google’s Joe Beda, Brendan Burns, Brian Grant, Tim Hockin, and Craig McLuckie
    conceived of Kubernetes as being an open source platform that could be used for
    many of the same use cases Google deployed for Borg internally. By July 2015,
    the first version of Kubernetes was publicly released. By 2017, big tech companies
    and software developers including Red Hat (IBM), VMware, Docker, Inc., Microsoft
    Azure, and AWS all announced support for it. That’s the beauty of **open source
    software** (**OSS**) and open standards! And just as some organizations have multi-cloud
    networks that integrate services from AWS, Azure, and GCP, some organizations
    have both Docker and Kubernetes containerized applications.
  prefs: []
  type: TYPE_NORMAL
- en: Here’s the basic architecture of a Kubernetes containerization orchestration
    system (you can refer to [*Chapter 6*](B18672_06.xhtml#_idTextAnchor101) for the
    architecture diagram).
  prefs: []
  type: TYPE_NORMAL
- en: 'The control plane supports the entire containerization system and works as
    the vector between your Kubernetes-based network and the cloud platform, such
    as **Google Kubernetes Engine** (**GKE**) in GCP. The control plane contains a
    handful of components, including those listed here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**etcd** is a key-value store. It maintains data about all of your clusters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pods run with the support of nodes, and **kube-scheduler** assigns nodes to
    newly created Pods.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kube-apiserver** manages the Kubernetes API. So, it helps your Kubernetes-based
    application integrate with external applications. It’s also where **kubectl**
    (**ctl** stands for **command-line tool**) connects to in order to send commands
    to your Kubernetes system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kube-controller-manager** runs controller processes. There are controllers
    for maintaining nodes, controllers for executing scheduled jobs (such as “back
    up these files every day at 6 p.m.”), controllers to generate links between services
    and Pods, and controllers to create service accounts. Pods and nodes will be explained
    later in this section.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cloud-controller-manager** connects your Kubernetes network to your cloud
    provider’s APIs. In GCP, **cloud-controller-manager** usually interfaces with
    GKE.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Nodes* are the control plane’s children. There could be 2 nodes, 20 nodes,
    or many different numbers of nodes according to what your application needs at
    any given time. Each node contains a kubelet. The kubelet is a node agent that
    registers the node with the API server using a hostname or another sort of identifier
    specific to the cloud provider.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Pods* are the children of nodes, which also makes Pods the grandchildren of
    the control plane. The kubelet in each node defines the nodes according to a PodSpec,
    which is written as a YAML or JSON file. It helps to know that YAML is similar
    in some ways to HTML, and JSON was created for use with JavaScript—two technologies
    that were developed for the web. YAML and JSON files can be viewed in a text editor,
    and sometimes they only have a few lines of code. The vulnerability scans you’ll
    be running as a pentester and in your red team engagements will sometimes scan
    YAML and JSON files depending on the situation. But you don’t need to know how
    to write your own YAML or JSON files for the purposes of this book.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each Pod has a container runtime in which your containers run. Containers are
    made from container images that are like the ISO disk images of operating systems
    that are used in VMs. But a Kubernetes container image will have just the operating
    system components that are needed to execute the code that it’ll process. There
    are many default container images that can be used, and also, container images
    are sometimes custom-made for a particular company and its application.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the nodes (which contain Pods) interface with a load balancer, which
    helps manage the hardware and network resources that are needed at any given time.
    The load balancer also provides an interface between your Kubernetes-based application
    and your end users.
  prefs: []
  type: TYPE_NORMAL
- en: As a cloud pentester, it helps to know that both the load balancer and the API
    servers can be vectors for cyber attacks on your Kubernetes application! The load
    balancer is most often subject to cyber attacks from an Ingress, north-south direction
    between your cloud and external networks, and the API servers are more often subject
    to attacks from an east-west direction between components within your cloud network.
    Sometimes, cyber attacks enter from the public internet through the ingress route
    and then travel between parts of a cloud network using lateral movement that may
    involve privilege escalation. That’s kind of like a burglar breaking into a department
    store’s jewelry department and then moving on to the fragrances and cosmetics.
  prefs: []
  type: TYPE_NORMAL
- en: The entire Kubernetes containerization system is called a cluster. Some organizations
    may deploy multiple clusters. But no matter how many clusters an organization
    uses, each cluster is composed of a control plane, nodes, and Pods, in the order
    of bottom to top.
  prefs: []
  type: TYPE_NORMAL
- en: GKE ([https://cloud.google.com/kubernetes-engine](https://cloud.google.com/kubernetes-engine))
    is a GCP service that’s specially designed to run Kubernetes-based applications.
    It automates cluster and node management and how hardware resources are provisioned
    through the load balancer. The vast majority of the time, organizations both large
    and small will prefer to run Kubernetes applications in GCP through GKE.
  prefs: []
  type: TYPE_NORMAL
- en: The beauty of cloud computing and containerization is that applications can
    be made to be very scalable, dynamic, and efficient with hardware resources. A
    lot of the drudgery of application deployment and network management can be automated.
    So, it’s natural that organizations will prefer to use GKE so that they aren’t
    burdened with server management tasks. A containerized application in the cloud
    can literally double and halve within days. There should always be just as much
    computing power and bandwidth as is needed at any given time, and containers sometimes
    only have a lifespan of hours.
  prefs: []
  type: TYPE_NORMAL
- en: It’s no wonder that cloud computing has revolutionized how all kinds of organizations
    of all sizes and in all industries deploy applications through the internet. However,
    the containerized applications that organizations deploy through the cloud can
    be just as attractive targets to cyber attackers as VMs deployed through the cloud.
    They interface with the internet, which provides an access route for attackers.
    And they can contain sensitive information that can make cyber criminals a lot
    of money, such as sensitive financial data.
  prefs: []
  type: TYPE_NORMAL
- en: Your job as a cloud pentester is to make sure you discover how an attacker could
    harm your client’s cloud networks before an attacker tries to do it. That way,
    the company you work for can improve its security accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: So, in the final set of hands-on pentesting exercises in this book, let’s get
    into pentesting Docker and Kubernetes in GCP!
  prefs: []
  type: TYPE_NORMAL
- en: Docker and Kubernetes pentesting techniques in GCP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we understand Docker and Kubernetes, let’s deploy them in GCP. Then,
    we’ll pentest them. First, let’s deploy the Docker and Kubernetes clusters that
    we’ll practice pentesting in.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying Docker
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will use basic default Docker container images in our Docker deployment
    because we’re not doing anything fancy with it; we’re just trying out our pentesting
    tools! Follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: The simplest way for us to deploy a Docker cluster in GCP is to start with Cloud
    Run. Use your web browser to log in to the Google Cloud account we set up in [*Chapter
    11*](B18672_11.xhtml#_idTextAnchor197). Once you’re in the GCP web console, go
    to [https://console.cloud.google.com/run](https://console.cloud.google.com/run)
    to use Cloud Run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The Cloud Run screen should look something like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 12.1 – Cloud Run panel in the GCP console](image/B18672_12_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.1 – Cloud Run panel in the GCP console
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on **+CREATE SERVICE** at the top, just underneath the top menu bar.
    You’ll see a screen that looks like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.2 – Creating a Cloud Run service in GCP to run Docker](image/B18672_12_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.2 – Creating a Cloud Run service in GCP to run Docker
  prefs: []
  type: TYPE_NORMAL
- en: We will be using as many defaults as possible just to create a basic Docker
    environment to try our pentesting tools in. In situations where you may want to
    deploy a particular type of application with Docker containers, you may have to
    use different settings in Cloud Run.
  prefs: []
  type: TYPE_NORMAL
- en: 'To keep it simple, these are the options I chose for my Docker deployment in
    Cloud Run:'
  prefs: []
  type: TYPE_NORMAL
- en: At the top where it provides the **Deploy one revision from an existing container
    image** and **Continuously deploy new revisions from a source repository options**,
    I chose the first option.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, instead of entering a container image URL, I clicked on **TEST WITH A**
    **SAMPLE CONTAINER**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'On this screen, I clicked on the **CONTAINER REGISTRY** tab and chose the **hello**
    demo container. Then, I clicked on **SELECT** next to the container image URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.3 – Choosing a Docker image for our Docker instance](image/B18672_12_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.3 – Choosing a Docker image for our Docker instance
  prefs: []
  type: TYPE_NORMAL
- en: In the **Service name** field, I entered **crawleydockertest**. I left my default
    region, which in my case is **us-central1 (lowa)**. Your default region might
    be something else. Each region represents a particular Google data center, and
    it may not even be in your country.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To save money, under **CPU allocation and pricing**, I chose **CPU is only allocated
    during** **request processing**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I left the **Autoscaling** option alone. By default, **0** is the minimum number
    of instances and **100** is the maximum. This sort of setting reflects the scalable
    nature of cloud applications. New instances can be automatically generated according
    to your application’s needs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Under **Ingress control**, I selected **All**, which will allow direct access
    to your service from the internet.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Under **Authentication**, I chose **Allow unauthenticated invocations**. These
    options may not be the best practices for cybersecurity, but they make trying
    out pentesting tools in our Docker application a lot easier.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, I clicked on the blue **CREATE** button at the bottom.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Your web console screen will look like this as your service is created. The
    creation process took about 30 seconds for me; I wasn’t waiting very long:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 12.4 – Creating a service for our Docker instance](image/B18672_12_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.4 – Creating a service for our Docker instance
  prefs: []
  type: TYPE_NORMAL
- en: Now that our Docker environment has been created in GCP, it’s time to make a
    Kubernetes environment!
  prefs: []
  type: TYPE_NORMAL
- en: Deploying Kubernetes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It’s possible to deploy Kubernetes in Cloud Shell or in some other CLI. But
    I prefer to use the web console for deploying services and to use the CLI for
    pentesting tools. Follow the next steps to deploy Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: While logged in to GCP from the web and in the web console, go to [https://console.cloud.google.com/projectselector2/home/dashboard](https://console.cloud.google.com/projectselector2/home/dashboard).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For the time being, leave the project selector you just opened in one web browser
    tab. Open **Enable access to APIs** in another tab while using this link: [https://console.cloud.google.com/flows/enableapi?apiid=artifactregistry.googleapis.com](https://console.cloud.google.com/flows/enableapi?apiid=artifactregistry.googleapis.com,container.googleapis.com).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will see a screen like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 12.5 – Enabling the required API access for Kubernetes](image/B18672_12_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.5 – Enabling the required API access for Kubernetes
  prefs: []
  type: TYPE_NORMAL
- en: Click on **Confirm project**. **Enable APIs** will transition and say that you’re
    about to enable **Artifact Registry API** and **Kubernetes Engine API**. That’s
    exactly what we want to do. Click on **ENABLE**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You may have to wait a few moments for your enabling of those APIs to process.
    I was surprised that this took more time than creating my Docker test container.
    But when that’s done, go back to your web browser tab with the project selector
    dashboard. That’ll look something like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.6 – Selecting a project in GCP for our Kubernetes instance](image/B18672_12_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.6 – Selecting a project in GCP for our Kubernetes instance
  prefs: []
  type: TYPE_NORMAL
- en: Click on a project. Make note of your project ID; it should be something similar
    to **blissful-axiom-115916**, as in the preceding screenshot.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, we will do the rest of the work in Cloud Shell in the CLI. Click on the
    icon that looks like this in the top menu bar on the right-hand side: **>_**.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, we’ll make sure that our selected project is the default by entering
    this at the command line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we’ll create a default autopilot Kubernetes cluster with this command.
    If the region you set up earlier isn’t **us-central1**, then change it to the
    name of your region:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see in the *Code in Action* video of this exercise, it may take a
    few minutes for your cluster to be created. Be patient! Thankfully the command
    line in Cloud Shell will show you what’s going on while you wait.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'After the several-minute process of creating your Kubernetes cluster is done,
    you next need to create authentication credentials for your cluster. This will
    make **kubectl** (the program you use to manage your Kubernetes cluster at the
    command line) ready to use your new cluster. Just be sure to change **us-central1**
    to the name of your region if it’s different:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we’re going to create an application deployment in our new Kubernetes
    cluster with the following command. The directory path after **image=** is our
    default **hello** Kubernetes container image for testing purposes. If you want
    to do something specific with Kubernetes in GCP at some point after reading this
    book, you can modify the command to use a different container image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we need to set up the load balancer so that we can expose our deployment
    to the internet. We will be accessing our Kubernetes deployment through the internet
    in order to pentest it, so this step is absolutely necessary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we need to run some checks to make sure our new Kubernetes Deployment
    is ready to use. First, let’s inspect the Pods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The command line should show a **hello-server** Pod.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, we’ll inspect **hello-server**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Copy the external IP that prints at the command line.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In a new web browser tab, enter **http://<your external IP here>** in the address
    bar and hit *Enter*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: My external connection to my Kubernetes Deployment was slow. But it eventually
    worked. I got an error in Firefox that warned me that the destination was HTTP
    and not HTTPS. I clicked the button to go to the HTTP site, and my screen showed
    this. It worked!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.7 – Viewing the IP address for our Kubernetes Deployment in a web
    browser](image/B18672_12_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.7 – Viewing the IP address for our Kubernetes Deployment in a web
    browser
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have both a working Docker environment and a working Kubernetes
    environment in GCP, it’s time to use those environments to try out some pentesting
    tools.
  prefs: []
  type: TYPE_NORMAL
- en: Trivy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Trivy ([https://github.com/aquasecurity/trivy](https://github.com/aquasecurity/trivy))
    is a pentesting tool that’s developed by Aqua Security and available on GitHub.
    It’s a security scanner that can find vulnerabilities in filesystems, VM images,
    and AWS. But it can also be used to scan Docker and Kubernetes images.
  prefs: []
  type: TYPE_NORMAL
- en: 'Trivy can be run from Red Hat and CentOS, Arch Linux, and macOS. The installation
    instructions for all supported platforms can be found here: [https://aquasecurity.github.io/trivy/v0.44/getting-started/installation/](https://aquasecurity.github.io/trivy/v0.44/getting-started/installation/).
    The Linux VM I have running in my GCP deployment is based on Debian, so I’ll use
    the Debian installation instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have Trivy installed on our Linux VM in GCP, let’s try a couple
    of basic container scanning exercises. Trivy users and developers have a wide
    range of container pentesting tutorials on their website ([https://aquasecurity.github.io/trivy/v0.45/tutorials/overview/](https://aquasecurity.github.io/trivy/v0.45/tutorials/overview/))
    if you’d like to try some others.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try looking for misconfigurations in how I configured my Docker image.
    Remember—misconfigurations are security vulnerabilities that can be exploited
    by cyber attackers! Follow the next steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'I used GCP’s default **hello** test Docker image to build my Docker containers.
    This is its name and address:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will need to verify the name and address of the image you used. In your
    GCP console, search for **Cloud Run**. You will then see a screen like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.8 – Viewing our Docker instance in the Cloud Run interface](image/B18672_12_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.8 – Viewing our Docker instance in the Cloud Run interface
  prefs: []
  type: TYPE_NORMAL
- en: I clicked on the name of my Docker cluster, which in my case is **crawleydockertest**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then, I clicked on the **YAML** tab to see the YAML file that was used to build
    my Docker cluster. Where it says **image:** is where I found the name and address
    of the Docker image that I used. You can find yours the same way:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 12.9 – Viewing the YAML file that was used to create my Docker cluster](image/B18672_12_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.9 – Viewing the YAML file that was used to create my Docker cluster
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s run the scan:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'My Docker image was found, and it was very misconfigured! Here are the results
    I got:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 12.10 – Trivy scan output](image/B18672_12_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.10 – Trivy scan output
  prefs: []
  type: TYPE_NORMAL
- en: You could use this sort of data in your pentest report if you were conducting
    a real pentest.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s try Trivy to conduct a pentest against my Kubernetes cluster in
    GCP:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, I found that I had to expose my Kubernetes cluster again in order for
    Trivy to be able to scan it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, I inspected the Pods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, here’s a Trivy command that conducted a very thorough scan of my Kubernetes
    cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After a few minutes in the Cloud Shell CLI, I got a very detailed summary that
    I could use in a pentest report:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 12.11 – Trivy scan vulnerability report](image/B18672_12_011.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.11 – Trivy scan vulnerability report
  prefs: []
  type: TYPE_NORMAL
- en: Trivy is a lot of fun to explore!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned which services manage containerization in GCP. We
    deployed our own Docker and Kubernetes clusters. Then, we conducted a security
    assessment with Trivy.
  prefs: []
  type: TYPE_NORMAL
- en: The default way to deploy a Docker containerization system in GCP uses Cloud
    Build to simplify the Docker build steps and Cloud Run to help run containerized
    apps, all while your Docker host runs in GCE.
  prefs: []
  type: TYPE_NORMAL
- en: The simplest way to deploy Kubernetes in GCP is to use GKE.
  prefs: []
  type: TYPE_NORMAL
- en: Trivy is a third-party pentesting application that has lots of great features
    for vulnerability scanning both Docker and Kubernetes deployments.
  prefs: []
  type: TYPE_NORMAL
- en: In the next and final chapter, I’ll quiz you on what we’ve learned in the previous
    12 chapters. Plus, I’ll give you tips for writing and signing pentesting contracts,
    more tips for writing pentest reports, and introduce you to cloud and pentesting-related
    certifications that may make you more employable as a cloud pentester.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To learn more about the topics covered in this chapter, you can visit the following
    links:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Google Cloud* *Run*: [https://cloud.google.com/run](https://cloud.google.com/run'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: '*Google Cloud* *Build*: [https://cloud.google.com/build](https://cloud.google.com/build'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: '*GKE*: [https://cloud.google.com/kubernetes-engine](https://cloud.google.com/kubernetes-engine'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: '*Google Cloud documentation on deploying containers to Cloud* *Run*: [https://cloud.google.com/run/docs/deploying](https://cloud.google.com/run/docs/deploying'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: '*Google Cloud documentation on deploying Kubernetes applications in* *GKE*:
    [https://cloud.google.com/kubernetes-engine/docs/deploy-app-cluster](https://cloud.google.com/kubernetes-engine/docs/deploy-app-cluster'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: '*Trivy*: [https://github.com/aquasecurity/trivy](https://github.com/aquasecurity/trivy)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
