<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Access Control and Security Through Obscurity</h1>
                </header>
            
            <article>
                
<p class="mce-root">Security through (or by) obscurity is a strategy in web application development that assumes a hacker can't hack what he can't see; even if a vulnerability exists, as long as it's appropriately hidden or obfuscated, it'll never be discovered and used for malicious purposes.</p>
<p class="mce-root">While this can feel true (how could someone find this thing I've cleverly hidden—I've cleverly hidden it), it ignores a basic understanding of computers and programming. Computers are great at finding needles in haystacks. And it's not just one person programming one script on one machine who's interested in probing your site for vulnerabilities; any site exposed to the internet faces a <kbd>24/7/365</kbd> crowd-sourced attempt to compromise its network. When you assume that no one will find your hidden exploit, you're actually assuming no one, among the many people targeting you (directly or indirectly), over the course of your site's lifetime, with the resources of the entire internet, will be successful. It's a dangerous bet to make.</p>
<p class="mce-root">In this chapter, we'll be demonstrating the use of various tools to find hidden content, and discussing the differences between what merits a payout and what doesn't: There's so much data flooding every corner of the web, it's important to have an understanding about what programs value. We'll also cover the shortcomings of the security mindset that can make data leakage such a critical vulnerability for so many sites. Of course, we'll also take an example of data leakage through the full life cycle of the bug bounty process, from discovery, to validation, to submission.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical Requirements</h1>
                </header>
            
            <article>
                
<p>For this chapter, we'll be using Burp Suite and its hidden content features, as well as Chrome (<kbd>66.0.3359.139</kbd>). We'll also be using WebGoat, an intentionally vulnerable app created by OWASP that you can download and practice against.</p>
<p class="mce-root"/>
<div class="packt_infobox">Please clone or download the repository to your local system (<a href="https://github.com/WebGoat/WebGoat">https://github.com/WebGoat/WebGoat</a>).</div>
<p>There are several ways you can set up WebGoat. You can download and run it as a <kbd>jar</kbd> executable (as we've been doing with Burp Suite), you can download a Docker image, or you can build it directly from source. Although using <kbd>jvm</kbd> to manage Java dependencies works for Burp, I prefer to use Docker when it's available, since there's so much great tooling around it.</p>
<p>There is one concern: if you're running the Burp Suite proxy and using the default proxy ports (<kbd>localhost:8080</kbd>), you'll need to make sure you start the WebGoat server on a different port so as not to cross traffic with Burp. These are the commands the GitHub page references to pull and start the server:</p>
<pre><strong>docker pull webgoat/webgoat-8.0</strong><br/><strong>docker run -p 8080:8080 -it webgoat/webgoat-8.0 /home/webgoat/start.sh</strong></pre>
<p>In our case, since we want it to run on <kbd>localhost:8081</kbd> instead of <kbd>localhost:8080</kbd>, we'll simply change the second command to map our Docker process to the correct port:</p>
<pre><strong>docker run -p 8081:8080 -it webgoat/webgoat-8.0 /home/webgoat/start.sh</strong></pre>
<p>Now we can use Burp and WebGoat together without any port clashes.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Security by Obscurity – The Siren Song</h1>
                </header>
            
            <article>
                
<p>The appeal—and trap—of security by obscurity is the ease with which strategies can be implemented, especially when compared to more rigorous credential management systems. Obscuring a piece of sensitive information just means scrambling it, rearranging and reordering it, until it looks like gibberish. Looks like is the operative phrase, since patterns can be detected outside the scope of human intuition or estimation.</p>
<p>The assumptions behind this sort of strategy invariably contain an element of human fallibility—someone couldn't find <em>X</em>, or trip across <em>Y</em>, because the odds are so stupendously against them, considering the scope of the application, the minimal nature of the vulnerability, and the implicitly assumed man-hours of brute-forcing a solution to the problem. But, of course, computers aren't constrained by such limitations, and the actual audience for the site is larger than assumed. And when a large set of users, augmented by crawlers, fuzzers, and all other sorts of web agents, train their tools on a target, they can uncover flaws and make that site (and others) safer.</p>
<p class="mce-root"/>
<p>There is an important caveat here that even though security by obscurity is not valid as the only or principal layer of security for a network; it is valid as just one defense among many. The strategy, artfully employed, can help increase the cost of compromising the site in order to repel less determined adversaries and at least deter opportunistic exploitation.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data Leaks – What Information Matters?</h1>
                </header>
            
            <article>
                
<p>There are a few categories of data that have instant and recognizable value. It should be clear to just about any developer that these should be treated as higher value pieces of information in any threat-modeling exercise.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">API Keys</h1>
                </header>
            
            <article>
                
<p>API keys are typically used to provide project-level authorization for an API, service, or other organization-type object. APIs can be critical pieces of information to expose because of the extent of their permissions and the generally wider scope of API keys. A ready example of an API key might be the API key for a SaaS app, such as Twilio. A Twilio API Key doesn't differentiate access based on the role of the user; it just gives everyone who has it the ability to make API calls to the associated Twilio account.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Access Tokens</h1>
                </header>
            
            <article>
                
<p>Tokens are different from API keys. Access tokens are usually used to authenticate an individual (for example, session tokens and generally all cookies) as opposed to an entire service or project. Access tokens can still be sensitive data, depending on the scope of the token's authentication.</p>
<p>API keys are something that should generally never be public (unless it's the public half of a multi-key system) but your browser trades session authentication tokens back and forth with the sites you visit every day.</p>
<p>These distinctions aren't ironclad—they only describe a convention that can be freely broken—but they do provide a great jumping-off point for understanding some of the distinctions between different kinds of authentication data.</p>
<p>A common example of a popular access token would be an AWS <strong>Identity and Access Management</strong> (<strong>IAM</strong>) access token, which provides the basis for regulating an IAM role's access to different Amazon resources owned by the larger organizational account.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Passwords</h1>
                </header>
            
            <article>
                
<p>This is a no-brainer. Team/role-based and individual passwords, if stored in plaintext (or insufficiently encrypted) and exposed, are obviously dangerous points of vulnerability that hackers can use to infiltrate even more privileged systems. The username/password credential pattern underpins most of the services consumers interact with regularly, from social media profiles to bank accounts.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Hostnames</h1>
                </header>
            
            <article>
                
<p>This can be a bit more of a gray area. Quite often, if a hostname is exposed in publicly available logs or in an API, if it's meant to be internal, it will be locked down to a VPN or privileged network. However, if they aren't protected by a VPN or firewall, even the IP or hostname of a box can be an exploitable liability.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Machine RSA/Encryption Keys</h1>
                </header>
            
            <article>
                
<p>Unlike API keys, which describe permissions for services, projects, and roles, a machine RSA, or similar key, represents the cryptographic identity of an individual machine (whether it's a laptop, server, and so on). Exposed RSA keys for even lesser services, such as continuous deployment build servers for smaller or staging environments, can provide the necessary foothold for an attacker to inject malicious elements into other parts of your network. If you're using a macOS-powered machine, you'll typically store the SSH keys associated with your machine in a hidden <kbd>.ssh</kbd> folder. A typical naming convention is <kbd>id_rsa</kbd> for you private key and <kbd>id_rsa.pub</kbd> for your public one.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Account and Application Data</h1>
                </header>
            
            <article>
                
<p>The information we've described up until now has all existed at the network level, with the exception of access tokens tied to in-app behavior (like session cookies). But data within the account itself—account settings, billing information, application configs, and so on—are all valuable targets for any attacker.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Low Value Data – What Doesn’t Matter</h1>
                </header>
            
            <article>
                
<p>Any discussion that includes important information to scout for bug bounties should cover data that is routinely leaked (without issue) by web apps every day.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Generally Descriptive Error Messages</h1>
                </header>
            
            <article>
                
<p>Although error messages can be a valid source of sensitive information that's only if, well, the message contains sensitive data. By itself, a stack trace that includes function names, exception types, and other common debugging info is not a vulnerability. The key differentiator here is: can you imagine an attack scenario using the information?</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">404 and Other Non-200 Error Codes</h1>
                </header>
            
            <article>
                
<p>404s and more exotic error codes are part of the normal functioning of an application. If sensitive information is exposed in a message, that's an issue, but otherwise, the code is to be expected.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Username Enumeration</h1>
                </header>
            
            <article>
                
<p>Savvy sites will contain error messages for sign-up and login pages that don't indicate whether a username exists: invalid credentials are vague enough to make it unclear whether it was the username or password that was incorrect, while the message username already exists instantly tells an attacker that there's a valid user target with that account.</p>
<p>Combined with a script that fuzzes different possible usernames (based on something like a dictionary attack), a determined assailant could create a list of all the site's users. Regardless, because it's so resource-intensive, common, and since it doesn't lead directly to a serious vulnerability like remote code execution, username enumeration does not merit a bug bounty payout for most companies.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Browser Autocomplete or Save Password Functionality</h1>
                </header>
            
            <article>
                
<p>Enabling a browser's form autocomplete or save password functionality is often recommended against because attackers who gain access to your browser can look back to leverage stored credentials. Since it already depends on another vulnerability to allow an attacker to access your browser in the first place, this bug does not merit a bounty payout.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data Leak Vectors</h1>
                </header>
            
            <article>
                
<p>So far we've listed different types of information, but not where we can expect to find anything. Here are a few places where a website or app can unintentionally expose sensitive information.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Config Files</h1>
                </header>
            
            <article>
                
<p>Config management is an entire branch of operations that ensures configuration credentials are never exposed. Whether you're injecting them at runtime via a service such as consul (see <em>Further reading</em> for a link) or simply leaving them unversioned by including them in your project's <kbd>.gitignore</kbd>, there are varying degrees of sophistication in the available solutions.</p>
<p>But sometimes those measures fail and a config file is included in a server's root directory, logs on an exposed build server, application error messages, or a public code repository. That can make the sensitive contents of that config fair game for any attackers.</p>
<p>Earlier, we discussed discovering sensitive config files in the context of applying fuzzing tools such as <kbd>wfuzz</kbd> that use wordlists to attempt to access files that have been left on a web server and mistakenly left accessible. We used the <kbd>SecLists</kbd> repository of curated pentesting resources for our wordlist (<a href="https://github.com/danielmiessler/SecLists">https://github.com/danielmiessler/SecLists</a>) in <a href="23759e04-8982-41fd-b936-580865a51439.xhtml">Chapter 3</a>, <span><em>Preparing for an Engagement</em></span>,<span> </span>but there are several great options for dictionaries of sensitive filenames. Check out <a href="ed465f46-31a7-429c-b0d2-6616dace7167.xhtml">chapter 11</a>, <em>Other Tools,</em> for more info.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Public Code Repos</h1>
                </header>
            
            <article>
                
<p>With more developers using open-source sites, such as GitHub, to network and share code, it's easy for flat file credentials and text-based secrets to be mistakenly included in a repo's commit history. It's important to note here that if you mistakenly commit sensitive data to your project's Git history, the first thing you should do is rotate those credentials.</p>
<p>Don't try and push a commit removing the info (keep in mind, it can still be found in a previous commit); just refresh those API keys or passwords first, and then worry about removing the info from the repo later.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Committing sensitive credentials to a public GitHub/Bitbucket repo has become so common that blogs such as A <em>Very Expensive AWS Mistake</em> have become their own content niche (<a href="https://medium.com/@morgannegagne/a-very-expensive-aws-mistake-56a3334ed9ad">https://medium.com/@morgannegagne/a-very-expensive-aws-mistake-56a3334ed9ad</a>). In that particular blog post, a developer working through the Flatiron development bootcamp commits her AWS IAM credentials to GitHub and only discovers her error when she starts exceeding her free-tier limits, finally seeing the $3,000+ bill she's racked up in the short time her creds have been exposed.</p>
<p>The practice has even spawned a variety of SaaS businesses designed to scan your public source code and notify you if you've included any sensitive information. Businesses such as GitGuardian (<a href="https://www.gitguardian.com/tweet">https://www.gitguardian.com/tweet</a>) and GitMonkey (<a href="https://gitmonkey.io/">https://gitmonkey.io/</a>) are designed to provide a notification safety net if a tired or junior developer mistakenly versions credentials.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Client Source Code</h1>
                </header>
            
            <article>
                
<p>Client source code—the static JavaScript, HTML, and CSS executed in your browser<span>—</span>is different from the entire source code repo represented by an entire Git project. You're less likely to find a config file with application-level secrets and the scope of the business logic exposed will probably be minimal (even an all-JavaScript, Angular, or React app will feature most logic in a connected API) but there are still opportunities to harvest weak cookies, <kbd>futz</kbd> with client-side validations, and look for old settings, resources, and functionality in commented-out code.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Hidden Fields</h1>
                </header>
            
            <article>
                
<p>Hidden fields are technically a part of the client code, but merit extra consideration as a prime vector for malicious data input. It's important if you're messing with hidden fields to avoid submitting values for honeypot fields. Honeypot fields are hidden <kbd>input</kbd> tags that, since a a normal GUI user can't see them, usually don't get don't get submitted—unless that form is being fuzzed by a script that's injecting values into every available <kbd>input</kbd> field it can.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Error Messages</h1>
                </header>
            
            <article>
                
<p>Just like we covered in <a href="847090b6-8871-4977-9538-17cc1ad52954.xhtml">Chapter 5</a>, <span><em>SQL, Code Injection, and Scanners</em>,</span> where we discussed the error-based SQL injection attack and how a determined attacker can often use public error messages propagated up from the SQL DB to enumerate information, error messages can leak data in other contexts. In application error logs, GUI error messages, API errors, and other error vectors, everything from machine-level RSA keys to user info can be exposed.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Unmasking Hidden Content – How to Pull the Curtains Back</h1>
                </header>
            
            <article>
                
<p>Exploring obfuscated, neglected, or otherwise exposed data is a critical exercise, both as part of a site's opening reconnaissance and as a dedicated end in itself.</p>
<p>We'll cover a couple of different ways, some passive and some more active, that will help you discover sensitive information that will win you a bounty payout.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Preliminary Code Analysis</h1>
                </header>
            
            <article>
                
<p>It's a simple step, but walking through the page's source and being able to get a sense of the code style and quality, framework, any extra connected services, and just a general feel for the code base powering the app is essential, and can lead to surprising finds.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using Burp to Uncover Hidden Fields</h1>
                </header>
            
            <article>
                
<p>There are two ways to use Burp to discover hidden input fields: one is easy, the other absurdly easy.</p>
<p>The first way is to examine any HTTP traffic generated by forms to ensure you catch any information being passed that wasn't available in the GUI.</p>
<p>The other (easier) way is a simple configuration setting in the <span class="packt_screen">Options</span> pane within the <span class="packt_screen">Proxy</span> tab:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/2c8029f0-3ebf-4154-8da7-a3c414d77c14.png" style=""/></div>
<p>Now when you walk through an application using the proxy-linked browser, you can see any hidden fields on a page highlighted in a bright red <kbd>div</kbd>:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/53b1e853-5377-4d1e-9489-d8a91c59d50a.png" style=""/></div>
<p class="mce-root"/>
<p>By highlighting any fields you come across, Burp allows you to pick up on secret info at the same time you're mapping your target application's attack surface.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data Leakage – An End-to-End Example</h1>
                </header>
            
            <article>
                
<p>Let's try out some of our new techniques on WebGoat, OWASP's deliberately-vulnerable Java application. After navigating to <kbd>localhost:8081/WebGoat</kbd>, go ahead and click on the link to register a new user and then log in.<br/>
<br/>
After you've logged in, you should be on the main WebGoat welcome page:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/855d54a9-833f-4bb1-88c8-2b430c8ba124.png" style=""/></div>
<p>Now we're going to click through to the <span class="packt_screen">Client side</span> <span><span>lesson:</span></span></p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/06549b13-d85d-4def-bc1f-5c9e014e3e8f.png" style=""/></div>
<p>Landing on the page, we can immediately see a couple of hidden fields of interest. We also get the gist of the lesson—we're a disgruntled employee that wants to get the personal info of our CEO, even though we (naturally) don't have access to it—and what it is that we're trying to subvert: a small, employee directory application.</p>
<p>Looking at the hidden fields, they seem to be associated with an employee ID that's connected to an employee info record. If we use our <kbd>dev</kbd> tools to inspect the markup, we can see the <kbd>select</kbd> tag where the employee we want info on is chosen, and the associated IDs:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/f956e5f5-fcf5-4cb8-abc2-c16cb36b2420.png" style=""/></div>
<p>Now if we can dive into that <kbd>onchange</kbd> callback—wait, what's that there in the bottom right of our pane?</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/7343110f-01fd-4c8e-bb05-9581ae6bbaa1.png" style=""/></div>
<p>This is obviously an extreme example—naming a class with a super-incriminating string—but exposing sensitive client-side data simply because the mechanisms used to keep it hidden rely on the GUI or no one tampering with it is unfortunately a real-life issue:</p>
<div class="CDPAlignCenter CDPAlign"><img style="" src="assets/0f843ad2-138a-4508-8a69-927800a166db.png"/></div>
<p>Now, diving into that class, we can see the markup does in fact contain the CEO and other's info. We now have the CEO's salary (a cool $450,000) and are just a little bit more accomplished in corporate espionage then we were a few moments ago.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Gathering Report Information</h1>
                </header>
            
            <article>
                
<p>Now that we've brought our company to its knees, let's walk through the info we need to write our report:</p>
<ul>
<li><strong>Category</strong>: This is a data leak of sensitive information. In this case, the CEO's salary and SSN.</li>
<li><strong>Timestamps</strong>: For our timestamp, we can just approximate a time manually.</li>
<li><strong>URL</strong>: For our URL, we can use the page where we discovered the info in the source code:</li>
</ul>
<pre style="padding-left: 60px"><strong>http://localhost:8081/WebGoat/start.mvc#lesson/ClientSideFiltering.lesson/1</strong></pre>
<ul>
<li><strong>Methodology</strong>: Skipping payload, we can just head to the methodology. In this case, we simply came across the information after a close inspection of the page's source code.</li>
<li><strong>Instructions to reproduce</strong>: Simple enough. Navigate to the affected page and look at its source.</li>
<li><strong>Attack scenario</strong>: For our attack scenario, it's important to prove the danger the data poses in the wrong hands. In this case, it's clear. Exposing sensitive financial information along with his SSN puts the CEO at a clear risk of cyberattack and identity theft.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Final Report</h1>
                </header>
            
            <article>
                
<p>Let's use this information to format our submission:</p>
<ul>
<li><strong>Category</strong>: Data leak of sensitive employee data.</li>
<li><strong>Time</strong>: 2017-03-25 17:27 (17:27) UTC.</li>
<li><strong>URL</strong>: <kbd><span><span>http://localhost:8081/WebGoat/start.mvc#lesson/ClientSideFiltering.lesson/1</span></span></kbd></li>
<li><strong>Methodology</strong>: <span>Vulnerability detected after inspecting the source code of the affected page.</span></li>
<li><strong>Instructions to procedure</strong>:
<ol>
<li>Navigate to the affected URL</li>
<li>Inspect the page's source code</li>
</ol>
</li>
<li><strong>Attack scenario</strong>: With access to the CEO and other privileged employees' personal information, an attacker could steal those individuals' identities, engage in spear-phishing campaigns to compromise company resources, and generally wreck havoc with the financial health of both the company and its employees.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, you've learned about the deficiency (and sometimes validity) of security by obscurity as a philosophy, how to unmask a site's hidden content with Burp and other tools, how to distinguish between different types of sensitive information, a rough guide to information that doesn't merit a bounty payout, and taking a data leak vulnerability from discovery to report formatting and submission. You should now feel prepared to incorporate at least basic hidden content discovery methods into your pentesting regimen. </p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<ol>
<li>Is security by obscurity a valid security layer?</li>
<li>What are some common pieces of information reported for bounties?</li>
<li>What's a good tool for uncovering hidden content?</li>
<li>What's the difference between an API key and an access token?</li>
<li>What information typically does not merit a payout as a data leak vulnerability?</li>
<li>What's a downside to relying on client-side data filtering?</li>
<li>What are some common vectors through which web application data leaks?</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further Reading</h1>
                </header>
            
            <article>
                
<p>You can find out more about some of the topics we have discussed in this chapter at:</p>
<ul>
<li>Google Cloud Endpoints on API Keys versus Authentication Tokens: <a href="https://cloud.google.com/endpoints/docs/openapi/when-why-api-key">https://cloud.google.com/endpoints/docs/openapi/when-why-api-key</a></li>
<li>Consul Config Management: <a href="https://www.consul.io/">https://www.consul.io/</a></li>
</ul>


            </article>

            
        </section>
    </body></html>