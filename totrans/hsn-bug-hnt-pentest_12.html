<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Other (Out of Scope) Vulnerabilities</h1>
                </header>
            
            <article>
                
<p class="mce-root">We've covered a lot about what you should look for—the structure of vulnerabilities, and how to test for them in both programmatic and manual ways.</p>
<p class="mce-root">It seems unimportant to talk about what you shouldn't look for—if you don't care about it, you'll just ignore it, right? But there are several common findings and false positives that you'll see being spit out by scanners, passive analysis tools, extensions, and command-line logs again and again. It's useful to have an idea of what vulnerabilities companies are not interested in so that you can both avoid wasting your time submitting doomed bug reports and configure your tools to report less noise to you in the first place.</p>
<p class="mce-root">The common theme for most of the vulnerabilities we'll cover here are that they don't have a clear path to exploitation. They either only affect the attacker, require other (more serious) vulnerabilities to be present before they can be exploited, or in the case of leaked information, don't give an attacker any actionable information.</p>
<p class="mce-root">This chapter will cover what vulnerabilities companies often exclude from bug bounty programs, including how they work and why they're often not covered, and some of the common themes in what excludes a bug from reward consideration.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical Requirements</h1>
                </header>
            
            <article>
                
<p>Since we'll mostly be discussing and using examples of vulnerabilities that you need to exclude from your workflow, we'll be able to get by with just our browser (Chrome version <kbd>66.0.3359.139</kbd>).</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">DoS/DDoS – The Denial-of-Service Problem</h1>
                </header>
            
            <article>
                
<p><strong>Denial-of-Service</strong> (<strong>DoS</strong>) and <strong>Distributed Denial-of-Service</strong> (<strong>DDoS</strong>) are familiar strains of cyberattack to anyone who follows security news. Flooding a target with traffic indistinguishable from a legitimate surge of visitors remains a popular method for either taking down or crippling a web property, especially when combined with amplification attacks caused by hijacking other servers, spoofing connected services, or taking advantage of an internal performance flaw or bottleneck.</p>
<p>In 2018, GitHub was hit by what was then the largest DDoS attack ever recorded (the record was broken just five days later), clocking in at a saturation rate of about 1.3 TBps. One reason the attackers were able to achieve such a high throughput was because they relied on commandeering unsecured Memcached database servers (Memcache is a general-purpose distributed memory caching system), where they could spoof a query packet meant to look like the target server asking for data from the memcache server. Then, the memcache server would batter the target server with data up to 50,000 times the size of the spoofed request. GitHub in particular has been repeatedly targeted, with this incident just the latest in a sustained campaign against the site.</p>
<p>If you look at GitHub's bug bounty program, you'll notice they do call out DDoS attacks specifically—that they don't allow them:</p>
<p>Don't perform any attack that could harm the reliability/integrity of our services or data. DDoS/spam attacks are not allowed. (emphasis theirs)</p>
<p>DoS/DDoS attacks often aren't a result of anything that the victim of the attacks did <span>–</span> they didn't miscode the application, or leave some critical network vector open. Defending against DDoS attacks requires an entire proactive security architecture, redistributing the load across different networks and throttling/isolating malicious sources of traffic.</p>
<p>The exception is when a DoS/DDoS attack is more effective <em>because</em> it can leverage a security flaw that exists on the victim network. If, as a security researcher, you come across, for example, an unsecured NTP server that could be hijacked to amplify a DDoS attack, you should certainly report it as a vulnerability that could be used to threaten either you or another bystander's network.</p>
<div class="packt_infobox">You should not try to validate any vulnerabilities like this by leveraging them for increased bot traffic, even if you think it falls below the threshold of something that could damage the target's infrastructure. The fact that DDoS prohibitions are so common is a sign of how seriously they're taken by bounty program operators.</div>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sandboxed and Self-XSS – Low-Threat XSS Varieties</h1>
                </header>
            
            <article>
                
<p>Self-XSS is a variety of XSS that relies heavily on social engineering, which is the primary reason it is excluded from most bug bounty programs. Sandboxed XSS, a similar term for a related strain, is typically used to describe an XSS vulnerability that happens on a machine isolated from sensitive user data or operations. Since Self-XSS refers to the specific phenomenon of executing code within your browser environment to make yourself vulnerable to an XSS attack, it also means that your XSS bug is isolated in terms of what information it can access.</p>
<p class="mce-root">For Self-XSS to take place, the attacker must get the victim to execute code within the browser context. That execution is what makes the victim susceptible to further exploitation by the attacker.</p>
<p class="mce-root">A simple example of self-XSS in action would be as follows:</p>
<ol>
<li>An attacker advertises a hacking-kit-in-a-box - H4x0rs l18e 1337! or whatever the kids say these days. All you have to do is copy this code snippet and paste it into the developer console of your browser.</li>
<li>You, beautifully gullible, happily copy the code and paste it into your console, imagining the terror of your digital wrath.</li>
<li>Instead of hacking someone else, the code you pasted into your console just exposed you to hackers. Any sensitive session cookies or information available in your browser is now the property of a shadowy cabal of cyberanarchists.</li>
</ol>
<p>For an example of this in action, check out the link in the <em>Further reading</em> section for a write-up of a very similar scam that got passed around on Facebook a few years ago: the post (also) encouraged you to follow the directions to hack any Facebook account, (also) asking you to copy and execute code in your developer console, and (also) hacking you when you actually complied.</p>
<p>Because this particular bug, like so many of these un-rewardable, almost-vulnerabilities, requires either action outside the application context (a phone support worker initiating a change under the influence of social engineering) or other application-based vulnerabilities to be present and ripe for exploitation, it falls outside the scope of most programs and is not eligible for a reward.</p>
<p>Even as companies write guides to avoiding these kinds of scams, they're limited in terms of the preventative action they can take: there's only so many ways to secure a house if the owner is intent on giving away their keys.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Non-Critical Data Leaks – What Companies Don’t Care About</h1>
                </header>
            
            <article>
                
<p>In <a href="24cf74e7-2770-4c3f-b804-3e52aaa6f852.xhtml">Chapter 8</a>, <em><span>Access Control and Security Through Obscurity</span></em>,<em><span> </span></em>as part of our discussion about access control, security by obscurity, and data leakage, we briefly covered different types of data that companies weren't interested in rewarding: usernames, descriptive-but-not-sensitive error messages, different kinds of error codes, and so on.</p>
<p>Here are some other, specific examples about information that security researchers often report, but that companies very rarely pay for.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Emails</h1>
                </header>
            
            <article>
                
<p>Emails are an item of information many people try to deny to bots and automated agents crawling their site. One typical strategy is encoding email links as HTML entities to make them harder to collect. That means you can hide an email such as  <kbd>nessus@generalproducts.biz</kbd> as the following entity code:</p>
<pre>nessus@generalproducts.biz</pre>
<p>Unless the crawler is expecting to detect and decode entities as part of its scraping process, this little obfuscation trick can be surprisingly effective.</p>
<p>But if an email is exposed on a company site, it's usually meant to be a public-facing handle. Submitting a bug report about <kbd>support@company.com</kbd> or even because you've deduced the employee email naming convention is something like <kbd>lastname.firstname@company.com</kbd> doesn't meet the standard for a payout.</p>
<p>There are too many extra steps beyond simply enumerating a company's email username registry before the disclosure becomes a vulnerability.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">HTTP Request Banners</h1>
                </header>
            
            <article>
                
<p>HTTP banners are an integral part of the protocol that stitches the entire web together. On common services, that might be privy to many different types of devices. They can include encoding data, device information, general information about the nature of the HTTP request, and other data.</p>
<p>All of that is to be expected as part of the service and doesn't constitute a leaked source of sensitive system information. This includes both information contained in the present banners as well as "missing" security banners.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Known Public Files</h1>
                </header>
            
            <article>
                
<p>This is simple: some files are designed to be accessible! Reporting on the configuration or availability of  <kbd>robots.txt</kbd>, <kbd>wp-uploads</kbd> , or <kbd>sitemap.xml</kbd> isn't going to merit a payout—or probably even a response.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Missing HttpOnly Cookie Flags</h1>
                </header>
            
            <article>
                
<p>HttpOnly cookie flags are anti-XSS prevention devices. If a server-side process flags a cookie as HttpOnly, it can't be accessed client-side (when the browser attempts to read the cookie, it just returns an empty string). Every major browser supports HttpOnly cookies. But whatever their value, they are a safeguard, and their absence does not directly imply a vulnerability. If there's no additional XSS, there's no issue.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Other Common No-Payout Vulnerabilities</h1>
                </header>
            
            <article>
                
<p>In addition to the larger categories of bugs that we've discussed that typically don't merit a payout, and keeping in mind that these are in addition to previously-submitted vulnerabilities, which are ineligible for payout everywhere, there are also a lot of one-offs and miscellaneous would-be vulnerabilities you should try to avoid submitting.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Weak or Easily Nypassed Captchas</h1>
                </header>
            
            <article>
                
<p>CAPTCHA (and their successor, reCAPTCHAs) are Google-administered Turing tests designed to block bot form submission spam by asking a bot to do things (sophisticated natural language detection, image pattern recognition, performing tasks on dynamic challenges, and so on) that your average bot can't do. Because they represent a third-party service whose security posture is managed by an outside company, most companies that host <span>CAPTCHAs </span>themselves won't reward any CAPTCHA-related bugs or vulnerabilities.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The HTTP OPTIONS Method Enabled</h1>
                </header>
            
            <article>
                
<p>HTTP supports a variety of requests outside the standard <kbd>GET</kbd>, <kbd>PUT</kbd>/<kbd>PATCH</kbd>, <kbd>POST</kbd>, and <kbd>DELETE</kbd> requests. <kbd>OPTIONS</kbd> is a diagnostic method that can enable debugging and stack trace data that can potentially be useful to an attacker. Although it increases your attack surface and is something you should definitely avoid as an application developer, having <kbd>OPTIONS</kbd> enabled is not a vulnerability per-se. Like other wannabe bugs that we've discussed, it requires too many extra steps in order to demonstrate a valid attack scenario.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">BEAST (CVE-2011-3389) and Other SSL-Based Attacks</h1>
                </header>
            
            <article>
                
<p>The <strong>Browser Exploit Against SSL/TLS</strong> (<strong>BEAST</strong>) attack assumes a fair degree of client-side control, with the attacker able to inject packets in the browser's TLS stream by performing a <strong>Man-in-The-Middle</strong> (<strong>MiTM</strong>) attack, which then allows the attacker to guess the initialization vector involved and decrypt other information.</p>
<p>As the security product company, Acunetix, notes in one of its blog posts about the attack:</p>
<div class="packt_quote">It’s worth noting that for the BEAST attack to succeed, an attacker must have reasonable control of the victim’s browser, in which case it's [sic] more probable that an easier attack vector is chosen.</div>
<p>This exemplifies a couple of themes common to our no-reward staple of would-be vulnerabilities: the vulnerability in question is one that affects the actual TLS/SSL connection, which means it's the responsibility of the underlying tech, and not just that particular implementation of it; it's also a bug that requires several other vulnerabilities to be exploited, meaning that if it's present, it's not the issue that should be our greatest concern. Both of these dynamics work to invalidate it and other SSL-based attacks as reportable submissions.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Brute Forcing Authentication Systems</h1>
                </header>
            
            <article>
                
<p>If an authentication system (a GUI form, an API request, or any other implementation or layer) doesn't lock a user out after a certain number of failed login attempts, it leaves itself open to being brute forced, with an attacker trying every possible combination of credentials until he/she is successful. Locking a user out after X failed attempts is a common security best practice, but missing that feature doesn't immediately make an application insecure. The amount of resources involved in brute forcing and the high level of noise it would make to any observing system engineer, means that, by itself, brute-force-ability isn't a compelling enough foundation for a severe attack scenario. Additionally, testing the efficacy of a brute force attack means <em>making</em> a brute force attack, which can deal serious damage to the target company's infrastructure and computing resources.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">CSRF Logout</h1>
                </header>
            
            <article>
                
<p>Traditionally considered to be a security non-issue (and still not rewarded by many bounty programs), the ability for a cross-site request to forcefully log a user out is being reevaluated as a possible security threat by organizations like Detectify Labs, who have published a couple of different attack scenarios outlining when logout functionality being susceptible to CSRF is a problem (check the <em>Further reading</em> section for the link). Despite the constant reevaluation of the bug, it still often requires several extra steps to become a true vulnerability with a credible attack scenario, and is therefore not a priority for bug bounty programs.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Anonymous Form CSRF</h1>
                </header>
            
            <article>
                
<p>Another common CSRF-related vulnerability that doesn't often receive a payout is an anonymous form (for example, Contact Us) that is susceptible to CSRF. If an anonymous form is susceptible to CSRF, it means that an attacker could trick the victim into submitting it with different or modified fields.</p>
<p>Taking the contact form as our example, this bug doesn't merit a payout because there's no relevant attack scenario that we can derive from it. Even if we submit the form with a different email address or message, it's not clear what damage that would do. For more mission-critical forms (filling out payment information, changing account settings, or authentication methods), we can come up with some bone-chilling scenarios, but if a form is anonymous, that usually means it's expected to receive a bunch of spam, and is isolated from important functions accordingly.</p>
<p class="mce-root"/>
<p>This example drives home a general point we've been making (and will continue to make) throughout this book: attack scenarios modeling a critical attack are essential to making sure that your submission is rewarded.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Clickjacking and Clickjacking-Enabled Attacks</h1>
                </header>
            
            <article>
                
<p><kbd>Clickjacking</kbd> is when an attacker hides a malicious link in a transparent or obscured link <em>under</em> a legitimate, safe, button so that users are tricked into following the black hat URL.</p>
<p>Clickjacking is omitted from bounty programs because it requires that the company itself is use dark patterns (malicious UX/UI techniques), tricking users into following harmful links on a platform they control. Since any company <em>actually</em> doing that most certainly wouldn't advertise it, bounty programs aren't interested in paying out for a vulnerability that can otherwise only exist if a user modifies code on their own machine. That's why clickjacking (and vulnerabilities that can only occur via clickjacking) don't get rewarded.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Physical Testing Findings</h1>
                </header>
            
            <article>
                
<p>Sometimes, firms interested in rigorous security audits go several steps further than just hiring a team to test a website or probe a network—they pay for a researcher to test the physical security perimeter controlling access to their data center. This type of testing is most common in industries with strong compliance policies around access control—PCI compliance, for example, entails that you have taken certain physical security measures (ID cards required for access to the premises, limited access to actual server boxes, and so on) for safeguarding your infrastructure.</p>
<p>Anything even close to physical testing is out-of-bounds for the type of work this book is concerned with. If you've identified a vulnerability that consists of you sneaking in through the company break room and messing with someone's unlocked laptop, that is not a vulnerability. That activity is very much out-of-scope and potentially legally actionable.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Outdated Browsers</h1>
                </header>
            
            <article>
                
<p>When you find a vulnerability that depends on an outdated browser for an attack vector, especially for a comparably ancient install (older than IE 8), it doesn't make sense for a company to reward it with a payout—outdated browsers aren't receiving security updates (and any fix the company might want to apply), after all. Even if the issue can be patched server-side, it makes no sense to carve out exceptions to an applicable end-of-life policy.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Server Information</h1>
                </header>
            
            <article>
                
<p>Although it's a valuable part of the discovery phase in any engagement, discovering the type of server or hosting service is not a bug. Obfuscation is nice, but superfluous, and basic public server data itself doesn't suggest a compelling attack chain worthy of a payout.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Rate-Limiting</h1>
                </header>
            
            <article>
                
<p>Rate-limiting might surprise you as something that has to be explicitly excluded in a program's out-of-scope vulnerabilities, but obviously rate-limiting (protecting your server from getting hosed by selectively throttling requests) is a feature, not a bug.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>This chapter has covered different types of security flaws that typically don't rise to the level of a profitable vulnerability, including DoS/DDoS, Self-XSS, and other types of attacks, as well as information that is commonly reported by scanners and pentesting tools but that don't necessarily interest bug bounty program operators. Along with various miscellaneous out-of-scope vulnerabilities, and an analysis of the common features that link these bugs together (they require other exploits, they have limited reach, they require social engineering or attacks on third-party services, and so on), you should have an understanding of not only what bugs don't get rewarded but <em>why</em> they aren't valuable. Now, moving forward, you can tune your own workflow to lower the noise in your reporting, and build a pentesting regimen that cuts down on time-wasting dead ends and focuses on the vulnerabilities that matter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<ol>
<li>Why are DoS/DDoS attacks typically out-of-scope? What's a scenario where a DoS/DDoS-related bug would merit a reward?</li>
<li>What is Self-XSS? Why does it not usually merit an award?</li>
<li>What's the potential damage of leaving HTTP's <kbd>OPTIONS</kbd> method enabled?</li>
<li>Why don't BEAST and other SSL vulnerabilities typically qualify for bug bounty programs?</li>
<li>What is clickjacking?</li>
</ol>
<ol start="6">
<li>What is physical testing?</li>
<li>What are some things that can make a CSRF vulnerability out-of-scope?</li>
<li>What are dark patterns?</li>
<li>Why aren't brute force-related vulnerabilities rewarded with payouts?</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further Reading</h1>
                </header>
            
            <article>
                
<p>You can find out more about some of the topics we have discussed in this chapter at:</p>
<ul>
<li><strong>Facebook Self-XSS Scam</strong>: <a href="https://www.tomsguide.com/us/facebook-self-xss,news-19224.html">https://www.tomsguide.com/us/facebook-self-xss,news-19224.html</a></li>
<li><strong>GitHub DDoS Attack</strong>: <a href="https://www.theregister.co.uk/2018/03/05/worlds_biggest_ddos_attack_record_broken_after_just_five_days/">https://www.theregister.co.uk/2018/03/05/worlds_biggest_ddos_attack_record_broken_after_just_five_days/</a></li>
<li><strong>TLS/SSL Vulnerability Attacks</strong>: <a href="https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/">https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/</a></li>
<li><strong>Detectify Labs on CSRF Logouts</strong>: <a href="https://labs.detectify.com/2017/03/15/loginlogout-csrf-time-to-reconsider/">https://labs.detectify.com/2017/03/15/loginlogout-csrf-time-to-reconsider/</a></li>
<li><strong>Dark Patterns</strong>: <a href="https://darkpatterns.org/">https://darkpatterns.org/</a></li>
</ul>


            </article>

            
        </section>
    </body></html>