<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Machine Learning for Cybersecurity</h1>
                </header>
            
            <article>
                
<p><span>In</span><span> this chapter, we will cover the fundamental techniques of machine learning. We will use these throughout the book to solve interesting cybersecurity problems. We will cover both foundational algorithms, such as clustering and gradient boosting trees, and solutions to common data challenges, such as imbalanced data and false-positive constraints. A machine learning practitioner in cybersecurity is in a unique and exciting position to leverage enormous amounts of data and create solutions in a constantly evolving landscape.<br/></span></p>
<p class="mce-root">This chapter covers the following recipes:</p>
<ul>
<li>Train-test-splitting your data</li>
<li>Standardizing your data</li>
<li>Summarizing large data using <strong>principal component analysis</strong> (<strong>PCA</strong>)</li>
<li>Generating text using Markov chains</li>
<li>Performing clustering using scikit-learn</li>
<li>Training an XGBoost classifier</li>
<li>Analyzing time series using statsmodels</li>
<li>Anomaly detection using <span>Isolation Forest</span></li>
<li><strong>Natural language processing</strong> (<strong>NLP</strong>) using hashing vectorizer and tf-idf with scikit-learn</li>
<li>Hyperparameter tuning with scikit-optimize</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>In this chapter, we will be using the following:</p>
<ul>
<li>scikit-learn</li>
<li>Markovify</li>
<li>XGBoost</li>
<li>statsmodels</li>
</ul>
<p><span>The installation instructions and code can be found at <a href="https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/tree/master/Chapter01">https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/tree/master/Chapter01</a></span>.<span><a href="https://github.com/emmanueltsukerman/MLforCSCookbook"><br/></a></span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Train-test-splitting your data</h1>
                </header>
            
            <article>
                
<p class="mce-root">In machine learning, our goal is to create a program that is able to perform tasks it has never been explicitly taught to perform. The way we do that is to use data we have collected to <em>train</em> or <em>fit</em> a mathematical or statistical model. The data used to fit the model is referred to as <em>training data</em>. The resulting trained model is then used to predict future, previously-unseen data. In this way, the program is able to manage new situations without human intervention.</p>
<p class="mce-root">One of the major challenges for a machine learning practitioner is the danger of <em>overfitting</em> – creating a model that performs well on the training data but is not able to generalize to new, previously-unseen data. In order to combat the problem of overfitting, machine learning practitioners set aside a portion of the data, called <em>test data</em>, and use it only to assess the performance of the trained model, as opposed to including it as part of the training dataset. This careful setting aside of testing sets is key to training classifiers in cybersecurity, where overfitting is an omnipresent danger. One small oversight, such as using only benign data from one locale, can lead to a poor classifier.</p>
<p>There are various other ways to validate model performance, such as cross-validation. For simplicity, we will focus mainly on train-test splitting.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<div class="a-b-r">
<div class="a-b-r-Tl a-b-va-Zf">
<div class="a-b-r-Ec a-b-tb-Ce">
<div class="a-b-r-x">
<p>Preparation for this recipe consists of installing the scikit-learn and <kbd>pandas</kbd> packages in <kbd>pip</kbd>. The command for this is as follows:</p>
</div>
<div class="a-b-r-x">
<pre><strong>pip install sklearn pandas</strong></pre></div>
</div>
</div>
</div>
<p>In addition, we have included the <kbd>north_korea_missile_test_database.csv</kbd> dataset for use in this recipe.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The following steps demonstrate how to take a dataset, consisting of features <kbd>X</kbd> and labels <kbd>y</kbd>, and split these into a training and testing subset:</p>
<ol>
<li>Start by importing the <kbd>train_test_split</kbd> module and the <kbd>pandas</kbd> library, and read your features into <kbd>X</kbd> and labels into <kbd>y</kbd>:</li>
</ol>
<pre style="padding-left: 60px" class="CDPAlignLeft CDPAlign">from sklearn.model_selection import train_test_split<br/>import pandas as pd<br/><br/>df = pd.read_csv("north_korea_missile_test_database.csv")<br/>y = df["Missile Name"]<br/>X = df.drop("Missile Name", axis=1)</pre>
<ol start="2">
<li>Next, randomly split the dataset and its labels into a training set consisting 80% of the size of the original dataset and a testing set 20% of the size:</li>
</ol>
<pre style="padding-left: 60px">X_train, X_test, y_train, y_test = train_test_split(<br/>    X, y, test_size=0.2, random_state=31<br/>)</pre>
<ol start="3">
<li> We apply the <kbd>train_test_split</kbd> method once more, to obtain a validation set, <kbd>X_val</kbd> and <kbd>y_val</kbd>:</li>
</ol>
<pre style="padding-left: 60px">X_train, X_val, y_train, y_val = train_test_split(<br/>    X_train, y_train, test_size=0.25, random_state=31<br/>)</pre>
<ol start="4">
<li>We end up with a training set that's 60% of the size of the original data, a validation set of 20%, and a testing set of 20%.</li>
</ol>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p style="padding-left: 60px">The following screenshot shows the output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1059 image-border" src="assets/e07b58f8-015b-4ff0-b98f-3ada859d0136.png" style="width:17.75em;height:10.33em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>We start by reading in our dataset, consisting of historical and continuing missile experiments in North Korea. We aim to predict the type of missile based on remaining features, such as facility and time of launch. This concludes step 1. In step 2, we apply scikit-learn's <kbd>train_test_split</kbd> method to subdivide <kbd>X</kbd> and <kbd>y</kbd> into a training set, <kbd>X_train</kbd> and <kbd>y_train</kbd>, and also a testing set, <kbd>X_test</kbd> and <kbd>y_test</kbd>. The <kbd>test_size = 0.2</kbd> parameter means that the testing set consists of 20% of the original data, while the remainder is placed in the training set. The <kbd>random_state</kbd> parameter allows us to reproduce the same <em>randomly generated</em> split. Next, concerning step 3, it is important to note that, in applications, we often want to compare several different models. The danger of using the testing set to select the best model is that we may end up overfitting the testing set. This is similar to the statistical sin of data fishing. In order to combat this danger, we create an additional dataset, called the validation set. We train our models on the training set, use the validation set to compare them, and finally use the testing set to obtain an accurate indicator of the performance of the model we have chosen. So, in step 3, we choose our parameters so that, mathematically speaking, the end result consists of a training set of 60% of the original dataset, a validation set of 20%, and a testing set of 20%. Finally, we double-check our assumptions by employing the <kbd>len</kbd> function to compute the length of the arrays (step 4).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Standardizing your data</h1>
                </header>
            
            <article>
                
<p>For many machine learning algorithms, performance is highly sensitive to the relative scale of features. For that reason, it is often important to <em>standardize </em>your features. To standardize a feature means to shift all of its values so that their mean = 0 and to scale them so that their variance = 1.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>One instance when normalizing is useful is when featuring the PE header of a file. The PE header contains extremely large values (for example, the <kbd>SizeOfInitializedData</kbd> field) and also very small ones (<span>for example</span>, the number of sections). For certain ML models, such as neural networks, the large discrepancy in magnitude between features can reduce performance.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<div class="a-b-r">
<div class="a-b-r-Tl a-b-va-Zf">
<div class="a-b-r-Ec a-b-tb-Ce">
<div class="a-b-r-x">
<p>Preparation for this recipe consists of installing the <kbd>scikit-learn</kbd> and <kbd>pandas</kbd> packages in <kbd>pip</kbd>. Perform the following steps:</p>
</div>
<div class="a-b-r-x">
<pre><strong>pip install sklearn pandas</strong></pre>
<p>In addition, you will find <span>a dataset named <kbd>file_pe_headers.csv</kbd> </span>in the <span>repository</span> for this recipe.</p>
</div>
</div>
</div>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>In the following steps, we utilize scikit-learn's <kbd>StandardScaler</kbd> method to standardize our data:</p>
<ol>
<li>Start by importing the required libraries and gathering a dataset, <kbd>X</kbd>:</li>
</ol>
<pre style="padding-left: 60px">import pandas as pd<br/><br/>data = pd.read_csv("file_pe_headers.csv", sep=",")<br/>X = data.drop(["Name", "Malware"], axis=1).to_numpy()</pre>
<p style="padding-left: 60px">Dataset <kbd>X</kbd> looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1060 image-border" src="assets/dd02cfd2-e3d5-411d-9192-89815651d799.png" style="width:31.42em;height:12.67em;"/></p>
<ol start="2">
<li>Next, standardize <kbd>X</kbd> using a <kbd>StandardScaler</kbd> instance:</li>
</ol>
<pre style="padding-left: 60px">from sklearn.preprocessing import StandardScaler<br/><br/>X_standardized = StandardScaler().fit_transform(X)</pre>
<p style="padding-left: 60px" class="CDPAlignLeft CDPAlign">The standardized dataset looks like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1061 image-border" src="assets/d70b9c6a-48d9-459c-bb08-8f2c50afc2cf.png" style="width:35.25em;height:14.08em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>We begin by reading in our dataset (step 1), which consists of the PE header information for a collection of PE files. These vary greatly, with some columns reaching hundreds of thousands of files, and others staying in the single digits. Consequently, certain models, such as neural networks, will perform poorly on such unstandardized data. In step 2, we instantiate <kbd>StandardScaler()</kbd> and then apply it to rescale <kbd>X</kbd> using <kbd>.fit_transform(X)</kbd>. As a result, we obtained a rescaled dataset, whose columns (corresponding to features) have a mean of 0 and a variance of 1.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summarizing large data using principal component analysis</h1>
                </header>
            
            <article>
                
<p>Suppose that you would like to build a predictor for an individual's expected net fiscal worth at age 45. There are a huge number of variables to be considered: IQ, current fiscal worth, marriage status, height, geographical location, health, education, career state, age, and many others you might come up with, such as number of LinkedIn connections or SAT scores.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The trouble with having so many features is several-fold. First, the amount of data, which will incur high storage costs and computational time for your algorithm. Second, with a large feature space, it is critical to have a large amount of data for the model to be accurate. That's to say, it becomes harder to distinguish the signal from the noise. For these reasons, when dealing with high-dimensional data such as this, we often employ dimensionality reduction techniques, such as PCA. More information on the topic can be found at <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">https://en.wikipedia.org/wiki/Principal_component_analysis</a>.</p>
<p>PCA allows us to take our features and return a smaller number of new features, formed from our original ones, with maximal explanatory power. In addition, since the new features are linear combinations of the old features, this allows us to anonymize our data, which is very handy when working with financial information, for example.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<div class="a-b-r">
<div class="a-b-r-Tl a-b-va-Zf">
<div class="a-b-r-Ec a-b-tb-Ce">
<div class="a-b-r-x">
<p>The preparation for this recipe consists of installing the scikit-learn and <kbd>pandas</kbd> packages in <kbd>pip</kbd>. The command for this is as follows:</p>
</div>
<div class="a-b-r-x">
<pre><strong>pip install sklearn pandas</strong></pre>
<p>In addition, we will be utilizing the same dataset, <kbd>malware_pe_headers.csv</kbd>, as in the previous recipe.</p>
</div>
</div>
</div>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>In this section, we'll walk through a recipe showing how to use PCA on data:</p>
<ol>
<li><span>Start </span>by importing the necessary libraries and reading in the dataset:</li>
</ol>
<pre style="padding-left: 60px">from sklearn.decomposition import PCA<br/>import pandas as pd<br/><br/>data = pd.read_csv("file_pe_headers.csv", sep=",")<br/>X = data.drop(["Name", "Malware"], axis=1).to_numpy()</pre>
<ol start="2">
<li>Standardize the dataset, as is necessary before applying PCA:</li>
</ol>
<pre style="padding-left: 60px">from sklearn.preprocessing import StandardScaler<br/><br/>X_standardized = StandardScaler().fit_transform(X)</pre>
<ol start="3">
<li>Instantiate a <kbd>PCA</kbd> instance and use it to reduce the dimensionality of our data:</li>
</ol>
<pre style="padding-left: 60px">pca = PCA()<br/>pca.fit_transform(X_standardized)</pre>
<ol start="4">
<li>Assess the effectiveness of your dimensionality reduction:</li>
</ol>
<pre style="padding-left: 60px">print(pca.explained_variance_ratio_)</pre>
<p style="padding-left: 60px">The following screenshot shows the output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1062 image-border" src="assets/31a84424-30b5-4159-83a6-ee81ae91fccb.png" style="width:37.08em;height:25.00em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>We begin by reading in our dataset and then standardizing it, as in the recipe on standardizing data (steps 1 and 2). (It is necessary to work with standardized data before applying PCA). We now instantiate a new PCA transformer instance, and use it to both learn the transformation (fit) and also apply the transform to the dataset, using <kbd>fit_transform</kbd> (step 3). In step 4, we analyze our transformation. In particular, note that the elements of <kbd>pca.explained_variance_ratio_</kbd> indicate how much of the variance is accounted for in each direction. The sum is 1, indicating that all the variance is accounted for if we consider the full space in which the data lives. However, just by taking the first few directions, we can account for a large portion of the variance, while limiting our dimensionality. In our example, the first 40 directions account for 90% of the variance:</p>
<pre class="mce-root">sum(pca.explained_variance_ratio_[0:40])</pre>
<div class="output">
<p class="output_area">This produces the following output:</p>
</div>
<div class="output_subarea output_text output_result">
<pre>0.9068522354673663</pre></div>
<p>This means that we can reduce our number of features to 40 (from 78) while preserving 90% of the variance. The implications of this are that many of the features of the PE header are closely correlated, which is understandable, as they are not designed to be independent.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Generating text using Markov chains</h1>
                </header>
            
            <article>
                
<p>Markov chains are simple stochastic models in which a system can exist in a number of states. To know the probability distribution of where the system will be next, it suffices to know where it currently is. This is in contrast with a system in which the probability distribution of the subsequent state may depend on the past history of the system. This simplifying assumption allows Markov chains to be easily applied in many domains, surprisingly fruitfully.</p>
<p>In this recipe, we will utilize Markov chains to generate fake reviews, which is useful for pen-testing a review system's spam detector. In a later recipe, you will upgrade the technology from Markov chains to RNNs.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<div class="a-b-r">
<div class="a-b-r-Tl a-b-va-Zf">
<div class="a-b-r-Ec a-b-tb-Ce">
<div class="a-b-r-x">
<p>Preparation for this recipe consists of installing the <kbd>markovify</kbd> and <kbd>pandas</kbd> packages in <kbd>pip</kbd>. The command for this is as follows:</p>
</div>
<div class="a-b-r-x">
<pre><strong>pip install markovify pandas</strong></pre>
<p>In addition, the directory in the repository for this chapter includes a CSV dataset, <kbd>airport_reviews.csv</kbd>, which should be placed alongside the code for the chapter.</p>
</div>
</div>
</div>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>Let's see how to generate text using Markov chains by performing the following steps:</p>
<ol>
<li>Start by importing the <kbd>markovify</kbd> library and a text file whose style we would like to imitate:</li>
</ol>
<pre style="padding-left: 60px">import markovify<br/>import pandas as pd<br/><br/>df = pd.read_csv("airport_reviews.csv")</pre>
<p style="padding-left: 60px">As an illustration, I have chosen a collection of airport reviews as my text:</p>
<pre style="padding-left: 60px">"The airport is certainly tiny! ..."</pre>
<ol start="2">
<li>Next, join the individual reviews into one large text string and build a Markov chain model using the airport review text:</li>
</ol>
<pre style="padding-left: 60px">from itertools import chain<br/><br/>N = 100<br/>review_subset = df["content"][0:N]<br/>text = "".join(chain.from_iterable(review_subset))<br/>markov_chain_model = markovify.Text(text)</pre>
<p style="padding-left: 60px">Behind the scenes, the library computes the transition word probabilities from the text.</p>
<ol start="3">
<li>Generate five sentences using the Markov chain model:</li>
</ol>
<pre style="padding-left: 60px">for i in range(5):<br/>    print(markov_chain_model.make_sentence())</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<ol start="4">
<li>Since we are using airport reviews, we will have the following as the output after executing the previous code:</li>
</ol>
<div class="output_subarea output_text output_stream output_stdout">
<pre style="padding-left: 60px">On the positive side it's a clean airport transfer from A to C gates and outgoing gates is truly enormous - but why when we arrived at about 7.30 am for our connecting flight to Venice on TAROM.<br/>The only really bother: you may have to wait in a polite manner.<br/>Why not have bus after a short wait to check-in there were a lots of shops and less seating.<br/>Very inefficient and hostile airport. This is one of the time easy to access at low price from city center by train.<br/>The distance between the incoming gates and ending with dirty and always blocked by never ending roadworks.</pre></div>
<p style="padding-left: 60px">Surprisingly realistic! Although the reviews would have to be filtered down to the best ones.</p>
<ol start="5">
<li>Generate <kbd>3</kbd> sentences with a length of no more than <kbd>140</kbd> characters:</li>
</ol>
<pre style="padding-left: 60px">for i in range(3):<br/>    print(markov_chain_model.make_short_sentence(140))</pre>
<p style="padding-left: 60px">With our running example, we will see the following output:</p>
<div class="output_subarea output_text output_stream output_stdout">
<pre style="padding-left: 60px">However airport staff member told us that we were put on a connecting code share flight.<br/>Confusing in the check-in agent was friendly.<br/>I am definitely not keen on coming to the lack of staff . Lack of staff . Lack of staff at boarding pass at check-in.</pre></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>We begin the recipe by importing the Markovify library, a library for Markov chain computations, and reading in text, which will inform our Markov model (step 1). In step 2, we create a Markov chain model using the text. The following is a relevant snippet from the text object's initialization code:</p>
<pre>class Text(object):<br/><br/>    reject_pat = re.compile(r"(^')|('$)|\s'|'\s|[\"(\(\)\[\])]")<br/><br/>    def __init__(self, input_text, state_size=2, chain=None, parsed_sentences=None, retain_original=True, well_formed=True, reject_reg=''):<br/>        """<br/>        input_text: A string.<br/>        state_size: An integer, indicating the number of words in the model's state.<br/>        chain: A trained markovify.Chain instance for this text, if pre-processed.<br/>        parsed_sentences: A list of lists, where each outer list is a "run"<br/>              of the process (e.g. a single sentence), and each inner list<br/>              contains the steps (e.g. words) in the run. If you want to simulate<br/>              an infinite process, you can come very close by passing just one, very<br/>              long run.<br/>        retain_original: Indicates whether to keep the original corpus.<br/>        well_formed: Indicates whether sentences should be well-formed, preventing<br/>              unmatched quotes, parenthesis by default, or a custom regular expression<br/>              can be provided.<br/>        reject_reg: If well_formed is True, this can be provided to override the<br/>              standard rejection pattern.<br/>        """</pre>
<p>The most important parameter to understand is <kbd>state_size = 2</kbd>, which means that the Markov chains will be computing transitions between consecutive pairs of words. For more realistic sentences, this parameter can be increased, at the cost of making sentences appear less original. Next, we apply the Markov chains we have trained to generate a few example sentences (steps 3 and 4). We can see clearly that the Markov chains have captured the tone and style of the text. Finally, in step 5, we create a few <kbd>tweets</kbd> in the style of the airport reviews using our Markov chains.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Performing clustering using scikit-learn</h1>
                </header>
            
            <article>
                
<p><strong>Clustering</strong> is a collection of unsupervised machine learning algorithms in which parts of the data are grouped based on similarity. For example, clusters might consist of data that is close together in n-dimensional Euclidean space. Clustering is useful in cybersecurity for distinguishing between normal and anomalous network activity, and for helping to classify malware into families.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Preparation for this recipe consists of installing the <kbd>scikit-learn</kbd>, <kbd>pandas</kbd>, and <kbd>plotly</kbd> packages in <kbd>pip</kbd>. The command for this is as follows:</p>
<pre><strong>pip install sklearn plotly pandas</strong></pre>
<p>In addition, a dataset named <kbd>file_pe_header.csv</kbd> is provided in the repository for this recipe.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>In the following steps, we will see a demonstration of how scikit-learn's K-means clustering algorithm performs on a toy PE malware classification:</p>
<ol>
<li>Start by importing and plotting the dataset:</li>
</ol>
<pre style="padding-left: 60px">import pandas as pd<br/>import plotly.express as px<br/><br/>df = pd.read_csv("file_pe_headers.csv", sep=",")<br/>fig = px.scatter_3d(<br/>    df,<br/>    x="SuspiciousImportFunctions",<br/>    y="SectionsLength",<br/>    z="SuspiciousNameSection",<br/>    color="Malware",<br/>)<br/>fig.show()</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p style="padding-left: 60px">The following screenshot shows the output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1063 image-border" src="assets/d5b81582-3439-462a-b2fd-90c0cb515aa0.png" style="width:39.50em;height:28.33em;"/></p>
<ol start="2">
<li>Extract the features and target labels:</li>
</ol>
<pre style="padding-left: 60px">y = df["Malware"]<br/>X = df.drop(["Name", "Malware"], axis=1).to_numpy()</pre>
<ol start="3">
<li>Next, import <span>scikit-learn's</span> clustering module and fit a K-means model with two clusters to the data:</li>
</ol>
<pre style="padding-left: 60px">from sklearn.cluster import KMeans<br/><br/>estimator = KMeans(n_clusters=len(set(y)))<br/>estimator.fit(X)</pre>
<ol start="4">
<li>Predict the cluster using our trained algorithm:</li>
</ol>
<pre style="padding-left: 60px">y_pred = estimator.predict(X)<br/>df["pred"] = y_pred<br/>df["pred"] = df["pred"].astype("category")</pre>
<ol start="5">
<li>To see how the algorithm did, plot the algorithm's clusters:</li>
</ol>
<pre style="padding-left: 60px">fig = px.scatter_3d(<br/>    df,<br/>    x="SuspiciousImportFunctions",<br/>    y="SectionsLength",<br/>    z="SuspiciousNameSection",<br/>    color="pred",<br/>)<br/>fig.show()</pre>
<p style="padding-left: 60px">The following screenshot shows the output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1208 image-border" src="assets/869390eb-e597-455c-801f-844687dc056e.png" style="width:35.08em;height:24.50em;"/></p>
<p>The results are not perfect, but we can see that the clustering algorithm captured much of the structure in the dataset.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>We start by importing our dataset of PE header information from a collection of samples (step 1). This dataset consists of two classes of PE files: malware and benign. We then use plotly to create a nice-looking interactive 3D graph (step 1). We proceed to prepare our dataset for machine learning. Specifically, in step 2, we set <kbd>X</kbd> as the features and y as the classes of the dataset. Based on the fact that there are two classes, we aim to cluster the data into two groups that will match the sample classification. We utilize the K-means algorithm (step 3), about which you can find more information at: <a href="https://en.wikipedia.org/wiki/K-means_clustering">https://en.wikipedia.org/wiki/K-means_clustering</a>. With a thoroughly trained clustering algorithm, we are ready to predict on the testing set. We apply our clustering algorithm to predict to which cluster each of the samples should belong (step 4). Observing our results in step 5, we see that clustering has captured a lot of the underlying information, as it was able to fit the data well.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Training an XGBoost classifier</h1>
                </header>
            
            <article>
                
<p>Gradient boosting is widely considered the most reliable and accurate algorithm for generic machine learning problems. We will utilize XGBoost to create malware detectors in future recipes.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>The preparation for this recipe consists of installing the scikit-learn, <kbd>pandas</kbd>, and <kbd>xgboost</kbd> packages in <kbd>pip</kbd>. The command for this is as follows:</p>
<pre><strong>pip install sklearn xgboost pandas</strong></pre>
<p>In addition, a dataset named <kbd>file_pe_header.csv</kbd> is provided in the repository for this recipe.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>In the following steps, we will demonstrate how to instantiate, train, and test an XGBoost classifier:</p>
<ol>
<li>Start by reading in the data:</li>
</ol>
<pre style="padding-left: 60px">import pandas as pd<br/><br/>df = pd.read_csv("file_pe_headers.csv", sep=",")<br/>y = df["Malware"]<br/>X = df.drop(["Name", "Malware"], axis=1).to_numpy()</pre>
<ol start="2">
<li>Next, train-test-split a dataset:</li>
</ol>
<pre style="padding-left: 60px">from sklearn.model_selection import train_test_split<br/><br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)</pre>
<ol start="3">
<li>Create one instance of an XGBoost model and train it on the training set:</li>
</ol>
<pre style="padding-left: 60px">from xgboost import XGBClassifier<br/><br/>XGB_model_instance = XGBClassifier()<br/>XGB_model_instance.fit(X_train, y_train)</pre>
<ol start="4">
<li>Finally, assess its performance on the testing set:</li>
</ol>
<pre style="padding-left: 60px">from sklearn.metrics import accuracy_score<br/><br/>y_test_pred = XGB_model_instance.predict(X_test)<br/>accuracy = accuracy_score(y_test, y_test_pred)<br/>print("Accuracy: %.2f%%" % (accuracy * 100))</pre>
<p style="padding-left: 60px">The following screenshot shows the output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1065 image-border" src="assets/0697316c-043c-48d1-9a3f-4eee7867f25f.png" style="width:7.67em;height:1.33em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>We begin by reading in our data (step 1). We then create a train-test split (step 2). We proceed to instantiate an XGBoost classifier with default parameters and fit it to our training set (step 3). Finally, in step 4, we use our XGBoost classifier to predict on the testing set. We then produce the measured accuracy of our XGBoost model's predictions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Analyzing time series using statsmodels</h1>
                </header>
            
            <article>
                
<p>A time series is a series of values obtained at successive times. For example, the price of the stock market sampled every minute forms a time series. In cybersecurity, time series analysis can be very handy for predicting a cyberattack, such as an insider employee exfiltrating data, or a group of hackers colluding in preparation for their next hit.</p>
<p>Let's look at several techniques for making predictions using time series.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Preparation for this recipe consists of installing the <kbd>matplotlib</kbd>, <kbd>statsmodels</kbd>, and <kbd>scipy</kbd> packages in <kbd>pip</kbd>. The command for this is as follows:</p>
<pre><strong>pip install matplotlib statsmodels scipy</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>In the following steps, we demonstrate several methods for making predictions using time series data:</p>
<ol>
<li>Begin by generating a time series:</li>
</ol>
<pre style="padding-left: 60px">from random import random<br/><br/>time_series = [2 * x + random() for x in range(1, 100)]</pre>
<ol start="2">
<li>Plot your data:</li>
</ol>
<pre style="padding-left: 60px">%matplotlib inline<br/>import matplotlib.pyplot as plt<br/><br/>plt.plot(time_series)<br/>plt.show()</pre>
<p style="padding-left: 60px">The following screenshot shows the output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1066 image-border" src="assets/1d04a34d-bfe3-441d-b431-a92458457502.png" style="width:24.00em;height:16.00em;"/></p>
<ol start="3">
<li>There is a large variety of techniques we can use to predict the consequent value of a time series:
<ul>
<li><strong>Autoregression</strong> (<strong>AR</strong>):</li>
</ul>
</li>
</ol>
<pre style="padding-left: 120px">from statsmodels.tsa.ar_model import AR<br/><br/>model = AR(time_series)<br/>model_fit = model.fit()<br/>y = model_fit.predict(len(time_series), len(time_series))</pre>
<ol start="3">
<li style="list-style-type: none">
<ul>
<li><strong>Moving average</strong> (<strong>MA</strong>):</li>
</ul>
</li>
</ol>
<pre style="padding-left: 120px">from statsmodels.tsa.arima_model import ARMA<br/><br/>model = ARMA(time_series, order=(0, 1))<br/>model_fit = model.fit(disp=False)<br/>y = model_fit.predict(len(time_series), len(time_series))</pre>
<ol start="3">
<li style="list-style-type: none">
<ul>
<li><strong>Simple exponential smoothing</strong> (<strong>SES</strong>):</li>
</ul>
</li>
</ol>
<pre style="padding-left: 120px">from statsmodels.tsa.holtwinters import SimpleExpSmoothing<br/><br/>model = SimpleExpSmoothing(time_series)<br/>model_fit = model.fit()<br/>y = model_fit.predict(len(time_series), len(time_series))</pre>
<p>The resulting predictions are as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1067 image-border" src="assets/b35f14f9-0bb6-425d-bbc3-c32e1b3be02c.png" style="width:32.00em;height:33.92em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>In the first step, we generate a simple toy time series. The series consists of values on a line sprinkled with some added noise. Next, we plot our time series in step 2. You can see that it is very close to a straight line and that a sensible prediction for the value of the time series at time <img class="fm-editor-equation" src="assets/bb728aba-f0a1-493f-a6d3-c8a52662bd65.png" style="width:0.42em;height:0.92em;"/> is <img class="fm-editor-equation" src="assets/f8365b1e-32c3-4f44-8eba-a235d3e09405.png" style="width:1.00em;height:1.00em;"/>. To create a forecast of the value of the time series, we consider three different schemes (step 3) for predicting the future values of the time series. In an autoregressive model, the basic idea is that the value of the time series at time <em>t</em> is a linear function of the values of the time series at the previous times. More precisely, there are some constants, <img class="fm-editor-equation" src="assets/78f5feb2-6573-41aa-a3e9-ace1a6660c99.png" style="width:6.83em;height:0.92em;"/>, and a number, <img class="fm-editor-equation" src="assets/039e0190-78eb-4e7a-ad1c-e30f1f0e6473.png" style="width:0.50em;height:0.83em;"/>, such that:</p>
<p style="padding-left: 150px" class="CDPAlignLeft CDPAlign"><img class="alignnone size-full wp-image-1068 image-border" src="assets/e6d48f5b-64b0-444d-9eee-4a7e31a2b667.png" style="width:23.75em;height:1.33em;"/></p>
<p>As a hypothetical example, <img class="fm-editor-equation" src="assets/dba51c21-ae4d-485d-b878-0f7f04b88c3c.png" style="width:0.50em;height:0.83em;"/> may be <em>3</em>, meaning that the value of the time series can be easily computed from knowing its last <em>3</em> values.</p>
<p>In the moving-average model, the time series is modeled as fluctuating about a mean. More precisely, let <img class="fm-editor-equation" src="assets/176f6dfd-d61f-4a5d-a8bf-7d1447efd15e.png" style="width:1.25em;height:0.92em;"/> be a sequence of i.i.d normal variables and let <img class="fm-editor-equation" src="assets/1b146731-b7ad-42a1-9901-80df10e48329.png" style="width:1.00em;height:1.17em;"/> be a constant. Then, the time series is modeled by the following formula:</p>
<p style="padding-left: 210px"><img class="alignnone size-full wp-image-1069 image-border" src="assets/c4c6352b-d94c-4d62-90fe-99519dbea008.png" style="width:10.58em;height:1.25em;"/></p>
<p>For that reason, it performs poorly in predicting the noisy linear time series we have generated.</p>
<p>Finally, in simple exponential smoothing, we propose a smoothing parameter, <img class="fm-editor-equation" src="assets/fe2653e2-e6f5-4665-b6cb-cd0585722359.png" style="width:3.42em;height:0.67em;"/>. Then, our model's estimate, <img class="fm-editor-equation" src="assets/0b46364e-73ee-499f-8a9a-4ab7013880b4.png" style="width:1.17em;height:1.08em;"/>, is computed from the following equations:</p>
<p style="padding-left: 210px"><img class="alignnone size-full wp-image-1070 image-border" src="assets/5590c81b-0f15-4fd5-bf0b-b9b4dc074eb2.png" style="width:4.25em;height:1.00em;"/></p>
<p style="padding-left: 180px"><img class="alignnone size-full wp-image-1071 image-border" src="assets/962f5ffe-7714-4e71-94ea-36e8b861cdfe.png" style="width:12.25em;height:1.50em;"/></p>
<p>In other words, we keep track of an estimate, <img class="fm-editor-equation" src="assets/bd3be59f-8df1-4602-9425-552842dbd7c4.png" style="width:1.17em;height:1.08em;"/>, and adjust it slightly using the current time series value, <img class="fm-editor-equation" src="assets/9fe675db-c5a5-4b58-9190-28199fb71327.png" style="width:1.17em;height:1.17em;"/>. How strongly the adjustment is made is regulated by the <img class="fm-editor-equation" src="assets/91976144-4a0c-46e8-96e0-9d996cca4b39.png" style="width:0.92em;height:0.83em;"/> <span>parameter</span>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Anomaly detection with Isolation Forest</h1>
                </header>
            
            <article>
                
<p>Anomaly detection is the identification of events in a dataset that do not conform to the expected pattern. In applications, these events may be of critical importance. For instance, they may be occurrences of a network intrusion or of fraud. We will utilize Isolation Forest to detect such anomalies. Isolation Forest relies on the observation that it is easy to isolate an outlier, while more difficult to describe a normal data point.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>The preparation for this recipe consists of installing the <kbd>matplotlib</kbd>, <kbd>pandas</kbd>, and <kbd>scipy</kbd> packages in <kbd>pip</kbd>. The command for this is as follows:</p>
<pre><strong>pip install matplotlib pandas scipy</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>In the next steps, we demonstrate how to apply the Isolation Forest algorithm to detecting anomalies:</p>
<ol>
<li>Import the required libraries and set a random seed:</li>
</ol>
<pre style="padding-left: 60px">import numpy as np<br/>import pandas as pd<br/><br/>random_seed = np.random.RandomState(12)</pre>
<ol start="2">
<li>Generate a set of normal observations, to be used as training data:</li>
</ol>
<pre style="padding-left: 60px">X_train = 0.5 * random_seed.randn(500, 2)<br/>X_train = np.r_[X_train + 3, X_train]<br/>X_train = pd.DataFrame(X_train, columns=["x", "y"])</pre>
<ol start="3">
<li>Generate a testing set, also consisting of normal observations:</li>
</ol>
<pre style="padding-left: 60px">X_test = 0.5 * random_seed.randn(500, 2)<br/>X_test = np.r_[X_test + 3, X_test]<br/>X_test = pd.DataFrame(X_test, columns=["x", "y"])</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="4">
<li>Generate a set of outlier observations. These are generated from a different distribution than the normal observations:</li>
</ol>
<pre style="padding-left: 60px">X_outliers = random_seed.uniform(low=-5, high=5, size=(50, 2))<br/>X_outliers = pd.DataFrame(X_outliers, columns=["x", "y"])</pre>
<ol start="5">
<li>Let's take a look at the data we have generated:</li>
</ol>
<pre style="padding-left: 60px">%matplotlib inline<br/>import matplotlib.pyplot as plt<br/><br/>p1 = plt.scatter(X_train.x, X_train.y, c="white", s=50, edgecolor="black")<br/>p2 = plt.scatter(X_test.x, X_test.y, c="green", s=50, edgecolor="black")<br/>p3 = plt.scatter(X_outliers.x, X_outliers.y, c="blue", s=50, edgecolor="black")<br/>plt.xlim((-6, 6))<br/>plt.ylim((-6, 6))<br/>plt.legend(<br/>    [p1, p2, p3],<br/>    ["training set", "normal testing set", "anomalous testing set"],<br/>    loc="lower right",<br/>)<br/><br/>plt.show()</pre>
<p style="padding-left: 60px">The following screenshot shows the output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1072 image-border" src="assets/62e1ed8c-6c95-4fbc-bf15-8f69ca89cb4b.png" style="width:24.50em;height:16.50em;"/></p>
<p> </p>
<ol start="6">
<li>Now train an Isolation Forest model on our training data:</li>
</ol>
<pre style="padding-left: 60px">from sklearn.ensemble import IsolationForest<br/><br/>clf = IsolationForest()<br/>clf.fit(X_train)<br/>y_pred_train = clf.predict(X_train)<br/>y_pred_test = clf.predict(X_test)<br/>y_pred_outliers = clf.predict(X_outliers)</pre>
<ol start="7">
<li>Let's see how the algorithm performs. Append the labels to <kbd>X_outliers</kbd>:</li>
</ol>
<pre style="padding-left: 60px">X_outliers = X_outliers.assign(pred=y_pred_outliers)<br/>X_outliers.head()</pre>
<p style="padding-left: 60px">The following is the output:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<thead>
<tr>
<th class="CDPAlignCenter CDPAlign"/>
<th class="CDPAlignCenter CDPAlign">x</th>
<th class="CDPAlignCenter CDPAlign">y</th>
<th class="CDPAlignCenter CDPAlign">pred</th>
</tr>
</thead>
<tbody>
<tr>
<td class="CDPAlignCenter CDPAlign">0</td>
<td class="CDPAlignCenter CDPAlign">3.947504</td>
<td class="CDPAlignCenter CDPAlign">2.891003</td>
<td class="CDPAlignCenter CDPAlign">1</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">1</td>
<td class="CDPAlignCenter CDPAlign">0.413976</td>
<td class="CDPAlignCenter CDPAlign">-2.025841</td>
<td class="CDPAlignCenter CDPAlign">-1</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">2</td>
<td class="CDPAlignCenter CDPAlign">-2.644476</td>
<td class="CDPAlignCenter CDPAlign">-3.480783</td>
<td class="CDPAlignCenter CDPAlign">-1</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">3</td>
<td class="CDPAlignCenter CDPAlign">-0.518212</td>
<td class="CDPAlignCenter CDPAlign">-3.386443</td>
<td class="CDPAlignCenter CDPAlign">-1</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">4</td>
<td class="CDPAlignCenter CDPAlign">2.977669</td>
<td class="CDPAlignCenter CDPAlign">2.215355</td>
<td class="CDPAlignCenter CDPAlign">1</td>
</tr>
</tbody>
</table>
<ol start="8">
<li>Let's plot the <span>Isolation Forest predictions </span>on the outliers to see how many it caught:</li>
</ol>
<pre style="padding-left: 60px">p1 = plt.scatter(X_train.x, X_train.y, c="white", s=50, edgecolor="black")<br/>p2 = plt.scatter(<br/>    X_outliers.loc[X_outliers.pred == -1, ["x"]],<br/>    X_outliers.loc[X_outliers.pred == -1, ["y"]],<br/>    c="blue",<br/>    s=50,<br/>    edgecolor="black",<br/>)<br/>p3 = plt.scatter(<br/>    X_outliers.loc[X_outliers.pred == 1, ["x"]],<br/>    X_outliers.loc[X_outliers.pred == 1, ["y"]],<br/>    c="red",<br/>    s=50,<br/>    edgecolor="black",<br/>)<br/><br/>plt.xlim((-6, 6))<br/>plt.ylim((-6, 6))<br/>plt.legend(<br/>    [p1, p2, p3],<br/>    ["training observations", "detected outliers", "incorrectly labeled outliers"],<br/>    loc="lower right",<br/>)<br/><br/>plt.show()</pre>
<p style="padding-left: 60px">The following screenshot shows the output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1073 image-border" src="assets/724ae20b-2325-4b22-8324-849089f48d95.png" style="width:21.00em;height:14.17em;"/></p>
<ol start="9">
<li>Now let's see how it performed on the normal testing data. Append the predicted label to <kbd>X_test</kbd>:</li>
</ol>
<pre style="padding-left: 60px">X_test = X_test.assign(pred=y_pred_test)<br/>X_test.head()</pre>
<p>The following is the output:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<thead>
<tr>
<th class="CDPAlignCenter CDPAlign"/>
<th class="CDPAlignCenter CDPAlign">x</th>
<th class="CDPAlignCenter CDPAlign">y</th>
<th class="CDPAlignCenter CDPAlign">pred</th>
</tr>
</thead>
<tbody>
<tr>
<td class="CDPAlignCenter CDPAlign">0</td>
<td class="CDPAlignCenter CDPAlign">3.944575</td>
<td class="CDPAlignCenter CDPAlign">3.866919</td>
<td class="CDPAlignCenter CDPAlign">-1</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">1</td>
<td class="CDPAlignCenter CDPAlign">2.984853</td>
<td class="CDPAlignCenter CDPAlign">3.142150</td>
<td class="CDPAlignCenter CDPAlign">1</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">2</td>
<td class="CDPAlignCenter CDPAlign">3.501735</td>
<td class="CDPAlignCenter CDPAlign">2.168262</td>
<td class="CDPAlignCenter CDPAlign">1</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">3</td>
<td class="CDPAlignCenter CDPAlign">2.906300</td>
<td class="CDPAlignCenter CDPAlign">3.233826</td>
<td class="CDPAlignCenter CDPAlign">1</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">4</td>
<td class="CDPAlignCenter CDPAlign">3.273225</td>
<td class="CDPAlignCenter CDPAlign">3.261790</td>
<td class="CDPAlignCenter CDPAlign">1</td>
</tr>
</tbody>
</table>
<ol start="10">
<li>Now let's plot the results to see whether our classifier labeled the normal testing data correctly:</li>
</ol>
<pre style="padding-left: 60px">p1 = plt.scatter(X_train.x, X_train.y, c="white", s=50, edgecolor="black")<br/>p2 = plt.scatter(<br/>    X_test.loc[X_test.pred == 1, ["x"]],<br/>    X_test.loc[X_test.pred == 1, ["y"]],<br/>    c="blue",<br/>    s=50,<br/>    edgecolor="black",<br/>)<br/>p3 = plt.scatter(<br/>    X_test.loc[X_test.pred == -1, ["x"]],<br/>    X_test.loc[X_test.pred == -1, ["y"]],<br/>    c="red",<br/>    s=50,<br/>    edgecolor="black",<br/>)<br/><br/>plt.xlim((-6, 6))<br/>plt.ylim((-6, 6))<br/>plt.legend(<br/>    [p1, p2, p3],<br/>    [<br/>        "training observations",<br/>        "correctly labeled test observations",<br/>        "incorrectly labeled test observations",<br/>    ],<br/>    loc="lower right",<br/>)<br/><br/>plt.show()</pre>
<p style="padding-left: 60px">The following screenshot shows the output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1074 image-border" src="assets/60609e2c-972c-4f26-ad58-4000736e81d6.png" style="width:24.75em;height:16.67em;"/></p>
<p class="mce-root"/>
<p>Evidently, our Isolation Forest model performed quite well at capturing the anomalous points. There were quite a few false negatives (instances where normal points were classified as outliers), but by tuning our model's parameters, we may be able to reduce these.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>The first step involves simply loading the necessary libraries that will allow us to manipulate data quickly and easily. In steps 2 and 3, we generate a training and testing set consisting of normal observations. These have the same distributions. In step 4, on the other hand, we generate the remainder of our testing set by creating outliers. This anomalous dataset has a different distribution from the training data and the rest of the testing data. Plotting our data, we see that some outlier points look indistinguishable from normal points (step 5). This guarantees that our classifier will have a significant percentage of misclassifications, due to the nature of the data, and we must keep this in mind when evaluating its performance. In step 6, we fit an instance of Isolation Forest with default parameters to the training data.</p>
<p>Note that the algorithm is fed no information about the anomalous data. We use our trained instance of Isolation Forest to predict whether the testing data is normal or anomalous, and similarly to predict whether the anomalous data is normal or anomalous. To examine how the algorithm performs, we append the predicted labels to <kbd>X_outliers</kbd> (step 7) and then plot the predictions of the Isolation Forest instance on the outliers (step 8). We see that it was able to capture most of the anomalies. Those that were incorrectly labeled were indistinguishable from normal observations. Next, in step 9, we append the predicted label to <kbd>X_test</kbd> in preparation for analysis and then plot the predictions of the Isolation Forest instance on the normal testing data (step 10). We see that it correctly labeled the majority of normal observations. At the same time, there was a significant number of incorrectly classified normal observations (shown in red).</p>
<p>Depending on how many false alarms we are willing to tolerate, we may need to fine-tune our classifier to reduce the number of false positives.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Natural language processing using a hashing vectorizer and tf-idf with scikit-learn</h1>
                </header>
            
            <article>
                
<p>We often find in data science that the objects we wish to analyze are textual. For example, they might be tweets, articles, or network logs. Since our algorithms require numerical inputs, we must find a way to convert such text into numerical features. To this end, we utilize a sequence of techniques.</p>
<p>A <em>token</em> is a unit of text. For example, we may specify that our tokens are words, sentences, or characters. A count vectorizer takes textual input and then outputs a vector consisting of the counts of the textual tokens. A <strong>hashing vectorizer</strong> is a variation on the count vectorizer that sets out to be faster and more scalable, at the cost of interpretability and hashing collisions. Though it can be useful, just having the counts of the words appearing in a document corpus can be misleading. The reason is that, often, unimportant words, such as <em>the</em> and <em>a</em> (known as <em>stop words</em>) have a high frequency of occurrence, and hence little informative content. For reasons such as this, we often give words different weights to offset this. The main technique for doing so is <strong>tf-idf</strong>, which stands for <strong>Term-Frequency, Inverse-Document-Frequency</strong>. The main idea is that we account for the number of times a term occurs, but discount it by the number of documents it occurs in.</p>
<p>In cybersecurity, text data is omnipresent; event logs, conversational transcripts, and lists of function names are just a few examples. Consequently, it is essential to be able to work with such data, something you'll learn in this recipe.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<div class="a-b-r">
<div class="a-b-r-Tl a-b-va-Zf">
<div class="a-b-r-Ec a-b-tb-Ce">
<div class="a-b-r-x">
<p>The preparation for this recipe consists of installing the scikit-learn package in <kbd>pip</kbd>. The command for this is as follows:</p>
</div>
<div class="a-b-r-x">
<pre><strong>pip install sklearn</strong></pre></div>
</div>
</div>
</div>
<p>In addition, a log file, <kbd>anonops_short.log</kbd>, consisting of an excerpt of conversations taking place on the IRC channel, <kbd>#Anonops</kbd>, is included in the repository for this chapter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it…</h1>
                </header>
            
            <article>
                
<p>In the next steps, we will convert a corpus of text data into numerical form, amenable to machine learning algorithms:</p>
<ol>
<li>First, import a textual dataset:</li>
</ol>
<pre style="padding-left: 60px">with open("anonops_short.txt", encoding="utf8") as f:<br/>    anonops_chat_logs = f.readlines()</pre>
<ol start="2">
<li>Next, count the words in the text using the hash vectorizer and then perform weighting using tf-idf:</li>
</ol>
<pre style="padding-left: 60px">from sklearn.feature_extraction.text import HashingVectorizer<br/>from sklearn.feature_extraction.text import TfidfTransformer<br/><br/>my_vector = HashingVectorizer(input="content", ngram_range=(1, 2))<br/>X_train_counts = my_vector.fit_transform(anonops_chat_logs,)<br/>tf_transformer = TfidfTransformer(use_idf=True,).fit(X_train_counts)<br/>X_train_tf = tf_transformer.transform(X_train_counts)</pre>
<ol start="3">
<li>The end result is a sparse matrix with each row being a vector representing one of the texts:</li>
</ol>
<pre style="padding-left: 60px">X_train_tf<br/><br/><span>&lt;180830</span><span> x </span><span>1048576 sparse matrix of type &lt;class 'numpy.float64'&gt;' with 3158166 stored elements in Compressed Sparse Row format&gt;<br/><br/></span>print(X_train_tf)</pre>
<p>The following is the output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1075 image-border" src="assets/84d753ae-9201-4079-aaad-ead4c340cd34.png" style="width:20.25em;height:44.83em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>We started by loading in the #Anonops text dataset (step 1). The Anonops IRC channel has been affiliated with the Anonymous hacktivist group. In particular, chat participants have in the past planned and announced their future targets on Anonops. Consequently, a well-engineered ML system would be able to predict cyber attacks by training on such data. In step 2, we instantiated a hashing vectorizer. The hashing vectorizer gave us counts of the 1- and 2-grams in the text, in other words, singleton and consecutive pairs of words (tokens) in the articles. We then applied a tf-idf transformer to give appropriate weights to the counts that the hashing vectorizer gave us. Our final result is a large, sparse matrix representing the occurrences of 1- and 2-grams in the texts, weighted by importance. Finally, we examined the frontend of a sparse matrix representation of our featured data in Scipy.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Hyperparameter tuning with scikit-optimize</h1>
                </header>
            
            <article>
                
<p>In machine learning, a <strong>hyperparameter</strong> is a parameter whose value is set before the training process begins. For example, the choice of learning rate of a gradient boosting model and the size of the hidden layer of a multilayer perceptron, are both examples of hyperparameters. By contrast, the values of other parameters are derived via training. Hyperparameter selection is important because it can have a huge effect on the model's performance.</p>
<p>The most basic approach to hyperparameter tuning is called a <strong>grid search</strong>. In this method, you specify a range of potential values for each hyperparameter, and then try them all out, until you find the best combination. This brute-force approach is comprehensive but computationally intensive. More sophisticated methods exist. In this recipe, you will learn how to use <em>Bayesian optimization</em> over hyperparameters using <kbd>scikit-optimize</kbd>. In contrast to a basic grid search, in Bayesian optimization, not all parameter values are tried out, but rather a fixed number of parameter settings is sampled from specified distributions. More details can be found at <a href="https://scikit-optimize.github.io/notebooks/bayesian-optimization.html" target="_blank">https://scikit-optimize.github.io/notebooks/bayesian-optimization.html</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>The preparation for this recipe consists of installing a specific version of <kbd>scikit-learn</kbd>, installing <kbd>xgboost</kbd>, and installing <kbd>scikit-optimize</kbd> in <kbd>pip</kbd>. The command for this is as follows:</p>
<pre><strong>pip install scikit-learn==0.20.3 xgboost scikit-optimize pandas</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>In the following steps, you will load the standard <kbd>wine</kbd> dataset and use Bayesian optimization to tune the hyperparameters of an XGBoost model:</p>
<ol>
<li>Load the <kbd>wine</kbd> dataset from scikit-learn:</li>
</ol>
<pre style="padding-left: 60px">from sklearn import datasets<br/><br/>wine_dataset = datasets.load_wine()<br/>X = wine_dataset.data<br/>y = wine_dataset.target</pre>
<ol start="2">
<li>Import XGBoost and stratified K-fold:</li>
</ol>
<pre style="padding-left: 60px">import xgboost as xgb<br/>from sklearn.model_selection import StratifiedKFold</pre>
<ol start="3">
<li> Import <kbd>BayesSearchCV</kbd> from <kbd>scikit-optimize</kbd> and specify the number of parameter settings to test:</li>
</ol>
<pre style="padding-left: 60px">from skopt import BayesSearchCV<br/><br/>n_iterations = 50</pre>
<ol start="4">
<li>Specify your estimator. In this case, we select XGBoost and set it to be able to perform multi-class classification:</li>
</ol>
<pre style="padding-left: 60px">estimator = xgb.XGBClassifier(<br/>    n_jobs=-1,<br/>    objective="multi:softmax",<br/>    eval_metric="merror",<br/>    verbosity=0,<br/>    num_class=len(set(y)),<br/>)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="5">
<li>Specify a parameter search space:</li>
</ol>
<pre style="padding-left: 60px">search_space = {<br/>    "learning_rate": (0.01, 1.0, "log-uniform"),<br/>    "min_child_weight": (0, 10),<br/>    "max_depth": (1, 50),<br/>    "max_delta_step": (0, 10),<br/>    "subsample": (0.01, 1.0, "uniform"),<br/>    "colsample_bytree": (0.01, 1.0, "log-uniform"),<br/>    "colsample_bylevel": (0.01, 1.0, "log-uniform"),<br/>    "reg_lambda": (1e-9, 1000, "log-uniform"),<br/>    "reg_alpha": (1e-9, 1.0, "log-uniform"),<br/>    "gamma": (1e-9, 0.5, "log-uniform"),<br/>    "min_child_weight": (0, 5),<br/>    "n_estimators": (5, 5000),<br/>    "scale_pos_weight": (1e-6, 500, "log-uniform"),<br/>}</pre>
<ol start="6">
<li>Specify the type of cross-validation to perform:</li>
</ol>
<pre style="padding-left: 60px">cv = StratifiedKFold(n_splits=3, shuffle=True)</pre>
<ol start="7">
<li>Define <kbd>BayesSearchCV</kbd> using the settings you have defined:</li>
</ol>
<pre style="padding-left: 60px">bayes_cv_tuner = BayesSearchCV(<br/>    estimator=estimator,<br/>    search_spaces=search_space,<br/>    scoring="accuracy",<br/>    cv=cv,<br/>    n_jobs=-1,<br/>    n_iter=n_iterations,<br/>    verbose=0,<br/>    refit=True,<br/>)</pre>
<p> </p>
<ol start="8">
<li>Define a <kbd>callback</kbd> function to print out the progress of the parameter search:</li>
</ol>
<pre style="padding-left: 60px">import pandas as pd<br/>import numpy as np<br/><br/>def print_status(optimal_result):<br/>    """Shows the best parameters found and accuracy attained of the search so far."""<br/>    models_tested = pd.DataFrame(bayes_cv_tuner.cv_results_)<br/>    best_parameters_so_far = pd.Series(bayes_cv_tuner.best_params_)<br/>    print(<br/>        "Model #{}\nBest accuracy so far: {}\nBest parameters so far: {}\n".format(<br/>            len(models_tested),<br/>            np.round(bayes_cv_tuner.best_score_, 3),<br/>            bayes_cv_tuner.best_params_,<br/>        )<br/>    )<br/><br/>    clf_type = bayes_cv_tuner.estimator.__class__.__name__<br/>    models_tested.to_csv(clf_type + "_cv_results_summary.csv")</pre>
<p> </p>
<ol start="9">
<li>Perform the parameter search:</li>
</ol>
<pre style="padding-left: 60px">result = bayes_cv_tuner.fit(X, y, callback=print_status)</pre>
<p> </p>
<p style="padding-left: 60px">As you can see, the following shows the output:</p>
<pre style="padding-left: 60px" class="mce-root">Model #1<br/> Best accuracy so far: 0.972<br/> Best parameters so far: {'colsample_bylevel': 0.019767840658391753, 'colsample_bytree': 0.5812505808116454, 'gamma': 1.7784704701058755e-05, 'learning_rate': 0.9050859661329937, 'max_delta_step': 3, 'max_depth': 42, 'min_child_weight': 1, 'n_estimators': 2334, 'reg_alpha': 0.02886003776717955, 'reg_lambda': 0.0008507166793122457, 'scale_pos_weight': 4.801764874750116e-05, 'subsample': 0.7188797743009225}<br/> <br/> Model #2<br/> Best accuracy so far: 0.972<br/> Best parameters so far: {'colsample_bylevel': 0.019767840658391753, 'colsample_bytree': 0.5812505808116454, 'gamma': 1.7784704701058755e-05, 'learning_rate': 0.9050859661329937, 'max_delta_step': 3, 'max_depth': 42, 'min_child_weight': 1, 'n_estimators': 2334, 'reg_alpha': 0.02886003776717955, 'reg_lambda': 0.0008507166793122457, 'scale_pos_weight': 4.801764874750116e-05, 'subsample': 0.7188797743009225}<br/><br/><span>&lt;</span>snip&gt;<br/><br/>Model #50<br/> Best accuracy so far: 0.989<br/> Best parameters so far: {'colsample_bylevel': 0.013417868502558758, 'colsample_bytree': 0.463490250419848, 'gamma': 2.2823050161337873e-06, 'learning_rate': 0.34006478878384533, 'max_delta_step': 9, 'max_depth': 41, 'min_child_weight': 0, 'n_estimators': 1951, 'reg_alpha': 1.8321791726476395e-08, 'reg_lambda': 13.098734837402576, 'scale_pos_weight': 0.6188077759379964, 'subsample': 0.7970035272497132}</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>In steps 1 and 2, we import a standard dataset, the <kbd>wine</kbd> dataset, as well as the libraries needed for classification. A more interesting step follows, in which we specify how long we would like the hyperparameter search to be, in terms of a number of combinations of parameters to try. The longer the search, the better the results, at the risk of overfitting and extending the computational time. In step 4, we select XGBoost as the model, and then specify the number of classes, the type of problem, and the evaluation metric. This part will depend on the type of problem. For instance, for a regression problem, we might set <kbd>eval_metric = 'rmse'</kbd> and drop <kbd>num_class</kbd> together.</p>
<p>Other models than XGBoost can be selected with the hyperparameter optimizer as well. In the next step, (step 5), we specify a probability distribution over each parameter that we will be exploring. This is one of the advantages of using <kbd>BayesSearchCV</kbd> over a simple grid search, as it allows you to explore the parameter space more intelligently. Next, we specify our cross-validation scheme (step 6). Since we are performing a classification problem, it makes sense to specify a stratified fold. However, for a regression problem, <kbd>StratifiedKFold</kbd> should be replaced with <kbd>KFold</kbd>.</p>
<p>Also note that a larger splitting number is preferred for the purpose of measuring results, though it will come at a computational price. In step 7, you can see additional settings that can be changed. In particular, <kbd>n_jobs</kbd> allows you to parallelize the task. The verbosity and the method used for scoring can be altered as well. To monitor the search process and the performance of our hyperparameter tuning, we define a callback function to print out the progress in step 8. The results of the grid search are also saved in a CSV file. Finally, we run the hyperparameter search (step 9). The output allows us to observe the parameters and the performance of each iteration of the hyperparameter search.</p>
<p>In this book, we will refrain from tuning the hyperparameters of classifiers. The reason is in part brevity, and in part because hyperparameter tuning here would be <em>premature optimization</em>, as there is no specified requirement or goal for the performance of the algorithm from the end user. Having seen how to perform it here, you can easily adapt this recipe to the application at hand.</p>
<p>Another prominent library for hyperparameter tuning to keep in mind is <kbd>hyperopt</kbd>.</p>


            </article>

            
        </section>
    </body></html>