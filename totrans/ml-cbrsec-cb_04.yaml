- en: Machine Learning for Social Engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a lot of cool new applications of **machine learning** (**ML**), and
    nowhere do these shine as much as they do in social engineering. ML has enabled
    hugely successful automated spear phishing, as we will learn via a Twitter spear
    phishing bot recipe. It has also been used to generate fake, but realistic, videos
    and, at the same time, to discover when these are fake. It offers the ability
    to voice transfer, detect lies, and many other handy tools that you will see in
    this chapter's recipes, designed to step up your social engineering game.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Twitter spear phishing bot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Voice impersonation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Speech recognition for **Open Source Intelligence** (**OSINT**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Facial recognition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deepfake
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deepfake recognition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lie detection using ML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Personality analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Social Mapper
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training a fake review generator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating fake reviews
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fake news
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will be using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Markovify
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Twitter developer account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tweepy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PyTorch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenCV
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keras
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorFlow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IBM's Watson
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code and datasets may be found at [https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/tree/master/Chapter04](https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/tree/master/Chapter04).
  prefs: []
  type: TYPE_NORMAL
- en: Twitter spear phishing bot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we are going to use machine learning to build a Twitter spear
    phishing bot. The bot will utilize artificial intelligence to mimic its targets'
    tweets, hence creating interesting and enticing content for its own tweets. Also,
    the tweets will contain embedded links, resulting in targets clicking these phishing
    links. Of course, we will not be utilizing this bot for malicious purpose, and
    our links will be dummy links. The links themselves will be obfuscated, so a target
    will not be able to tell what is really hidden behind them until after they click.
  prefs: []
  type: TYPE_NORMAL
- en: Experimentally, it has been shown that this form of attack has a high percentage
    success rate, and by simulating this form of attack, you can test and improve
    the security posture of your client or organization.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Preparation for this recipe consists of installing the `tweepy` and `markovify` packages in
    `pip`. The instructions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Also, you will need to set up a developer account on Twitter. The process is
    relatively simple and account creation is free.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, we demonstrate how to use machine learning to create
    a spear phishing Twitter bot:'
  prefs: []
  type: TYPE_NORMAL
- en: Set up a developer account on Twitter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new app and obtain your consumer API keys, access token, and access
    token secret.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the `tweepy` library and fill in your credentials to access the Twitter
    API:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We select a user we would like to target or imitate. In this case, I chose
    a prominent figure in technology, active on Twitter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Collect the user''s latest `count = 200` tweets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Collect all of the user''s Tweets into one large text:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We now proceed to process the text. We define a function that will replace
    any found instance of a URL with a new URL:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a phishing link and insert it into the tweets. In our case, we used
    a URL shortener to obfuscate the fact that the link takes a user to [google.com](http://google.com):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Train a Markov model on the processed text and generate tweets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Generate the desired number of tweets that contains the phishing link:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We will see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/3e7aedd3-3037-46ce-b1d1-73ed514502ef.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Publish your tweets and target either the user, followers of the user, or friends
    of the user. For instance, this code obtains the user''s friends:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The output we''ll see is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In steps 1 and 2, you will want to go onto the Twitter developer web page to
    create your API account, which will be free. To access the Twitter API through
    Python, we use the `tweepy` library (step 3). Our goal is to learn from the tweets
    of a target Twitter user so that our tweets have the same style and topics as
    that user. Such tweets then form likely bait for anyone interested in the same
    topics and style. We chose to imitate Elon Musk's style for our tweets (step 4).
    We proceed to collect the last 200 tweets that Elon has released (steps 5 and
    6). Generally speaking, the more tweets from the user you can obtain, the more
    convincing the model will be. However, it may be important to account for time
    and relevancy—that is, that users are more likely to click on timely and relevant
    tweets than those dealing with aged topics.
  prefs: []
  type: TYPE_NORMAL
- en: We define a function to process the text so that all the URLs are replaced with
    the desired URL (step 7) and then apply it to our text (step 8). We used a URL
    shortener to hide the destination of the phishing link, which is just Google.
    There is great room for creativity at this stage of processing the tweets. For
    instance, we may customize the `@` screen names so they are more relevant to our
    target. In steps 9 and 10, we train a Markov model on the tweets we have processed
    and then generate several tweets with the phishing link embedded in them. Finally,
    concerning step 11, keep in mind that other modifications to make the bot more
    effective include picking the optimal time of day, week, month, or other (for
    example, event-related timing) to send the tweet or adding photos with links into
    the tweet.
  prefs: []
  type: TYPE_NORMAL
- en: Voice impersonation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using the new technology of voice style transfer via neural networks, it is
    becoming easier and easier to convincingly impersonate a target's voice. In this
    section, we show you how to use deep learning to have a recording of a target
    saying whatever you want them to say, for example, to have a target's voice used
    for social engineering purposes or, a more playful example, using Obama's voice
    to sing Beyoncé songs. We selected the architecture in `mazzzystar/randomCNN-voice-transfer`
    that allows for fast results with high quality. In particular, there is no need
    to pre-train the model on a large dataset of recorded audio.
  prefs: []
  type: TYPE_NORMAL
- en: In the accompanying code for this book, you will find two versions of the voice
    transfer neural network code, one for GPU and one for CPU. We describe here the
    one for CPU, though the one for GPU is very similar.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Preparation for this recipe consists of installing `pytorch` and `librosa`
    in `pip`. The instructions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Also, place two files in the `voice_impersonation_input` folder. One file will
    be an audio recording of the message you would like to vocalize and another file
    will be the voice in which you would like to vocalize that message.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, we provide a recipe for transferring the voice of one
    speaker to the recording of another speaker. The code is structured in three parts:
    Voice Impersonation for CPU (main), a model, and utilities. We will discuss how
    to run the main and explain what it is doing. Whenever a reference occurs to the
    other parts of the code, we will provide a high-level explanation of what the
    referenced method does, but leave the details out for the sake of brevity.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code can be found in `Voice Impersonation.ipynb`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import PyTorch utilities, the neural network model, and `math` for some basic
    computations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Specify the voice we wish to use in `style_file` and the audio we wish to utter
    in that voice in `content_file`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We extract the spectra of the content and style files and convert these into
    PyTorch tensors:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We instantiate a Random CNN model and set it to `eval` mode:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We prepare the tensors for the upcoming training of the neural network and
    select the Adam optimizer and a learning rate:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We specify `style` and `content` parameters and how long we wish to train our
    model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We train our model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'We print the ongoing progress of the training, specify the output file''s name,
    and, finally, convert the neural network''s output spectrum into an audio file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The final result of our computation can be seen in the audio file with the name
    `Eleanor_saying_there_was_a_change_now.wav`.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We begin by importing PyTorch, the neural network model, and `math` for some
    basic computations (step 1). More interestingly, in step 2, we specify content
    and style audio. In the content file, you can utter whatever phrase you wish,
    for example, *you can't do cybersecurity without machine learning*. Then, in the
    style file, you select a recording of someone's voice, for example, a recording
    of a famous individual such as Elon Musk. The final result of the voice impersonation
    is that Elon Musk says that *you can't do cybersecurity without machine learning*.
    Steps 3, 4, and 5 involve some legwork to prepare our data to be fed into our
    model and then instantiate a Random CNN model and its optimizer. The main feature
    of the model is that it uses a 2D convolutional layer rather than a 1D layer for
    the audio spectrogram and it computes `grams` over the time axis. Setting the
    model to evaluation mode (to be contrasted with training mode) affects the behavior
    of certain layers, such as dropout and batch norm, that are used differently in
    training versus testing. In the next step (step 6), we define the `style` and
    `content` parameters, which assign relative weights to style and content. In particular,
    these determine how strongly the final audio will inherit the style versus content
    from the respective files. We are now ready to train our model, which we do in
    step 7 by performing forward and back propagation. We monitor the progress of
    the training (step 8), and then finally output an audio file to disk that pronounces
    the content file using the style of the style file. You may find this file in
    the repository for this book.
  prefs: []
  type: TYPE_NORMAL
- en: Speech recognition for OSINT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The story goes that a pen tester was performing intelligence gathering on the
    at-the-time director of the FBI, James Comey. By listening to footage from Comey,
    the pen tester noted that Comey mentioned having several social media accounts,
    including a Twitter account. However, at the time, no account of his was known.
  prefs: []
  type: TYPE_NORMAL
- en: Through thorough investigation, the pen tester eventually discovered Comey's
    secret Twitter account, screen name Reinhold Niebuhr. The goal of this recipe
    is to help the pen tester to automate and expedite the sifting through large amounts
    of audio/video footage about a target in the search of keywords. Specifically,
    we use machine learning to convert speech into text, collect this text, and then
    search for keywords of interest.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Preparation for this recipe consists of installing the `speechrecognition`
    package in `pip`. The instructions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In addition, collect a number of audio files whose speech you would like to
    recognize.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, we show how to use the speech recognition library to
    convert audio recordings of speech into text and then search through these texts
    for desired keywords:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the speech recognition library and select a list of audio files whose
    speech we wish to convert into text. Also, create a list of keywords you would
    like to automatically detect in these audio files:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a function that uses the Google speech recognition API to convert the
    audio file into text:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Convert the audio files into text and create a dictionary to remember which
    audio file the text came from:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The corpus output is as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Search through the corpus of text for the keywords and print out which audio
    files had those keywords:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Our run has detected the keyword `Twitter`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We begin by importing the speech recognition library and selecting a list of
    audio files whose speech we wish to convert into text. Also, we create a list
    of keywords we would like to automatically detect in these audio files (step 1).
    The approach taken, of detecting the utterance of these keywords, can be made
    more robust through stemming or lemmatization, which effectively accounts for
    variants of the keywords that have the same meaning. For example, Twitter, Twitted,
    and Tweet would all be detected if this approach is properly implemented. In step
    2, we specify that we will use Google's Speech Recognition API to transcribe the
    audio. Other speech recognition services, such as pocketsphinx, are available
    as well. We are now ready to transcribe our audio files, which we do in step 3\.
    Now we have our audio in text format, and it's smooth sailing from here. Simply
    search for the keywords of interest (step 4). An additional optimization that
    may be fruitful when the corpus and text grow larger is to print the sentence
    where the keyword was found, to make it easier to understand the context.
  prefs: []
  type: TYPE_NORMAL
- en: Facial recognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A facial recognition system is a technology for identifying or verifying a person
    in images or videos. When performing OSINT on a target or potential targets, a
    facial recognition system can be invaluable. In this recipe, you will learn how
    to use the well-developed `face_recognition` Python library.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Preparation for this recipe consists of installing the `face_recognition` and
    OpenCV packages in `pip`. The instructions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: In addition, you will want a portrait of an individual and a collection of images
    through which you would like to search for that individual.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, you will train `face_recognition` to find and label
    a given individual in a series of images:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Begin by importing the `face_recognition` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Start by loading in a labeled portrait of the individual on which you will
    perform OSINT:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The face of the individual must be clearly visible:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ab1cb3f4-c88f-407d-854f-84fdda2fe552.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, load in an `unknown` image, in which you would like to automatically
    detect the face of the individual:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The individual whose face is being searched for is present in this screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/6dc5fd33-e04a-4c6a-b76b-342c63c0e8c3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Encode the face of the individual:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Encode the faces of all individuals in the unknown image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Perform a search for the face of the individual:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Load the locations of all faces in the unknown image and save the location
    of the match into a variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Read in the unknown image into `cv2`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Draw a rectangle on the unknown image for where the matching face is:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Label the rectangle:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Display the image with the labeled rectangle:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot shows us that the output has been successful:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/a50ba5dd-c7f1-4134-bdb9-bf958eea114b.png)'
  prefs: []
  type: TYPE_IMG
- en: It is straightforward to automate this searching and labeling process.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Begin simply by importing the facial recognition library (step 1). In the next
    step, we load the image of the target we wish to locate in a collection of images
    in our pen test. Next, prepare an example image that we would like to scan for
    the presence of the target's face (step 3). Encode all found faces in images (steps
    4 and 5) and then search for the face of the target (step 6). For convenience,
    we print out the results of seeking a match with the target's face. In steps 7-10,
    we wish to demonstrate that we have found a match. To that end, we load the image
    we have scanned. We then draw a rectangle and a label where our classifier has
    detected the target's face. Looking at the result in step 11, we see a massive
    success. We made a successful detection.
  prefs: []
  type: TYPE_NORMAL
- en: In passing, note that the technology behind the `face_recognition` tool is deep
    learning, and, as a corollary, a search process for faces can be expedited using
    a GPU.
  prefs: []
  type: TYPE_NORMAL
- en: Deepfake
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Deepfake** is the technique of using a neural network to take a video or
    image, superimpose some content onto it, and make the result look realistic. For
    example, the technique can take a video of Alice saying she supports a movement,
    and then, replacing Alice with Bob, create a realistic-looking video of Bob saying
    he supports the movement. Clearly, this technique has deep implications on the
    trust we can place on videos and images, while also providing a useful tool for
    social engineers.'
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we use a Deepfake variant to take the image of the face of one
    target and realistically superimpose it onto the image of another target's face.
    The recipe is a refactored and simplified version of the code in the GitHub repository,
    `wuhuikai/FaceSwap`.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Preparation for this recipe consists of installing `opencv`, `dlib`, and `scipy`
    in `pip`. The instructions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Also, you will want two images; one is a portrait of an individual and one is
    an image containing a face. The former face will be transferred onto the latter.
    A sample has been provided for you in the `deepfake_input` folder.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, we provide a recipe for replacing the face of one individual
    in an image with that of another. The code is structured in five parts: `Deepfake.ipynb`
    (main), the `deepfake_config` configuration file, `deepfake_face_detection`, `deepfake_face_points_detection`,
    and `deepfake_face_swap`. Also, a models folder is included.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code can be found in `Deepfake.ipynb`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `opencv` for image operations and the methods needed to swap faces from
    the associated code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Specify the image containing the face we wish to use in `content_image` and
    the image where we want the face to be transferred to in `target_image`. Finally,
    specify where you''d like the result created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'In the running example, the source image is a picture of the author''s face:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/496dcb42-9f33-42d4-a495-d0a6af15168c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The destination image is a picture of a gymnast mid-performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/2bb0fc84-9761-4944-89fe-61015978deb6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Read in the images into `opencv` and then extract the source and destination
    faces:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Compute a transformed version of the source face:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Draw the transformed face into the destination image and write the file to
    disk:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'The final result of the `deepfake` operation in this example is an image with
    the gymnast''s body and author''s face:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/cb7b4948-d6ec-482f-a1fa-4f3a56f0558e.png)'
  prefs: []
  type: TYPE_IMG
- en: By applying the method frame by frame, it can be extended to videos.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Begin, as usual, by importing the appropriate libraries (step 1). Specify, in
    step 2, the style and content images. Here, the content is the target image while
    the style is the face to draw in. In step 3, note that if there are several faces
    in the image, a screen will be presented to you asking which of the faces you
    would like to use. The next step is a computation to determine how to draw the
    superimposed face (step 4). Having completed this step, we can now draw out and
    display the `deepfake` superimposed face in step 5\. Evidently, this implementation
    has room for improvement but does an OK job.
  prefs: []
  type: TYPE_NORMAL
- en: Deepfake recognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the advent of deepfake and similar image forgery technology, it is becoming
    more and more difficult to differentiate between forgery and real media. Fortunately,
    just as neural networks can compose fake media, they can also detect it. In this
    recipe, we will utilize a deep neural network to detect fake images. The recipe
    utilizes the MesoNet architecture, found in the GitHub repository, `DariusAf/MesoNet`.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Preparation for this recipe consists of installing `keras`, `tensorflow`, and
    `pillow` in `pip`. The instructions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: In addition, a collection of fake and real images has been provided for you
    in the `mesonet_test_images` folder, to which you may add additional images.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, we provide a recipe for detecting when an image is
    produced by deepfake. The code is structured in four parts: Deepfake `Recognition.ipynb`
    (main), the `mesonet_classifiers.py` file defining the MesoNet classifier, the `mesonet_weights`
    folder holding the trained weights, and the `mesonet_test_images` folder containing
    our test images.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code can be found in Deepfake `Recognition.ipynb`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the MesoNet neural network and the image data generator from `keras`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Instantiate MesoNet and load its weights:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Create an image data generator to read in images from a directory and specify
    the path where the unknown images are stored:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a dictionary to translate numerical labels to the text labels, `"real"`
    and `"fake"`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'In our example, we place three images in the folder, one real and two fake:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/3d2752b4-ff56-4583-b0a1-5d89d389546f.png)'
  prefs: []
  type: TYPE_IMG
- en: Can you tell which ones are which?
  prefs: []
  type: TYPE_NORMAL
- en: 'Running MesoNet reveals the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As for most recipes, we begin by importing the necessary libraries. We then
    load up a MesoNet model in step 2, that is, load up its structure and pre-trained
    weights. For clarity, the architecture may be found in the `MesoNet_classifiers`
    file and is given by the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: In step 3, we define and use an `ImageDataGenerator`, a convenient `keras` object
    that allows us to perform image processing in one place—in the case at hand, to
    rescale and normalize the numerical values of pixels. It is hard to tell what
    the labels `0` and `1` represent. For that reason, for readability purposes, we
    define a dictionary to translate 0s and 1s into the words, `real` and `fake` (step
    4). Finally, in step 5, we see that the MesoNet model was able to correctly predict
    the labels of the test images.
  prefs: []
  type: TYPE_NORMAL
- en: Lie detection using machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When gathering intelligence for social engineering purposes, it is crucial to
    be able to tell when an individual is telling the truth and when they are lying.
    To this end, machine learning can come to our aid. By analyzing a video for microexpressions
    and vocal quality, a machine learning system can help to identify untruthful actors.
    In this recipe, we will be running through a lie detection cycle, using a slightly
    modified version of Lie To Me, a lie detection system that uses facial and vocal
    recognition.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Preparation for this recipe consists of installing several packages in `pip`.
    The list of packages can be found in the `requirements.txt` file. To install all
    of these at once, run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: You will need one video file with audio to analyze.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, we provide a recipe for analyzing a video for lying
    behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the Lie To Me application:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: Open the portal for Lie To Me by going to the IP address specified, for example,
    `127.0.0.1:5000`, by opening a web browser and typing this address.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on **UPLOAD** and select a video you would like to analyze:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/11288da4-2f84-4c91-95d7-ff9c6755378a.png)'
  prefs: []
  type: TYPE_IMG
- en: Once the analysis is complete, you will notice the following.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following screenshot shows the variation happening in the **Blink Analysis**
    graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/f8a14ee8-ae4a-41f8-9d12-6a382936c6d3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following screenshot shows the variation happening in the **Micro Expression
    Analysis** graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/37cbad82-7c4f-49c9-9244-4833f8a0d7be.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following screenshot shows the variation happening in the **Voice Energy
    Analysis** graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/3cbcdef4-2f40-424e-a442-d6ac9641429b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following screenshot shows the variation happening in the **Voice Pitch
    Analysis** graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/c1a025b9-ed03-47e4-9627-24da5b18cde5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following screenshot shows the variation happening in the **Voice Pitch
    Contour Analysis** graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/d7763af6-b146-4219-bc7d-117c4858eb58.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following screenshot shows the variation happening in the **Vowel Duration
    Analysis** graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/47bdbdee-d25d-4d57-87ce-590541dc5efd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, clicking on results shows an analysis of the lies detected in the
    video:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/12a286af-cc3f-41bf-af79-068412c04c50.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In step 1, we run the Lie To Me application using Python. We enter the application's
    portal and upload a candidate video (steps 2 and 3). Upon completion of the analysis
    of the video, the Lie To Me application shows several exploratory screens (step
    4). These represent features that may be indicative of lying. Finally, in step
    5, we see a screen that reveals whether the video contained any lying individuals,
    and if so, when and how many times a lie has been spoken.
  prefs: []
  type: TYPE_NORMAL
- en: Personality analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Knowing a target's personality type and communication style greatly increases
    the potential to influence. For this reason, a personality analysis is a nice
    tool to have in the social engineer's toolbelt. In this recipe, we will utilize
    IBM Watson's Personality Insights API to analyze a target's Tweets to obtain a
    personality profile.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Preparation for this recipe consists of installing the IBM Watson package in
    `pip`. The instructions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: In addition, you will want to sign up for a Watson Personality Insights account.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, we set up an API call to analyze the personality of
    an author of tweets:'
  prefs: []
  type: TYPE_NORMAL
- en: Sign up for a Watson Personality Insights account. It is quick and free.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the Python library for Watson and record today''s date:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Specify your API key, which you have obtained in step 1, and declare the Personality
    Insights instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Curate a text file, for example, a collection of tweets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Call the Personality Insights API on the text file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, print out the personality profile:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Start by signing up for a Watson Personality Insights account. There are different
    tiers for the service, with different limits on API call rates and different prices,
    but the lowest tier is easy to set up, free, and sufficient enough for this recipe.
    We save today's date into a variable and import the IBM Watson library (step 2).
    By specifying the latest date, we are ensuring that we will be employing the latest
    version of Watson. In the next step, we instantiate IBM Watson personality insights
    using our API key.
  prefs: []
  type: TYPE_NORMAL
- en: For step 4, we must collate a text dataset produced by the target. It may be
    helpful to utilize the recipe from the Twitter spear phishing bot to gather a
    user's Tweets. In step 5, we run the personality insights application on our text
    set, consisting of Elon Musk's recent tweets. We elected to display the personality
    profile as a JSON. It is also possible to display in other formats, such as CSV,
    and details may be found in the personality insights' API documentation. Finally,
    in step 6, we print a small snippet from the personality profile. As you can see,
    it even provides actionable insights, such as how likely the target is to agree
    to volunteer.
  prefs: []
  type: TYPE_NORMAL
- en: Social Mapper
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Social Mapper** is an OSINT tool that allows you to correlate the multitude
    of social media profiles of a target using facial recognition. It automatically
    searches popular social media sites for the target''s name and pictures to effortlessly
    find the user''s social media profiles and then outputs the results into a report
    that you can use to take your investigations further.'
  prefs: []
  type: TYPE_NORMAL
- en: The largest benefit of Social Mapper is that by combining name search with image
    recognition, as opposed to just name search, it can eliminate false positives,
    saving the social engineer valuable time.
  prefs: []
  type: TYPE_NORMAL
- en: Social Mapper currently supports LinkedIn, Facebook, Twitter, Google Plus, Instagram,
    VKontakte, Weibo, and Douban.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this recipe, it is recommended that you prepare a Python 2.7 environment.
    Social Mapper has been designed to be used on Python 2.7 and may not work with
    other Python environments. The prerequisites for installation are delineated in
    [https://github.com/Greenwolf/social_mapper](https://github.com/Greenwolf/social_mapper).
    Also, you will want to use a Mac or Linux machine for this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, we provide a recipe for using Social Mapper to correlate
    the social media accounts of an individual:'
  prefs: []
  type: TYPE_NORMAL
- en: Following the instructions on the GitHub page at [https://github.com/Greenwolf/social_mapper](https://github.com/Greenwolf/social_mapper),
    install Social Mapper and its prerequisites.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Place an image of the face of your target into `Input, Examples/imagefolder/`
    with the name of the file and the full name of the target:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/886752a2-59ff-46f1-bd42-96828f5dfa22.png)'
  prefs: []
  type: TYPE_IMG
- en: Create throwaway accounts for the social media websites you wish to search your
    target on. For example, create throwaway Facebook, LinkedIn, and Twitter accounts.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open the `social_mapper.py` file and fill in your throwaway accounts credentials.
    For instance, you may only be interested in Twitter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'In Terminal, run the command to search for the target''s social media profiles:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Examine the output in the `social_mapper/results-social-mapper.html` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/d22a0574-be38-4681-b197-c5c9a9e765db.png)'
  prefs: []
  type: TYPE_IMG
- en: With each target individual, an additional row is added having that individual's
    social network data.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Start by preparing Social Mapper in your environment (step 1). Place an image
    of your target in the inputs directory (step 2). The image must be named after
    the target's full name; otherwise, the application will not be able to find the
    target's accounts. Next, in step 3, create throwaway accounts for the social media
    websites you wish to search your target on and fill these into the appropriate
    place in `social_mapper.py` (step 4). Note that the more different accounts you
    have, the more data you can gather on the target via Social Mapper. You are ready
    now to perform the search on the target. In Terminal, run the command to search
    for the target's social media profiles (step 5). There are many variations on
    the arguments and options you may wish to use. For instance, we have specified
    Twitter using the `-tw` argument. However, you may wish to add in additional social
    media sites, such as LinkedIn (`-li`) or Instagram (`-ig`). Finally, in step 6,
    observe that Social Mapper was able to find Bill Gates's Twitter account.
  prefs: []
  type: TYPE_NORMAL
- en: Fake review generator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An important part of social engineering is impersonation. A social engineer
    may want to pretend to represent a company or business that doesn't currently
    exist. By creating a profile and populating it with convincing reviews, the social
    engineer can add credibility to the fake business. In this recipe, we show how
    to train an RNN so that it can generate new reviews, similar to the ones in the
    training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Training a fake review generator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our first step is to train the model. Later, we will utilize it to produce new
    reviews.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Preparation for this recipe consists of installing `keras` and `tensorflow`
    in `pip`. The instructions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, we provide a recipe for training a Recurrent Neural
    Network (RNN) using a corpus of reviews:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Collect the types of reviews you wish to imitate. For more on this, see the
    discussion in the *How it works...* section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a dictionary to vectorize the characters of the text:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'The dictionary might look like so, depending on which characters your corpus
    contains:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Construct an RNN to learn and predict the sequence of characters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Select an optimizer and compile the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a convenience function to vectorize text:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Vectorize our sample input text and train the model in batches:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: Finally, save the model's weights for future use.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Start by collecting a dataset of reviews you''d like to imitate (step 1). A
    practical example would require a large corpus of reviews. There are many such
    datasets available, such as the Yelp reviews dataset. Proceeding to step 2, we
    create a mapping between characters and numbers. This will allow us to vectorize
    the text. Depending on your application, you may want to use the standard ASCII
    code. However, if you are using only a small number of characters, then this will
    unnecessarily slow down your model. We go on to declare the architecture of an
    RNN to learn and predict the sequence of characters (step 3). We used a relatively
    simple architecture. As will be shown in the next section, it nonetheless provides
    convincing results. The motivated reader is free to experiment with other architectures.
    Next, we declare a (standard) optimizer (step 4), define a function to take in
    text, and then vectorize it so we can feed it into our neural network (step 5).
    In step 5, note the shape of the vectors is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**X**: (number of reviews, `maxlen`, number of characters)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Y**: (number of reviews, number of characters)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In particular, we set `max_length=40` to simplify computation by indicating
    that we will only be considering the first `40` characters of a review. Having
    made all the needed preparations, we now pass in our text to be vectorized and
    then train our model on it (step 6). Specifically, our `text_to_vector` function
    takes the text and converts it into vectorized sentences, as well as a vectorized
    label, which is the following character. Finally, we save our model's weights
    so that we do not have to retrain it in the future (step 7).
  prefs: []
  type: TYPE_NORMAL
- en: Generating fake reviews
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having trained a network, our next step is to utilize it to generate new fake
    reviews.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Preparation for this recipe consists of installing `keras` and `tensorflow`
    in `pip`. The instructions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, we provide a recipe for using a previously trained
    RNN to generate reviews:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start by importing `keras`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a dictionary of indices for the characters or load up the one from the
    previous recipe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'Read in a seed text and declare `max_length` of a sentence taken in by the
    neural network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'Construct an RNN model and load in your pre-trained weights:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a function for sampling from a probability vector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'Generate random reviews from the initial seed text:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the review output from a run of the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/76e836af-49a3-417c-8a78-83248d10534e.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our initial steps (steps 1, 2, and 4) are operations we have performed during
    the training phase, which we reproduce here to allow the recipe to be self-contained.
    In step 3, we read in a seed text to initialize our RNN. The seed text can be
    any text consisting of the listed characters, as long as it is longer than `max_length`.
    Now, we must be able to create interesting text using our pre-trained, pre loaded,
    and initialized-on-a-seed-text neural network. To this end, we define a convenience
    function to sample the consequent character that the neural network will generate
    (step 5). Sampling from the probability vector ensures that the RNN does not simply
    select the most likely subsequent character, leading to repetitive generated text.
    There are more clever ways to sample, employing a temperature parameter and exponential
    weighing, but this one addresses the basics. Finally, in step 6, we go ahead and
    generate text using our neural network. We specify 1,000 as the number of characters
    to generate. Varying this parameter will alter the number of reviews in the output.
  prefs: []
  type: TYPE_NORMAL
- en: Fake news
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Fake news is a type of disinformation or propaganda that is spread via traditional
    news media or online social media. Like any disinformation campaign, its effects
    can be devastating. In this recipe, you will load a dataset of real and fake news,
    and utilize ML to determine when a news story is fake.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Preparation for this recipe consists of installing `pandas` and scikit-learn
    in `pip`. The instructions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: Also, extract `fake_news_dataset.7z`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, you will read in the fake news dataset, preprocess
    it, and then train a Random Forest classifier to detect fake news:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `pandas` and read in the CSV file, `fake_news_dataset.csv`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'Preprocess the dataset by focusing on articles in English and dropping rows
    with missing values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a convenience function to convert categorical features into numerical:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'Convert the `"fake"` and `"real"` features into numerical:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a function that will convert all labels into `real` or `fake`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply the function to the DataFrame to convert the labels into 0s and 1s:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a train-test split on the DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'Instantiate two Tf-Idf vectorizers, one for the text of the article and one
    for its headline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'Fit and transform the text and headline data using the Tf-Idf vectorizers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'Convert the remaining numerical fields of the DataFrame into matrices:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'Merge all of the matrices into one feature matrix and create a set of labels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'Instantiate a Random Forest classifier and train it on the training data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'Transform the text and headlines of the testing data into numerical form using
    the previously trained Tf-Idf vectorizers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'As before, combine all numerical features into one feature matrix:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'Test the Random Forest classifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our initial steps are to import our dataset of fake news and perform basic data
    munging (steps 1-6), such as converting the target into a numeric type. Next,
    in step 7, we train-test split our dataset in preparation for constructing a classifier.
    Since we are dealing with textual data, we must featurize these. To that end,
    in steps 8 and 9, we instantiate Tf-Idf vectorizers for NLP on the text and fit
    these. Other NLP approaches may be fruitful here. Continuing to featurize, we
    extract the numerical features of our DataFrame (steps 10 and 11). Having finished
    featurizing the dataset, we can now instantiate a basic classifier and fit it
    on the dataset (step 12). In steps 13-15, we repeat the process on the testing
    set and measure our performance. Observe the remarkable performance. Even now, possible
    steps for increasing the performance of the classifier include accounting for
    the source of the article, including images, and performing more sophisticated
    correlations with other events.
  prefs: []
  type: TYPE_NORMAL
