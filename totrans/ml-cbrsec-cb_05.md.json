["```\npip install opencv-python imutils\n```", "```\nimport os\n\ncaptcha_images_folder = \"captcha_images\"\ncaptchas = [\n    os.path.join(captcha_images_folder, f) for f in os.listdir(captcha_images_folder)\n]\n```", "```\nimport cv2\n\ndef preprocess_CAPTCHA(img):\n    \"\"\"Takes a CAPTCHA image and thresholds it.\"\"\"\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    gray_with_border = cv2.copyMakeBorder(gray, 8, 8, 8, 8, cv2.BORDER_REPLICATE)\n    preprocessed = cv2.threshold(\n        gray_with_border, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU\n    )[1]\n    return gray_with_border, preprocessed\n```", "```\ndef get_CAPTCHA_label(path_to_file):\n    \"\"\"Get the CAPTCHA text from the file name.\"\"\"\n    filename = os.path.basename(path_to_file)\n    label = filename.split(\".\")[0]\n    return label\n```", "```\ndef find_bounding_rectangles_of_contours(contours):\n    \"\"\"Determines the bounding rectangles of the contours of the cropped letters.\"\"\"\n    letter_bounding_rectangles = []\n    for contour in contours:\n        (x, y, w, h) = cv2.boundingRect(contour)\n        if w / h > 1.25:\n            half_width = int(w / 2)\n            letter_bounding_rectangles.append((x, y, half_width, h))\n            letter_bounding_rectangles.append((x + half_width, y, half_width, h))\n        else:\n            letter_bounding_rectangles.append((x, y, w, h))\n    return letter_bounding_rectangles\n```", "```\ndef CAPTCHA_to_gray_scale_and_bounding_rectangles(captcha_image_file):\n    \"\"\"Take a CAPTCHA and output a grayscale version as well as the bounding rectangles of its cropped letters.\"\"\"\n    image = cv2.imread(captcha_image_file)\n    gray, preprocessed = preprocess_CAPTCHA(image)\n    contours = cv2.findContours(\n        preprocessed.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n    )\n    contours = contours[0]\n    letter_bounding_rectangles = find_bounding_rectangles_of_contours(contours)\n    letter_bounding_rectangles = sorted(letter_bounding_rectangles, key=lambda x: x[0])\n    return gray, letter_bounding_rectangles\n```", "```\ndef bounding_rectangle_to_letter_image(letter_bounding_box, grayscaled):\n    \"\"\"Obtains the letter defined by a bounding box.\"\"\"\n    x, y, w, h = letter_bounding_box\n    letter_image = grayscaled[y - 2 : y + h + 2, x - 2 : x + w + 2]\n    return letter_image\n```", "```\ncaptcha_processing_output_folder = \"extracted_letter_images\"\ncharacter_counts = {}\n\ndef crop_bounding_rectangles_and_save_to_file(\n    letter_bounding_rectangles, gray, captcha_label\n):\n    \"\"\"Saves the individual letters of a CAPTCHA.\"\"\"\n    for letter_bounding_rectangle, current_letter in zip(\n        letter_bounding_rectangles, captcha_label\n    ):\n        letter_image = bounding_rectangle_to_letter_image(\n            letter_bounding_rectangle, gray\n        )\n\n        save_path = os.path.join(captcha_processing_output_folder, current_letter)\n        if not os.path.exists(save_path):\n            os.makedirs(save_path)\n\n        character_count = character_counts.get(current_letter, 1)\n\n        p = os.path.join(save_path, str(character_count) + \".png\")\n        cv2.imwrite(p, letter_image)\n\n        character_counts[current_letter] = character_count + 1\n```", "```\nimport imutils\nimport numpy as np\n\nfor captcha_image_file in captchas:\n    captcha_label = get_CAPTCHA_label(captcha_image_file)\n    gray, letter_bounding_rectangles = CAPTCHA_to_gray_scale_and_bounding_rectangles(\n        captcha_image_file\n    )\n    if len(letter_bounding_rectangles) != 4:\n        continue\n    crop_bounding_rectangles_and_save_to_file(\n        letter_bounding_rectangles, gray, captcha_label\n    )\n```", "```\npip install opencv-python imutils sklearn keras tensorflow\n```", "```\ncaptcha_processing_output_folder = \"extracted_letter_images\"\n```", "```\nimport cv2\nimport imutils\n```", "```\ndef resize_image_to_dimensions(image, desired_width, desired_height):\n    \"\"\"Resizes an image to the desired dimensions.\"\"\"\n    (h, w) = image.shape[:2]\n    if w > h:\n        image = imutils.resize(image, width=desired_width)\n    else:\n        image = imutils.resize(image, height=desired_height)\n    pad_width = int((desired_width - image.shape[1]) / 2.0)\n    pad_height = int((desired_height - image.shape[0]) / 2.0)\n    image_with_border = cv2.copyMakeBorder(\n        image, pad_height, pad_height, pad_width, pad_width, cv2.BORDER_REPLICATE\n    )\n    image_with_border_resized = cv2.resize(\n        image_with_border, (desired_width, desired_height)\n    )\n    return image_with_border_resized\n```", "```\ndef read_image(image_file_path):\n    \"\"\"Read in an image file.\"\"\"\n    img = cv2.imread(image_file_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img = resize_image_to_dimensions(img, 20, 20)\n    img = np.expand_dims(img, axis=2)\n    return img\n```", "```\nimport numpy as np\nimport os\nfrom imutils import paths\n\nimages = []\nlabels = []\n\nfor image_file_path in imutils.paths.list_images(captcha_processing_output_folder):\n    image_file = read_image(image_file_path)\n    label = image_file_path.split(os.path.sep)[-2]\n    images.append(image_file)\n    labels.append(label)\n```", "```\nimages = np.array(images, dtype=\"float\") / 255.0\nlabels = np.array(labels)\n```", "```\nfrom sklearn.model_selection import train_test_split\n\n(X_train, X_test, y_train, y_test) = train_test_split(\n    images, labels, test_size=0.3, random_state=11\n)\n```", "```\nfrom sklearn.preprocessing import LabelBinarizer\n\nlabel_binarizer = LabelBinarizer().fit(y_train)\ny_train = label_binarizer.transform(y_train)\ny_test = label_binarizer.transform(y_test)\n```", "```\nfrom keras.models import Sequential\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers.core import Flatten, Dense\n\nnum_classes = 32\nNN_model = Sequential()\nNN_model.add(\n    Conv2D(20, (5, 5), padding=\"same\", input_shape=(20, 20, 1), activation=\"relu\")\n)\nNN_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nNN_model.add(Conv2D(50, (5, 5), padding=\"same\", activation=\"relu\"))\nNN_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nNN_model.add(Flatten())\nNN_model.add(Dense(512, activation=\"relu\"))\nNN_model.add(Dense(num_classes, activation=\"softmax\"))\nNN_model.compile(\n    loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n)\nNN_model.summary()\n```", "```\nNN_model.fit(\n    X_train,\n    y_train,\n    validation_data=(X_test, y_test),\n    batch_size=16,\n    epochs=5,\n    verbose=1,\n)\n```", "```\nCAPTCHA = \"captcha_images\\\\NZH2.png\"\n```", "```\ncaptcha_label = get_CAPTCHA_label(CAPTCHA)\ngray, letter_bounding_rectangles = CAPTCHA_to_gray_scale_and_bounding_rectangles(\n    CAPTCHA\n)\npredictions = []\n```", "```\nfor letter_bounding_rectangle in letter_bounding_rectangles:\n    x, y, w, h = letter_bounding_rectangle\n    letter_image = gray[y - 2 : y + h + 2, x - 2 : x + w + 2]\n    letter_image = resize_image_to_dimensions(letter_image, 20, 20)\n    letter_image = np.expand_dims(letter_image, axis=2)\n    letter_image = np.expand_dims(letter_image, axis=0)\n    prediction = NN_model.predict(letter_image)\n    letter = label_binarizer.inverse_transform(prediction)[0]\n    predictions.append(letter)\n```", "```\npredicted_captcha_text = \"\".join(predictions)\nprint(\"Predicted CAPTCHA text is: {}\".format(predicted_captcha_text))\nprint(\"CAPTCHA text is: {}\".format(CAPTCHA.split(\"\\\\\")[-1].split(\".\")[0]))\n\nPredicted CAPTCHA text is: NZH2\nCAPTCHA text is: NZH2\n```", "```\npip install keras\n```", "```\ngcc -O3 -funroll-loops ./neuzz.c -o neuzz\n```", "```\n sudo dpkg --add-architecture i386\n sudo apt-get update\n sudo apt-get install libc6:i386 libncurses5:i386 libstdc++6:i386 lib32z1\n```", "```\n cd /sys/devices/system/cpu\n echo performance | tee cpu*/cpufreq/scaling_governor\n echo core >/proc/sys/kernel/core_pattern\n```", "```\n cp /path_to_neuzz/neuzz /path_to_neuzz/programs/readelf\n cp /path_to_neuzz/nn.py /path_to_neuzz/programs/readelf\n cp /path_to_neuzz/afl-showmap /path_to_neuzz/programs/readelf\n```", "```\nchmod +x /path_to_neuzz/programs/readelf/neuzz\nchmod +x /path_to_neuzz/programs/readelf/nn.py\nchmod +x /path_to_neuzz/programs/readelf/afl-showmap\nchmod +x /path_to_neuzz/programs/readelf/readelf\n```", "```\ncd /path_to_neuzz/programs/readelf\npython nn.py ./readelf -a\n```", "```\n ./neuzz -i neuzz_in -o seeds -l 7507 ./readelf -a @@\n```", "```\n ./readelf -a crash/file_name\n```", "```\nsudo apt install git\n```", "```\nsudo apt install python3-pip\n```", "```\ngit clone https://github.com/emmanueltsukerman/machine_learning_security.git\n```", "```\ncd machine_learning_security/DeepExploit\n```", "```\npip3 install -r requirements.txt\n```", "```\n ...snip...\n [ProxyList]\n ...snip...\n socks4  127.0.0.1 9050\n```", "```\n vim config.ini\n ...snip...\n proxy_host      : 127.0.0.1\n proxy_port      : 9050\n```", "```\nmsf> load msgrpc ServerHost=\"kali linux ip\" ServerPort=55553 User=test Pass=test1234.\n```", "```\n[*] MSGRPC Service: \"kali linux ip\":55553\n[*] MSGRPC Username: test\n[*] MSGRPC Password: test1234\n[*] Successfully loaded plugin: msgrpc\n```", "```\nfirefox report/DeepExploit_test_report.html\n```", "```\nsudo apt install git\n```", "```\nsudo apt install python3-pip\n```", "```\ngit clone https://github.com/gyoisamurai/GyoiThon.git\n```", "```\ncd GyoiThon\n```", "```\npip3 install -r requirements.txt\n```", "```\nsudo apt install git\n```", "```\ngit clone https://github.com/conmarap/website-fingerprinting\n```", "```\nsudo apt install tor lynx\n```", "```\n./pcaps/capture.sh duckduckgo.com\n```", "```\ntorsocks lynx https://duckduckgo.com\n```", "```\npython gather_and_train.py\n```", "```\npip install pandas sklearn xgboost\n```", "```\nimport pandas as pd\nimport os\n\ntraining_data = pd.read_csv(\"iot_devices_train.csv\")\ntesting_data = pd.read_csv(\"iot_devices_test.csv\")\n```", "```\nX_train, y_train = (\n    training_data.loc[:, training_data.columns != \"device_category\"].values,\n    training_data[\"device_category\"],\n)\nX_test, y_test = (\n    testing_data.loc[:, testing_data.columns != \"device_category\"].values,\n    testing_data[\"device_category\"],\n)\n```", "```\nfrom sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()\nle.fit(training_data[\"device_category\"].unique())\ny_train_encoded = le.transform(y_train)\ny_test_encoded = le.transform(y_test)\n```", "```\nfrom xgboost import XGBClassifier\n\nmodel = XGBClassifier()\n```", "```\nmodel.fit(X_train, y_train_encoded)\nmodel.score(X_test, y_test_encoded)\n```", "```\n0.6622222222222223\n```", "```\nsudo apt install git\n```", "```\ngit clone https://github.com/emmanueltsukerman/keystroke_dynamics.git\n```", "```\npython example.py\n```", "```\npip install keras tensorflow sklearn pandas matplotlib\n```", "```\ngit clone https://github.com/emmanueltsukerman/keras-malicious-url-detector.git\n```", "```\npython bidirectional_lstm_train.py\n```", "```\npython bidirectional_lstm_predict.py\n```", "```\nhttp://google.com,0\nhttp://facebook.com,0\nhttp://youtube.com,0\nhttp://yahoo.com,0\nhttp://baidu.com,0\nhttp://wikipedia.org,0\nhttp://qq.com,0\nhttp://linkedin.com,0\nhttp://live.com,0\nhttp://twitter.com,0\nhttp://amazon.com,0\nhttp://taobao.com,0\nhttp://blogspot.com,0\n\n<snip>\nhttp://360.cn,0 \nhttp://go.com,0 \nhttp://bbc.co.uk,0\nhttp://xhamster.com,0\n```", "```\ngit clone https://github.com/emmanueltsukerman/deep-pwning.git\n```", "```\npip install -r requirements.txt\n```", "```\npython mnist_driver.py â€“restore_checkpoint\n```", "```\npip install pandas gensim keras tensorflow sklearn\n```", "```\ngit clone https://github.com/emmanueltsukerman/Deep-Learning-Based-System-for-Automatic-Detection-of-Software-Vulnerabilities.git\n```", "```\npython vuldeepecker_train.py \"path to dataset\"\n```", "```\npython vuldeepecker_predict.py \"path to data\" \"path to model\"\n```", "```\nBidirectional(LSTM(300), input_shape=(50, 50))\nDense(300)\nLeakyReLU()\nDropout(0.5)\nDense(300)\nLeakyReLU()\nDropout(0.5)\nDense(2, activation='softmax')\nAdamax(lr=0.002)\n'categorical_crossentropy'\n```"]