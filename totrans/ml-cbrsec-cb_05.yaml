- en: Penetration Testing Using Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A penetration test, aka a pen test, is an authorized simulated cyberattack on
    an information system, designed to elicit security vulnerabilities. In this chapter,
    we will be covering a wide selection of machine learning-technologies for penetration
    testing and security countermeasures. We'll begin by cracking a simple CAPTCHA
    system. We'll cover the automatic discovery of software vulnerabilities using
    deep learning, using fuzzing and code gadgets. We'll demonstrate enhancements
    to Metasploit, as well as covering how to assess the robustness of machine learning
    systems to adversarial attacks. Finally, we'll cover more specialized topics,
    such as deanonymizing Tor traffic, recognizing unauthorized access via keystroke
    dynamics, and detecting malicious URLs.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: CAPTCHA breaker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural network-assisted fuzzing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DeepExploit
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Web server vulnerability scanner using machine learning (GyoiThon)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deanonymizing Tor using machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Internet of Things** (**IoT**) device type identification using machine learning'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keystroke dynamics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Malicious URL detector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep-pwning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep learning-based system for the automatic detection of software vulnerabilities
    (VulDeePecker)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will be using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keras
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenCV
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google API Client
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Censys
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NetworkX
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tldextract
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: dpkt
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NumPy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SciPy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xlib
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gensim
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code and datasets can be found at [https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/tree/master/Chapter05](https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/tree/master/Chapter05).
  prefs: []
  type: TYPE_NORMAL
- en: CAPTCHA breaker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A **CAPTCHA** is a system intended to prevent automated access or scraping.
    It does so by asking questions that are meant to recognize when the user is a
    human and when the user is a program. You have probably seen countless variations
    of the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/2d535842-1285-4150-aa14-470cc388ae91.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Sometimes, the request is to insert a code, sometimes it is to select some
    objects, for example, storefronts or traffic lights in a series of images, and
    sometimes the CAPTCHA is a math question. In this chapter, we are going to break
    a simple CAPTCHA system, called Really Simple CAPTCHA:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/3e6d42c3-d51a-4506-b5f0-f88abef38a1c.png)'
  prefs: []
  type: TYPE_IMG
- en: Despite its simplicity, **Really Simple CAPTCHA** is still widely used. Most
    importantly, it will illustrate how to approach breaking other, more complicated,
    CAPTCHA systems.
  prefs: []
  type: TYPE_NORMAL
- en: The first step will be to process the CAPTCHA dataset so that it is convenient
    for machine learning. The most naive approach to the problem is likely to fail.
    Namely, constructing a supervised classifier that takes a four-character CAPTCHA
    and classifies it into one of the *(26+10)^4 = 1,679,616* possible classes (26
    letters and 10 digits, taken to the fourth power due to the number of possible
    combinations of four in such a sequence) would require a huge amount of data and
    computation. Instead, we train a classifier on individual characters, cut the
    CAPTCHA into individual characters, and then perform classification four times.
    Here, again, there is a catch, and that is that it is not that easy to precisely
    crop the characters. Using OpenCV functionality and additional considerations,
    this recipe will solve this challenge.
  prefs: []
  type: TYPE_NORMAL
- en: Processing a CAPTCHA dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we'll perform the first part of creating a CAPTCHA breaker,
    in which we process a CAPTCHA dataset to make it amenable to training a machine
    learning model.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The preparation for this recipe consists of installing a number of packages
    in `pip`. The instructions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In addition, a collection of CAPTCHAs has been included for your convenience
    in `captcha_images.7z`. To use these, simply extract the archive into a `captcha_images` folder.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, we''ll process a CAPTCHA dataset to make it amenable
    to training a machine learning model:'
  prefs: []
  type: TYPE_NORMAL
- en: Collect a large corpus of CAPTCHAs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Our next goal is to process the CAPTCHAs, specify where the CAPTCHA images
    are stored and then enumerate all CAPTCHAs in the specified folder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a function that will take the image of a CAPTCHA and produce a grayscale
    version, as well as a thresholded (that is, black and white) version of the CAPTCHA''s
    image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a function that will take the path of a CAPTCHA and use it to store
    the text label of that CAPTCHA:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a function that will take the contours of the CAPTCHA, which we will
    compute, and then determine their bounding rectangles, in preparation for cropping
    the CAPTCHA into individual characters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a function that will take the path of a CAPTCHA, read it in as an image,
    and then preprocess it using the functions we have defined:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Define another helper function to take the bounding rectangles of contours
    of letters and produce character images from these:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Define one last helper function to perform the cropping of a CAPTCHA and then
    save each cropped character:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Loop through all of the CAPTCHAs, preprocess them, find the character contours,
    and then save the corresponding characters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our starting point is to collect a large corpus of CAPTCHAs (*step 1*). You
    can find these in `captcha_images.7z`. Alternatively, since Really Simple CAPTCHA's
    code is available online, you can modify it to generate a large number of CAPTCHAs.
    Additional ideas include utilizing bots to scrape CAPTCHAs. Next, in *step 2*,
    we specify where the CAPTCHA images are stored and then enumerate all CAPTCHAs
    in the specified folder. Our goal is to begin processing these. In *step 3*, we
    define a function to threshold and grayscale the CAPTCHA images. This allows us
    to reduce the computation, as well as making it easier to determine where one
    character starts and where the next one ends. We then define a function to obtain
    the label of a CAPTCHA (*step 4*). Continuing, to prepare for processing, we define
    a utility function that takes the contours of the CAPTCHA and uses them to determine
    each character's bounding rectangles. Once a bounding rectangle is found, it is
    easy to crop the character in order to isolate it (*step 5*). Next, in *step 6*,
    we combine the functions we have defined thus far into one convenient function.
    We also define an additional function, to actually crop the characters. Putting
    the above together, in *step 8*, we write a function that will perform the preceding
    steps, and then save the resulting isolated character, as well as keeping count
    of how many of each character has been saved. This is helpful for naming, as well
    as accounting. We are now in a position to perform the cropping, so, in *step
    9*, we iterate through all the CAPTCHAs and, using our utility functions, crop
    individual characters. Note that the `if` statement is meant to skip any incorrectly
    cropped CAPTCHAs.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the conclusion of the recipe, your output folder, `extracted_letter_images`,
    should have a folder for most letters and digits, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/23403397-e788-4dde-9d75-6ca1739d3a20.png)'
  prefs: []
  type: TYPE_IMG
- en: The reason not all characters and digits are represented is that the CAPTCHAs
    do not contain the digit 1 and letter I, as the two are easily confused. Similarly
    for 0 and O.
  prefs: []
  type: TYPE_NORMAL
- en: 'Inside each folder, you will have a large collection of instances of that letter
    or digit, cropped and processed from the initial CAPTCHAs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/21529bd2-1d19-4f7b-9556-2da0eb14c722.png)'
  prefs: []
  type: TYPE_IMG
- en: This concludes the preprocessing step.
  prefs: []
  type: TYPE_NORMAL
- en: Training a CAPTCHA solver neural network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that our data is nicely processed, we can train a neural network to perform
    CAPTCHA prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Preparation for this recipe consists of installing a number of packages in
    pip. The instructions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, we''ll train a neural network to solve Really Simple
    CAPTCHA''s CAPTCHAs:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Specify the folder where the extracted letter images are located:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Import OpenCV and imutils for image manipulation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a helper function to resize an image to a given size:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Prepare to read in the images:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Read in each letter image and record its label:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Normalize all images, that is, rescale the pixel values to 0-1 and convert
    labels to a NumPy array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a train-test split:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Import `LabelBinarizer` in order to encode the labels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a neural network architecture:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Fit the neural network to the training data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Select a CAPTCHA instance you would like to break:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: We'll import all of the functions we used to process images in the previous
    recipe, namely, `find_bounding_rectangles_of_contours`, `preprocess_CAPTCHA`,
    `get_CAPTCHA_label`, and `CAPTCHA_to_grayscale_and_bounding_rectangles`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Process the CAPTCHA image as we did in the previous recipe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Read in each cropped letter and use the neural network to predict the label:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Print out the prediction:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having completed our preprocessing of CAPTCHAs in the previous recipe, we are
    now ready to utilize these to train a CAPTCHA breaker. We start by setting a variable
    to the path of all of our individual characters extracted from CAPTCHAs. We import
    the image manipulation libraries we will be using (*step 2*) and then define a
    function to resize an image in *step 3*. This is a relatively standard method
    for character recognition, which allows training to proceed faster, and memory
    utilization to be reduced. In *step 4*, we define a convenience function to read
    in files as NumPy arrays, for training purposes, and then, in *step 5*, we iterate
    through all the letters and record their labels. Next, we normalize all of the
    images (*step 6*), another standard computer vision trick. We now create a train-test
    split in preparation for fitting our classifier (*step 7*) and then utilize label
    binarizers to encode our labels (*step 8*). This is necessary since the labels
    are the characters, which may not be numerical. In *step 9*, we define the architecture
    of our neural network. The architecture stated is relatively common, and offers
    both precision and speed. We fit our neural network to the training set in *step
    10*. Other parameters can enhance the performance of the network. The hard work
    is now finished. We now proceed to demonstrate how the CAPTCHA breaker works.
    In *step 11*, we choose a singleton instance to demonstrate the efficacy of our
    CAPTCHA breaker. In steps 12-14, we pass this image through our pipeline and produce
    predicted text for this CAPTCHA. Finally, we verify that the prediction is correct
    (*step 15*).
  prefs: []
  type: TYPE_NORMAL
- en: Neural network-assisted fuzzing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Fuzzing is a software vulnerability detection method wherein a large number
    of random inputs are fed into a program in search of ones that will cause a crash,
    unwanted information leak, or other unintended behavior. In automated fuzzing,
    a program generates these inputs. Generally, automated fuzzers suffer from the
    shortcoming that they tend to get stuck trying redundant inputs. For this reason,
    AI-based fuzzers have recently been developed. In this recipe, we'll employ NEUZZ,
    a neural network-based fuzzer by She et al. (see [https://arxiv.org/abs/1807.05620](https://arxiv.org/abs/1807.05620)),
    to find unknown vulnerabilities in software.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following recipe requires an Ubuntu 16.04 or 18.04 virtual or physical
    machine. On this device, run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Extract `neuzz-modified.7z` to a folder of your choosing.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, we provide a recipe for using NEUZZ to find crash-causing
    inputs to the readelf Unix tool:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Build neuzz using the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: If you receive warnings, that's okay.
  prefs: []
  type: TYPE_NORMAL
- en: '2\. Install the libraries needed for 32-bit binaries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'As root, set the CPU scaling algorithm and core dump notification:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Copy `neuzz`, `nn.py`, and `afl-showmap` to `programs/readelf`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Provide all files with executable permission:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Open a Terminal to start the neural network module:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Open another Terminal and start NEUZZ:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a snippet from running the commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/9675c7a1-2b44-43e5-8fd8-9816e4176517.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Test the crashes that NEUZZ has collected by running the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/d367d900-4a9f-47ff-906c-d598bb32bc9c.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most popular fuzzers, while effective in some limited situations, often get
    stuck in a loop. Gradient-based methods, such as the one discussed here, are promising
    but do not clearly apply to the problem, because real-world program behaviors
    are not necessarily smooth functions (for example, they can be discontinuous).
    The idea behind NEUZZ is to approximate the program's behavior as a smooth function
    using neural networks. Then, it is possible to apply gradient methods to improve
    fuzzing efficiency. We start our recipe by compiling NEUZZ (*step 1)*. The `funroll-loops`
    flag causes the compiler to unroll loops whose number of iterations can be determined
    at compile time or upon entry to the loop. As a result, the code is larger, and
    may run faster, although not necessarily. Continuing to setup NEUZZ, we add in
    32-bit support (*step 2*). We set the CPU scaling algorithm and core dump notification
    (*step 3*); the CPU frequency scaling is a setting that enables the OS to save
    power by scaling the CPU frequency up or down. In the next two steps, we simply
    place the files in a convenient location and allow permissions to execute them.
    We are done setting up NEUZZ. We can now use it to find inputs that cause programs
    to crash. In *step 6* and *step 7*, we begin the search for crashes using our
    neural network. After waiting a sufficient amount of time for *step 6* and *step 7*
    to gather enough inputs to cause the readelf tool to crash, we execute one of
    these inputs (*step 8*) to see the result. Indeed, we see that the input resulted
    in readelf crashing.
  prefs: []
  type: TYPE_NORMAL
- en: DeepExploit
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**DeepExploit** is a penetration testing tool that elevates Metasploit to a
    whole new level by leveraging AI. Its key features are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Deep penetration**: If DeepExploit successfully exploits the target, it will
    automatically execute the exploit to other internal servers as well.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Learning**: DeepExploit is a reinforcement learning system, akin to AlphaGo.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using DeepExploit to pentest your security systems will take you a long way
    toward keeping your systems secure. In this recipe, we will set up and run DeepExploit.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You will now be guided through the steps required to install `DeepExploit`:'
  prefs: []
  type: TYPE_NORMAL
- en: Download and set up Kali Linux. You can find VM images online at [https://www.offensive-security.com/kali-linux-vm-vmware-virtualbox-image-download/](https://www.offensive-security.com/kali-linux-vm-vmware-virtualbox-image-download/). The
    following steps all take place in your Kali Linux box.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Install Git by running the following in a Terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Install Python by running the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Clone the `git` repository. In a Terminal, run the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Open the `DeepExploit` directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In a Terminal, run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Install the prerequisite packages for `DeepExploit`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In a Terminal, run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will use `DeepExploit` to compromise a victim virtual machine.
  prefs: []
  type: TYPE_NORMAL
- en: Download a `Metasploitable2` VM image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Details can be found at [https://metasploit.help.rapid7.com/docs/metasploitable-2](https://metasploit.help.rapid7.com/docs/metasploitable-2).
  prefs: []
  type: TYPE_NORMAL
- en: Run a `Metasploitable2` instance on a VM.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Obtain the IP address of your `Metasploitable2`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The next step is to set up DeepExploit's configurations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In a Terminal, run `ifconfig` to obtain your Kali Linux's IP. Edit `config.ini`
    (for example, using `vim`) by setting `server_host` under `[common]` to your Kali
    Linux IP.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the values of `proxy_host` and `proxy_port` in `config.ini` to those in
    `proxychains.conf`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the Terminal, run `cat /etc/proxychains.conf` and find the value next to
    `socks4`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, set the values of `proxy_host` and `proxy_port` in `config.ini` equal
    to these values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Launch Metasploit in the Terminal by running `msfconsole`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Launch an RPC server on Metasploit. Where indicated, type in your Kali Linux''s
    IP:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'In a Terminal of your Kali Linux machine, run `python3 DeepExploit.py -t "Metasploitable2
    ip" -m train` to train `DeepExploit`. The beginning of the training should look
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/b2fccab6-e290-47a0-b863-7b447bb02774.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Whenever `DeepExploit` finds a vulnerability, you will see a `BINGO!!!` notification,
    as in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/b63f382c-1202-4166-9c8c-fb3fc19f2119.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Upon conclusion of the training, the learning is saved. You can see the completion
    screen here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/e312ea67-43e8-4c15-bb3f-1e50298d61ea.png)'
  prefs: []
  type: TYPE_IMG
- en: Test `Metasploitable2` for vulnerabilities using `DeepExploit`. In a Terminal,
    run `python DeepExploit.py -t "Metasploitable2 ip" -m test`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Check the report of the pen test as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll get the following as the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/840efb2f-5ed7-433e-8226-ef3474486359.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe requires a large amount of preparation and configuration. The initial
    steps are to set up a victim virtual machine (*steps 1 and 2*). In *step 3*, we
    determine the IP address of the victim VM. Note that the credentials of `Metasploitable2`
    are `msfadmin/msfadmin`. You can use the credentials to log in and then use `ifconfig`
    to obtain your `Metasploitable2` IP. If you are using a Kali Linux VM and a `Metasploitable2`
    VM on the same host, make sure that the two can communicate. For instance, put
    both VMs on a Host-Only Adapter and ping from your Kali Linux machine to the Metasploitable2
    machine. Proceeding, we now configure `DeepExploit` so we can target the victim
    VM (*steps 4*-*8*). In *steps 9* and *10*, we open up Metasploit, which is used
    as a submodule by `DeepExploit`. Metasploit is a major penetration testing framework.
    Having finished all the preparation, we can now start to train our model. In *step
    11*, we train `DeepExploit` on the `Metasploitable2` VM. The model utilizes the
    **Asynchronous Actor-Critic Agents** (`A3C`) algorithm, released by Google's DeepMind
    group a few years back, famous for outperforming the `deep Q-network` (`DQN`)
    approach. Next, we test our model (*step 12*) and print out the results of its
    analysis in a report (*step 13*). As you can see from the long report, a large
    number of vulnerabilities were found by `DeepExploit`. Speaking from a high level,
    the application of reinforcement learning to penetration testing suggests that
    extremely efficient automated penetration testing is on the horizon.
  prefs: []
  type: TYPE_NORMAL
- en: Web server vulnerability scanner using machine learning (GyoiThon)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**GyoiThon** is an intelligence-gathering tool for web servers. It executes
    remote access to a target web server and identifies products operated on the server,
    such as the **Content Management System** (**CMS**), web server software, framework,
    and programming language. In addition, it can execute exploit modules for the
    identified products using Metasploit.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the main features of GyoiThon are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Remote access/Fully automatic**: GyoiThon can automatically gather information
    on a target web server using only remote access. You only execute GyoiThon once
    for your operation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Non-destructive test**:GyoiThon can gather information on the target web
    server using only normal access. A feature permits GyoiThon to access abnormally,
    such as by sending exploit modules.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Gathering varied information**: GyoiThon has a number of intelligence gathering
    engines such as a web crawler, the Google Custom Search API, Censys, an explorer
    of default contents, and the examination of cloud services. By analyzing gathered
    information using string pattern matching and machine learning, GyoiThon can identify
    a product/version/CVE number operated on the target web server, HTML comments/debug
    messages, login pages, and other information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Examination of real vulnerabilities**: GyoiThon can execute exploit modules
    on identified products using Metasploit. As a result, it can determine the real
    vulnerabilities of the target web server.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You will now be guided through the steps for installing and running GyoiThon:'
  prefs: []
  type: TYPE_NORMAL
- en: Download and set up Kali Linux. You can find VM images online at [https://www.offensive-security.com/kali-linux-vm-vmware-virtualbox-image-download/](https://www.offensive-security.com/kali-linux-vm-vmware-virtualbox-image-download/). The
    following steps all take place in your Kali Linux box.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Install `git` in the Terminal by running the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Install `python` in the Terminal by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Clone the Git repository into your Linux box in the Terminal by running the
    following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Open the `GyoiThon` directory in the Terminal by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Install the prerequisites for DeepExploit in the Terminal by running the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: (Optional.) Substitute the `Gyoi_CveExplorerNVD` file in modules with the one
    available in the repository for this book. In some cases, the original code has
    malfunctioned and the modified code available in the repository for this book
    may address this problem.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, you will use DeepExploit to compromise a victim virtual machine:'
  prefs: []
  type: TYPE_NORMAL
- en: Download a `Metasploitable2` VM image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run a `Metasploitable2` instance on a VM.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Obtain the IP address of your `Metasploitable2`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In your Kali Linux machine, you should be able to see your `Metasploitable2''s`
    website instance by typing `Metasploitable2''s ip address:80` into a web browser:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/71464351-549d-4a10-9759-c96489711565.png)'
  prefs: []
  type: TYPE_IMG
- en: In a Terminal, run `ifconfig` to obtain your Kali Linux's IP. Edit `config.ini`
    (for example, using `vim`) by setting `proxy` to `empty`, `server host` to your
    `Kali Linux IP`, `LHOST` to your `Metasploitable2 IP`, and `LPORT` to `80`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the host file and add the `Metasploitable2` web server address by typing
    in `http:Metasploitable2 ip:80/`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In a Terminal of your Kali Linux machine, run `python3 Gyoithon.py` to begin
    the attack.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Upon the conclusion of the attack, check the report of the pen test in the
    folder report:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/efb44d52-8217-4d81-beae-0e222e914e69.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Steps 1-3* are no different than in the recipe for DeepExploit, where we prepared
    a victim VM. The credentials of `Metasploitable2` are `msfadmin/msfadmin`. You
    can use the credentials to log in and then use `ifconfig` to obtain your `Metasploitable2`
    IP. If you are using a Kali Linux VM and `Metasploitable2` VM on the same host,
    make sure that the two can communicate. For instance, put both VMs on a Host-only
    Adapter and ping from your Kali Linux machine to the Metasploitable2 machine.
    Next, we verify that the environment has been properly set up by checking that
    we are able to access the victim VM''s web page in *step 4*. In *step 5* and *step
    6*, we configure GyoiThon in preparation for our pen test. Having finished setting
    up our environments, we are now ready to perform the pen test. In *step 7*, we
    utilize GyoiThon to search for vulnerabilities. We then output a full report of
    the vulnerabilities detected (*step 8*). Looking at the report, we can see that
    GyoiThon was able to find a large number of vulnerabilities. Having now determined
    the vulnerabilities of the victim box, we can go ahead and exploit these, using,
    for example, Metasploit, to hack the victim box.'
  prefs: []
  type: TYPE_NORMAL
- en: Deanonymizing Tor using machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tor is a free, open source software for enabling anonymous communication. In
    addition, websites accessible only when using the Tor browser exist, and are part
    of the **dark web** ecosystem – the name given to the part of the internet that
    is hidden from the average user. In this recipe, we will deanonymize Tor traffic
    by collecting enough features and information from individual sessions to be able
    to identify the activity of anonymized users. This recipe utilizes the **conmarap/website-fingerprinting**
    repository.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You will now be guided through the steps needed to set up Tor and the Lynx
    web browser:'
  prefs: []
  type: TYPE_NORMAL
- en: Set up an Ubuntu VM.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Install `git` in the Terminal by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Clone the code repository in the Terminal by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Install `tor` and `lynx` in the Terminal by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe consists of three parts. The first part consists of the data collection
    of Tor traffic. The second consists of training a classifier on this data. And
    the final part consists of using the classifier to predict the type of traffic
    being observed.
  prefs: []
  type: TYPE_NORMAL
- en: Collecting data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following steps need to be followed for data collection:'
  prefs: []
  type: TYPE_NORMAL
- en: 'List the classes of traffic you wish to classify in `config.json`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/5c3ccb28-410d-41c7-bb0b-f8f7c8577d14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Collect an additional data point for one of the classes, say `duckduckgo.com`,
    in a Terminal, from the website-fingerprinting directory by running the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Open another Terminal, and run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Your two Terminals should look as follows, at this point:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ecfa12db-50fc-48f7-b06e-fa36a7cbdbdb.png)'
  prefs: []
  type: TYPE_IMG
- en: Once you have finished the browsing session, end the capture by pressing *Q*
    twice.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When a sufficient amount of training data has been gathered, we are ready to
    train a classifier.
  prefs: []
  type: TYPE_NORMAL
- en: Training
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To train a classifier on the data, run the following script using Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: The result is a file classifier: `nb.dmp`.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s use the classifier to predict the type of traffic being observed:'
  prefs: []
  type: TYPE_NORMAL
- en: To predict a new instance of traffic, collect the `pcap` file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Using Python, run the `predict.py` script with the `pcap` file as an argument:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/3ed74252-6025-48bc-b427-eea3b88220cd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The clustering by the author looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/63bfbc53-5589-47b6-a81a-a8a28fe1d895.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding diagram shows that the features do indeed differentiate between
    the type of traffic, despite it being anonymous.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We start constructing our classifier by creating a catalog of all of the websites
    we wish to profile (*step 1*). The more there are, the more likely the target
    is to visit one of these. On the other hand, the fewer there are, the smaller
    the training dataset will have to be. In *steps 2*-*4*, we perform the steps required
    to collect a data point for our classifier. Specifically, we do so by visiting
    one of the websites defined in *step 1* and then capture the packets for that
    visit. By repeating these steps for different browsing sessions, we are able to
    construct a robust dataset. In *step 5*, we train a classifier on our data, which
    we have collected up until now. We are now ready to test out our classifier. In
    *step 6*, we visit a website and collect its `pcap`, just as we did when collecting
    our training data. We then employ the classifier to classify this visit (*step
    7*). We see that it did, indeed, correctly determine which web page the user visited,
    despite the user using Tor.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, in this recipe, scikit-learn was used to write a k-nearest neighbors
    classifier that would classify Tor `pcap` files. In practice, traffic is never
    as *clean*, so accuracy is likely to decrease on a real dataset of the same size.
    However, an entity with large amounts of resources can create a very accurate
    classifier. This means that it is entirely possible to use a method like this
    to accurately compromise anonymized users.
  prefs: []
  type: TYPE_NORMAL
- en: IoT device type identification using machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the advent of IoT, the attack surfaces on any given target have increased
    exponentially. With new technology comes new risks, and, in the case of IoT, one
    such risk to an organization is the addition of a malicious IoT device connected
    to the organization's network. It is essential to be able to tell when such a
    device has been added to a network and to understand its nature. In this recipe,
    we'll build a machine learning model to classify network IoT devices by type.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The preparation for this recipe consists of installing the `sklearn`, `pandas`,
    and `xgboost` packages in `pip`. The instructions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: A dataset has been provided for you in the `iot_train.csv` and `iot_test.csv`
    files.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, we''ll train and test a classifier on IoT network information:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `pandas` and `os` and read in the training and testing data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The data contains 298 features, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/9c50983f-be84-4f46-9db7-6d554bbccf6e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Create a training and testing dataset, where the target is the device category:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: The device categories are security camera, TV, smoke detector, thermostat, water
    sensor, watch, baby monitor, motion sensor, lights, and socket.
  prefs: []
  type: TYPE_NORMAL
- en: 'Encode the class categories into numerical form:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Instantiate an `xgboost` classifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Train and test the `xgboost` classifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An important motivation for this recipe is that we can't rely on the IP address
    as an identifier of the device, since this value can be spoofed. Consequently,
    we would like to analyze the traffic's high-level data, that is, the metadata
    and traffic statistics, rather than content, to determine whether the device belongs
    to the network. We begin by reading in the training and testing datasets. We go
    on to featurize these and perform a quick data exploration step by observing the
    classification labels (*step 2*). To feed these into our classifier, we convert
    these categorical labels into numerical ones to be used to train our machine learning
    classifier (*step 3*). Having featurized the data in *step 4* and *step 5*, we
    instantiate, train and test an `xgboost` classifier, obtaining a score of `0.66`
    on the testing set. There are 10 categories of IoT devices in the associated data.
    The baseline of randomly guessing between the 10 would yield an accuracy of 0.1\.
    The `XGBoost` classifier trained here attains an accuracy of 0.66, suggesting
    that it is indeed a promising approach to classify IoT devices successfully based
    on high-level traffic data.
  prefs: []
  type: TYPE_NORMAL
- en: Keystroke dynamics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Keystroke dynamics, aka typing biometrics, is the study of recognizing a person
    by the way they type. One important use case is recognizing which user is logging
    in using a given credential, for example, who is logging in as root? Another use
    case is recognizing when a different user has typed a sequence of keystrokes.
    In this recipe, we'll show how to use a machine learning-based keystroke dynamics
    algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This recipe will require a Linux virtual or real machine. In preparation, do
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Install `git` on your device.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In a Terminal, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Clone the `git` repository containing the code for the keystroke dynamics algorithm:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, we''ll train the model on two users'' typing patterns
    and then use the model to recognize one of the user''s typing patterns. The recipe
    should be run on a Linux virtual or real machine:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run `example.py`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Train on the keystrokes of user 1 by selecting option 1 and then typing in
    the text:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/209f8806-a477-4839-b1e1-221d511f8a53.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Run `example.py` and train on the keystrokes of user 2 by selecting option
    1 and then having user 2 type in the text:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/b69bbb11-e7fb-4448-b4c9-fb5081e45a08.png)'
  prefs: []
  type: TYPE_IMG
- en: Run `example.py` and, this time, select option 2.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Have one of the users type the text again. The algorithm will match the keyboard
    dynamics to the most similar typist from the training data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/04dfcca1-d472-4c2a-a11e-b4c06a74d71f.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Analyzing keystroke dynamics utilizes the rhythm and pace at which a user types
    on a keyboard to verify that individual's identity. We begin by setting up some
    baselines. In *step 1* and *step 2*, we set up the keystroke dynamics system to
    learn the typing pattern of the first user. We then do the same for the second
    user (*step 3*). This establishes our *normal* users, as well as their typing
    patterns. In *step 4* and *step 5*, we utilize our trained model (trained in *steps
    1*-*3*), to determine who the current user is. As you can see, the classifier
    outputs a similarity score and a prediction of who the current user is from its
    catalog of saved users. This allows us to detect unauthorized users, as well as
    to simply keep track of system usage.
  prefs: []
  type: TYPE_NORMAL
- en: Malicious URL detector
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Malicious URLs cause billions of dollars of damage every year by hosting spam,
    malware, and exploits, as well as stealing information. Traditionally, defenses
    against these have relied on blacklists and whitelists – lists of URLs that are
    considered malicious, and lists of URLs that are considered safe. However, blacklists
    suffer from a lack of generality and an inability to defend against previously
    unseen malicious URLs. To remedy the situation, machine learning techniques have
    been developed. In this recipe, we'll run a malicious URL detector using character-level
    recurrent neural networks with Keras. The code is based on [https://github.com/chen0040/keras-malicious-url-detector](https://github.com/chen0040/keras-malicious-url-detector).
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The preparation for this recipe consists of installing a number of packages
    in `pip`. The instructions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition, clone the following `git` repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Train the bidirectional LSTM model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'The training screen should look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/84819f8a-6cdb-44bc-92b1-ddf7aaae7375.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Test the classifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'The testing screen should look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/9c1798ae-4ed4-4b4c-9241-67f07a4fd2cb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, you can see the results under the `reports` folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/44212e52-6f14-44fd-864b-1937f0dbf77b.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is a relatively simple recipe but serves as a good starting point for
    a more high-powered malicious URL detector. The dataset consists of URLs with
    the labels 0 and 1, depending on whether they are malicious or benign:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: In *step 1*, we train a bidirectional LSTM model. By digging deeper into the
    code, you can adjust the network to your needs. Having trained our model, it is
    important to assess its performance and perform some sanity checks. We do so in
    *step 2*, the testing step, consisting of displaying the results of the classifier
    on a random selection of 20 URLs. In general, a bidirectional LSTM is a recurrent
    neural network architecture that shows great promise, due to its ability to remember
    information and analyze data from both beginning to end, and end to beginning.
  prefs: []
  type: TYPE_NORMAL
- en: Deep-pwning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deep-pwning is a framework for evaluating the robustness of machine learning
    tools against adversarial attacks. It has become widely known in the data science
    community that naive machine learning models, such as deep neural networks trained
    with the sole aim of classifying images, are very easily fooled.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows Explaining and Harnessing Adversarial Examples,
    I. J. Goodfellow et al:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/9ac0d85b-0396-4dcd-af64-85b1d4e362f1.png)'
  prefs: []
  type: TYPE_IMG
- en: Cybersecurity being an adversarial field of battle, a machine learning model
    used to secure from attackers ought to be robust against adversaries. As a consequence,
    it is important to not only report the usual performance metrics, such as accuracy,
    precision, and recall, but also to have some measure of the adversarial robustness
    of the model. The deep-pwning framework is a simple toolkit for doing so.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In preparation for this recipe, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Install `git` on your device.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Download or clone the repository using Git by using the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: Install the requirements for the repo.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In a Terminal, go to the root directory of your repository and run the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, you will utilize deep-pwning to attack LeNet5 on the
    MNIST digits dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: 'From the directory down, run the MNIST driver using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'The result should appear like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/850ff85a-8a0e-4458-80f8-9b13406ba064.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In *step 1*, we create a large dataset of adversarial samples; namely, 150,000
    adversarial samples are created, almost all of which are able to fool LeNet5 on
    digits. To examine these adversarial samples, unpickle the pickle in the output
    directory, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bb8fd2b2-dd3f-4dbf-906c-6c8e2af2fdf7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Under `utils`, a file named `mnist_read_pickle.py` takes as an argument the
    `pickle` file. Running it displays one of the adversarial samples. The following
    image tricks LeNet5 into thinking that it is seeing the number 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/d48b2dcf-0f92-4bb1-a4a8-fdf33014de85.png)'
  prefs: []
  type: TYPE_IMG
- en: The deep-pwning framework is designed to be modular, so a user plugs in and
    modifies pieces to suit their needs. For instance, replacing the MNIST dataset
    and the LeNet5 architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning-based system for the automatic detection of software vulnerabilities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Experts in information security can usually identify potentially exploitable
    pieces of code. Yet, the work is intensive and costly, and may not be sufficient
    to make a program secure. One of the great advantages of deep learning over traditional
    machine learning is that features can be automatically discovered. This allows
    us to alleviate the need for a human expert on vulnerabilities, as well as to
    produce more effective systems. In this recipe, we'll utilize a modified version
    of *VulDeePecker : **A Deep Learning-Based System for Vulnerability Detection* ([https://arxiv.org/pdf/1801.01681.pdf](https://arxiv.org/pdf/1801.01681.pdf)),
    to automatically detect buffer error vulnerabilities and resource management errors
    in C/C++ software.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The preparation for this recipe consists of installing the `pandas`, `gensim`,
    `keras`, `tensorflow`, and `sklearn` packages in `pip`. The instructions are as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition, for this recipe, clone the repository for VulDeePecker:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Install `git` and then, in a Terminal, run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: Two datasets are available in the `datasets` folder, `cwe119_cgd.7z` and `cwe399_cgd.7z`.
    If you wish to use them for this recipe, extract them.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Collect a training dataset of gadgets and place it under `datasets`. Two datasets
    are available in the `datasets` folder, and they are of this form:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/5bbdf15e-6406-47bc-8453-6fb22a8ac5f2.png)'
  prefs: []
  type: TYPE_IMG
- en: Train and test the deep learning model on your dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This is accomplished by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is displayed in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/714ed965-843e-4b21-9bd8-1d3c857a5f23.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Collect the dataset you would like to predict on and place it under `datasets`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/86517346-69b4-49ec-97f7-9d758835d94b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Use your trained model to predict whether these are vulnerable pieces of code
    by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/0422d9eb-52b2-4079-a859-beecd558e5de.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For machine learning to work for vulnerability detection, you need to find
    representations of the software programs that are amenable to learning. For this
    purpose, we use code gadgets, which are transformed into vectors. A code gadget
    is a selection of lines of code that are semantically related to each other. In
    *step 1*, we collect such code gadgets for training. You can see an image of three
    code gadgets, along with labels. Here, a label of 1 indicates a vulnerability,
    while a label of 0 indicates no vulnerability. To extract gadgets from the desired
    program, it is advised to use the commercial product Checkmarx to extract program
    slices, and then assemble them into code gadgets. Another dataset is available.
    That dataset, `cwe-119`, corresponds to buffer error vulnerabilities. Next, we
    train a deep learning model on our vulnerability dataset (*step 2*). The deep
    learning model used is a **Bidirectional Long Short-Term Memory** (**BLSTM**),
    whose architecture is given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: Note that the training phase automatically saves the model as `[base-name-of-training-dataset]_model.h5`.
    We are now ready to look for new vulnerabilities. So, we place a testing set in
    `datasets` (*step 3*) and then put our neural network to use by predicting vulnerabilities
    in this new set (*step 4*).
  prefs: []
  type: TYPE_NORMAL
