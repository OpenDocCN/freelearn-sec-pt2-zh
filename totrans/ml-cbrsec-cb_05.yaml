- en: Penetration Testing Using Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A penetration test, aka a pen test, is an authorized simulated cyberattack on
    an information system, designed to elicit security vulnerabilities. In this chapter,
    we will be covering a wide selection of machine learning-technologies for penetration
    testing and security countermeasures. We'll begin by cracking a simple CAPTCHA
    system. We'll cover the automatic discovery of software vulnerabilities using
    deep learning, using fuzzing and code gadgets. We'll demonstrate enhancements
    to Metasploit, as well as covering how to assess the robustness of machine learning
    systems to adversarial attacks. Finally, we'll cover more specialized topics,
    such as deanonymizing Tor traffic, recognizing unauthorized access via keystroke
    dynamics, and detecting malicious URLs.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following recipes:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: CAPTCHA breaker
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural network-assisted fuzzing
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DeepExploit
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Web server vulnerability scanner using machine learning (GyoiThon)
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deanonymizing Tor using machine learning
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Internet of Things** (**IoT**) device type identification using machine learning'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keystroke dynamics
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Malicious URL detector
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep-pwning
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep learning-based system for the automatic detection of software vulnerabilities
    (VulDeePecker)
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will be using the following:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keras
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenCV
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google API Client
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Censys
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NetworkX
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tldextract
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: dpkt
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NumPy
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SciPy
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xlib
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gensim
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code and datasets can be found at [https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/tree/master/Chapter05](https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/tree/master/Chapter05).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: CAPTCHA breaker
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A **CAPTCHA** is a system intended to prevent automated access or scraping.
    It does so by asking questions that are meant to recognize when the user is a
    human and when the user is a program. You have probably seen countless variations
    of the following screenshot:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/2d535842-1285-4150-aa14-470cc388ae91.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
- en: 'Sometimes, the request is to insert a code, sometimes it is to select some
    objects, for example, storefronts or traffic lights in a series of images, and
    sometimes the CAPTCHA is a math question. In this chapter, we are going to break
    a simple CAPTCHA system, called Really Simple CAPTCHA:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/3e6d42c3-d51a-4506-b5f0-f88abef38a1c.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
- en: Despite its simplicity, **Really Simple CAPTCHA** is still widely used. Most
    importantly, it will illustrate how to approach breaking other, more complicated,
    CAPTCHA systems.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: The first step will be to process the CAPTCHA dataset so that it is convenient
    for machine learning. The most naive approach to the problem is likely to fail.
    Namely, constructing a supervised classifier that takes a four-character CAPTCHA
    and classifies it into one of the *(26+10)^4 = 1,679,616* possible classes (26
    letters and 10 digits, taken to the fourth power due to the number of possible
    combinations of four in such a sequence) would require a huge amount of data and
    computation. Instead, we train a classifier on individual characters, cut the
    CAPTCHA into individual characters, and then perform classification four times.
    Here, again, there is a catch, and that is that it is not that easy to precisely
    crop the characters. Using OpenCV functionality and additional considerations,
    this recipe will solve this challenge.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: Processing a CAPTCHA dataset
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we'll perform the first part of creating a CAPTCHA breaker,
    in which we process a CAPTCHA dataset to make it amenable to training a machine
    learning model.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The preparation for this recipe consists of installing a number of packages
    in `pip`. The instructions are as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In addition, a collection of CAPTCHAs has been included for your convenience
    in `captcha_images.7z`. To use these, simply extract the archive into a `captcha_images` folder.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, we''ll process a CAPTCHA dataset to make it amenable
    to training a machine learning model:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Collect a large corpus of CAPTCHAs.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Our next goal is to process the CAPTCHAs, specify where the CAPTCHA images
    are stored and then enumerate all CAPTCHAs in the specified folder:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Define a function that will take the image of a CAPTCHA and produce a grayscale
    version, as well as a thresholded (that is, black and white) version of the CAPTCHA''s
    image:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Define a function that will take the path of a CAPTCHA and use it to store
    the text label of that CAPTCHA:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Define a function that will take the contours of the CAPTCHA, which we will
    compute, and then determine their bounding rectangles, in preparation for cropping
    the CAPTCHA into individual characters:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Define a function that will take the path of a CAPTCHA, read it in as an image,
    and then preprocess it using the functions we have defined:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Define another helper function to take the bounding rectangles of contours
    of letters and produce character images from these:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Define one last helper function to perform the cropping of a CAPTCHA and then
    save each cropped character:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Loop through all of the CAPTCHAs, preprocess them, find the character contours,
    and then save the corresponding characters:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: How it works…
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our starting point is to collect a large corpus of CAPTCHAs (*step 1*). You
    can find these in `captcha_images.7z`. Alternatively, since Really Simple CAPTCHA's
    code is available online, you can modify it to generate a large number of CAPTCHAs.
    Additional ideas include utilizing bots to scrape CAPTCHAs. Next, in *step 2*,
    we specify where the CAPTCHA images are stored and then enumerate all CAPTCHAs
    in the specified folder. Our goal is to begin processing these. In *step 3*, we
    define a function to threshold and grayscale the CAPTCHA images. This allows us
    to reduce the computation, as well as making it easier to determine where one
    character starts and where the next one ends. We then define a function to obtain
    the label of a CAPTCHA (*step 4*). Continuing, to prepare for processing, we define
    a utility function that takes the contours of the CAPTCHA and uses them to determine
    each character's bounding rectangles. Once a bounding rectangle is found, it is
    easy to crop the character in order to isolate it (*step 5*). Next, in *step 6*,
    we combine the functions we have defined thus far into one convenient function.
    We also define an additional function, to actually crop the characters. Putting
    the above together, in *step 8*, we write a function that will perform the preceding
    steps, and then save the resulting isolated character, as well as keeping count
    of how many of each character has been saved. This is helpful for naming, as well
    as accounting. We are now in a position to perform the cropping, so, in *step
    9*, we iterate through all the CAPTCHAs and, using our utility functions, crop
    individual characters. Note that the `if` statement is meant to skip any incorrectly
    cropped CAPTCHAs.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的起点是收集大量 CAPTCHA（*步骤 1*）。您可以在 `captcha_images.7z` 中找到这些 CAPTCHA。或者，由于 Really
    Simple CAPTCHA 的代码可以在线获取，您可以修改它来生成大量的 CAPTCHA。其他方法包括使用机器人抓取 CAPTCHA。接下来，在 *步骤
    2* 中，我们指定 CAPTCHA 图像的存储位置，并列举出指定文件夹中的所有 CAPTCHA。我们的目标是开始处理这些 CAPTCHA。在 *步骤 3*
    中，我们定义一个函数，用来阈值化并将 CAPTCHA 图像转换为灰度图像。这样可以减少计算量，并且更容易确定一个字符的起始位置和下一个字符的结束位置。然后我们定义一个函数来获取
    CAPTCHA 的标签（*步骤 4*）。接下来，为了准备处理，我们定义一个实用函数，获取 CAPTCHA 的轮廓，并利用这些轮廓来确定每个字符的边界矩形。一旦找到边界矩形，就可以轻松地裁剪字符，以便将其隔离出来（*步骤
    5*）。然后，在 *步骤 6* 中，我们将到目前为止定义的函数组合成一个方便的函数。我们还定义了一个额外的函数，用来实际裁剪字符。将以上内容结合起来，在 *步骤
    8* 中，我们编写一个函数来执行前面的步骤，然后保存结果中的隔离字符，并统计每个字符保存的数量。这对命名和统计都非常有帮助。现在我们可以开始裁剪了，所以，在
    *步骤 9* 中，我们遍历所有的 CAPTCHA，并利用我们的实用函数裁剪单个字符。请注意，`if` 语句用于跳过裁剪错误的 CAPTCHA。
- en: 'At the conclusion of the recipe, your output folder, `extracted_letter_images`,
    should have a folder for most letters and digits, as shown in the following screenshot:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程结束时，您的输出文件夹 `extracted_letter_images` 应该会有一个文件夹，包含大多数字母和数字，如下图所示：
- en: '![](assets/23403397-e788-4dde-9d75-6ca1739d3a20.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/23403397-e788-4dde-9d75-6ca1739d3a20.png)'
- en: The reason not all characters and digits are represented is that the CAPTCHAs
    do not contain the digit 1 and letter I, as the two are easily confused. Similarly
    for 0 and O.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有的字符和数字都有表示，原因是 CAPTCHA 中不包含数字 1 和字母 I，因为这两者容易混淆。同理，数字 0 和字母 O 也存在相同问题。
- en: 'Inside each folder, you will have a large collection of instances of that letter
    or digit, cropped and processed from the initial CAPTCHAs:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个文件夹内，您将会有大量该字母或数字的实例，这些实例是从原始 CAPTCHA 中裁剪和处理出来的：
- en: '![](assets/21529bd2-1d19-4f7b-9556-2da0eb14c722.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/21529bd2-1d19-4f7b-9556-2da0eb14c722.png)'
- en: This concludes the preprocessing step.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这结束了预处理步骤。
- en: Training a CAPTCHA solver neural network
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练一个 CAPTCHA 解码神经网络
- en: Now that our data is nicely processed, we can train a neural network to perform
    CAPTCHA prediction.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的数据已经处理得很整洁，可以训练一个神经网络来进行 CAPTCHA 预测。
- en: Getting ready
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Preparation for this recipe consists of installing a number of packages in
    pip. The instructions are as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程的准备工作包括通过 pip 安装若干软件包。安装步骤如下：
- en: '[PRE9]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: How to do it...
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'In the following steps, we''ll train a neural network to solve Really Simple
    CAPTCHA''s CAPTCHAs:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的步骤中，我们将训练一个神经网络来解决 Really Simple CAPTCHA 的 CAPTCHA：
- en: 'Specify the folder where the extracted letter images are located:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指定提取的字母图像所在的文件夹：
- en: '[PRE10]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Import OpenCV and imutils for image manipulation:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 OpenCV 和 imutils 进行图像处理：
- en: '[PRE11]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Define a helper function to resize an image to a given size:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个辅助函数，将图像调整为给定的大小：
- en: '[PRE12]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Prepare to read in the images:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备读取图像：
- en: '[PRE13]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Read in each letter image and record its label:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取每个字母图像并记录其标签：
- en: '[PRE14]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Normalize all images, that is, rescale the pixel values to 0-1 and convert
    labels to a NumPy array:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 归一化所有图像，即将像素值缩放到0-1，并将标签转换为NumPy数组：
- en: '[PRE15]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Create a train-test split:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建训练集和测试集的划分：
- en: '[PRE16]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Import `LabelBinarizer` in order to encode the labels:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`LabelBinarizer`以编码标签：
- en: '[PRE17]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Define a neural network architecture:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义神经网络架构：
- en: '[PRE18]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Fit the neural network to the training data:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将神经网络拟合到训练数据上：
- en: '[PRE19]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Select a CAPTCHA instance you would like to break:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个你想破解的CAPTCHA实例：
- en: '[PRE20]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We'll import all of the functions we used to process images in the previous
    recipe, namely, `find_bounding_rectangles_of_contours`, `preprocess_CAPTCHA`,
    `get_CAPTCHA_label`, and `CAPTCHA_to_grayscale_and_bounding_rectangles`.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将导入在上一节中用于处理图像的所有函数，即`find_bounding_rectangles_of_contours`、`preprocess_CAPTCHA`、`get_CAPTCHA_label`和`CAPTCHA_to_grayscale_and_bounding_rectangles`。
- en: 'Process the CAPTCHA image as we did in the previous recipe:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照我们在上一节中所做的方式处理CAPTCHA图像：
- en: '[PRE21]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Read in each cropped letter and use the neural network to predict the label:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取每个裁剪后的字母，并使用神经网络预测标签：
- en: '[PRE22]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Print out the prediction:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出预测结果：
- en: '[PRE23]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: How it works…
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: Having completed our preprocessing of CAPTCHAs in the previous recipe, we are
    now ready to utilize these to train a CAPTCHA breaker. We start by setting a variable
    to the path of all of our individual characters extracted from CAPTCHAs. We import
    the image manipulation libraries we will be using (*step 2*) and then define a
    function to resize an image in *step 3*. This is a relatively standard method
    for character recognition, which allows training to proceed faster, and memory
    utilization to be reduced. In *step 4*, we define a convenience function to read
    in files as NumPy arrays, for training purposes, and then, in *step 5*, we iterate
    through all the letters and record their labels. Next, we normalize all of the
    images (*step 6*), another standard computer vision trick. We now create a train-test
    split in preparation for fitting our classifier (*step 7*) and then utilize label
    binarizers to encode our labels (*step 8*). This is necessary since the labels
    are the characters, which may not be numerical. In *step 9*, we define the architecture
    of our neural network. The architecture stated is relatively common, and offers
    both precision and speed. We fit our neural network to the training set in *step
    10*. Other parameters can enhance the performance of the network. The hard work
    is now finished. We now proceed to demonstrate how the CAPTCHA breaker works.
    In *step 11*, we choose a singleton instance to demonstrate the efficacy of our
    CAPTCHA breaker. In steps 12-14, we pass this image through our pipeline and produce
    predicted text for this CAPTCHA. Finally, we verify that the prediction is correct
    (*step 15*).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中我们已经完成了CAPTCHA的预处理，现在我们准备利用这些数据来训练一个CAPTCHA破解器。我们首先设置一个变量，指向从CAPTCHA中提取的所有单个字符的路径。然后我们导入将要使用的图像处理库（*第2步*），接着在*第3步*中定义一个调整图像大小的函数。这是一种相对标准的字符识别方法，可以加速训练并减少内存消耗。在*第4步*中，我们定义一个方便的函数，将文件读取为NumPy数组，用于训练；然后在*第5步*中，我们遍历所有字母并记录它们的标签。接下来，我们对所有图像进行归一化处理（*第6步*），这是另一个标准的计算机视觉技巧。现在我们创建训练集和测试集的划分，准备进行分类器拟合（*第7步*），然后使用标签二值化器对标签进行编码（*第8步*）。这是必要的，因为标签是字符，可能并非数值类型。在*第9步*中，我们定义神经网络的架构。所定义的架构是相对常见的，既具有精度又具备速度。在*第10步*中，我们将神经网络拟合到训练集上。其他参数可以增强网络的性能。现在，繁重的工作已经完成。接下来，我们展示CAPTCHA破解器如何工作。在*第11步*中，我们选择一个单例实例来展示CAPTCHA破解器的有效性。在*第12到14步*中，我们将图像通过我们的处理管道，生成对该CAPTCHA的预测文本。最后，我们验证预测是否正确（*第15步*）。
- en: Neural network-assisted fuzzing
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络辅助模糊测试
- en: Fuzzing is a software vulnerability detection method wherein a large number
    of random inputs are fed into a program in search of ones that will cause a crash,
    unwanted information leak, or other unintended behavior. In automated fuzzing,
    a program generates these inputs. Generally, automated fuzzers suffer from the
    shortcoming that they tend to get stuck trying redundant inputs. For this reason,
    AI-based fuzzers have recently been developed. In this recipe, we'll employ NEUZZ,
    a neural network-based fuzzer by She et al. (see [https://arxiv.org/abs/1807.05620](https://arxiv.org/abs/1807.05620)),
    to find unknown vulnerabilities in software.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: Fuzz 测试是一种软件漏洞检测方法，其中将大量随机输入提供给程序，寻找会导致崩溃、信息泄露或其他意外行为的输入。在自动化模糊测试中，程序会生成这些输入。通常，自动化模糊测试器存在一个缺点，即它们倾向于重复尝试冗余的输入。为了解决这个问题，最近开发了基于
    AI 的模糊测试器。在这个食谱中，我们将使用 She 等人开发的基于神经网络的模糊测试器 NEUZZ（见 [https://arxiv.org/abs/1807.05620](https://arxiv.org/abs/1807.05620)）来发现软件中的未知漏洞。
- en: Getting ready
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The following recipe requires an Ubuntu 16.04 or 18.04 virtual or physical
    machine. On this device, run the following:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 以下食谱要求使用 Ubuntu 16.04 或 18.04 虚拟机或物理机。在此设备上运行以下命令：
- en: '[PRE24]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Extract `neuzz-modified.7z` to a folder of your choosing.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 将 `neuzz-modified.7z` 解压到你选择的文件夹中。
- en: How to do it...
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'In the following steps, we provide a recipe for using NEUZZ to find crash-causing
    inputs to the readelf Unix tool:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的步骤中，我们提供了一个使用 NEUZZ 查找导致崩溃的输入的食谱，针对的是 `readelf` Unix 工具：
- en: 'Build neuzz using the following:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令构建 neuzz：
- en: '[PRE25]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: If you receive warnings, that's okay.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你收到警告，没关系。
- en: '2\. Install the libraries needed for 32-bit binaries:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 安装 32 位二进制文件所需的库：
- en: '[PRE26]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'As root, set the CPU scaling algorithm and core dump notification:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以 root 用户身份设置 CPU 缩放算法和核心转储通知：
- en: '[PRE27]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Copy `neuzz`, `nn.py`, and `afl-showmap` to `programs/readelf`:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `neuzz`、`nn.py` 和 `afl-showmap` 复制到 `programs/readelf`：
- en: '[PRE28]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Provide all files with executable permission:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为所有文件提供可执行权限：
- en: '[PRE29]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Open a Terminal to start the neural network module:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开终端以启动神经网络模块：
- en: '[PRE30]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Open another Terminal and start NEUZZ:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开另一个终端并启动 NEUZZ：
- en: '[PRE31]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Here is a snippet from running the commands:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是运行这些命令的一部分：
- en: '![](assets/9675c7a1-2b44-43e5-8fd8-9816e4176517.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/9675c7a1-2b44-43e5-8fd8-9816e4176517.png)'
- en: 'Test the crashes that NEUZZ has collected by running the following:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令测试 NEUZZ 收集的崩溃：
- en: '[PRE32]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '![](assets/d367d900-4a9f-47ff-906c-d598bb32bc9c.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/d367d900-4a9f-47ff-906c-d598bb32bc9c.png)'
- en: How it works…
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理…
- en: Most popular fuzzers, while effective in some limited situations, often get
    stuck in a loop. Gradient-based methods, such as the one discussed here, are promising
    but do not clearly apply to the problem, because real-world program behaviors
    are not necessarily smooth functions (for example, they can be discontinuous).
    The idea behind NEUZZ is to approximate the program's behavior as a smooth function
    using neural networks. Then, it is possible to apply gradient methods to improve
    fuzzing efficiency. We start our recipe by compiling NEUZZ (*step 1)*. The `funroll-loops`
    flag causes the compiler to unroll loops whose number of iterations can be determined
    at compile time or upon entry to the loop. As a result, the code is larger, and
    may run faster, although not necessarily. Continuing to setup NEUZZ, we add in
    32-bit support (*step 2*). We set the CPU scaling algorithm and core dump notification
    (*step 3*); the CPU frequency scaling is a setting that enables the OS to save
    power by scaling the CPU frequency up or down. In the next two steps, we simply
    place the files in a convenient location and allow permissions to execute them.
    We are done setting up NEUZZ. We can now use it to find inputs that cause programs
    to crash. In *step 6* and *step 7*, we begin the search for crashes using our
    neural network. After waiting a sufficient amount of time for *step 6* and *step 7*
    to gather enough inputs to cause the readelf tool to crash, we execute one of
    these inputs (*step 8*) to see the result. Indeed, we see that the input resulted
    in readelf crashing.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: DeepExploit
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**DeepExploit** is a penetration testing tool that elevates Metasploit to a
    whole new level by leveraging AI. Its key features are as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '**Deep penetration**: If DeepExploit successfully exploits the target, it will
    automatically execute the exploit to other internal servers as well.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Learning**: DeepExploit is a reinforcement learning system, akin to AlphaGo.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using DeepExploit to pentest your security systems will take you a long way
    toward keeping your systems secure. In this recipe, we will set up and run DeepExploit.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You will now be guided through the steps required to install `DeepExploit`:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Download and set up Kali Linux. You can find VM images online at [https://www.offensive-security.com/kali-linux-vm-vmware-virtualbox-image-download/](https://www.offensive-security.com/kali-linux-vm-vmware-virtualbox-image-download/). The
    following steps all take place in your Kali Linux box.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Install Git by running the following in a Terminal:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Install Python by running the following:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Clone the `git` repository. In a Terminal, run the following:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Open the `DeepExploit` directory:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In a Terminal, run the following:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Install the prerequisite packages for `DeepExploit`.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In a Terminal, run the following:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: How to do it...
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will use `DeepExploit` to compromise a victim virtual machine.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: Download a `Metasploitable2` VM image.
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Details can be found at [https://metasploit.help.rapid7.com/docs/metasploitable-2](https://metasploit.help.rapid7.com/docs/metasploitable-2).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 详细信息请参见[https://metasploit.help.rapid7.com/docs/metasploitable-2](https://metasploit.help.rapid7.com/docs/metasploitable-2)。
- en: Run a `Metasploitable2` instance on a VM.
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在虚拟机上运行一个`Metasploitable2`实例。
- en: Obtain the IP address of your `Metasploitable2`.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取你的`Metasploitable2`的IP地址。
- en: The next step is to set up DeepExploit's configurations.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是设置`DeepExploit`的配置。
- en: In a Terminal, run `ifconfig` to obtain your Kali Linux's IP. Edit `config.ini`
    (for example, using `vim`) by setting `server_host` under `[common]` to your Kali
    Linux IP.
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在终端中运行`ifconfig`以获取Kali Linux的IP地址。编辑`config.ini`（例如，使用`vim`）并将`[common]`下的`server_host`设置为你的Kali
    Linux IP。
- en: Set the values of `proxy_host` and `proxy_port` in `config.ini` to those in
    `proxychains.conf`.
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`config.ini`中的`proxy_host`和`proxy_port`的值设置为`proxychains.conf`中的值。
- en: 'In the Terminal, run `cat /etc/proxychains.conf` and find the value next to
    `socks4`:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在终端中，运行`cat /etc/proxychains.conf`并找到`socks4`旁边的值：
- en: '[PRE38]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Then, set the values of `proxy_host` and `proxy_port` in `config.ini` equal
    to these values:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，将`config.ini`中`proxy_host`和`proxy_port`的值设置为这些值：
- en: '[PRE39]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Launch Metasploit in the Terminal by running `msfconsole`.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在终端中运行`msfconsole`启动Metasploit。
- en: 'Launch an RPC server on Metasploit. Where indicated, type in your Kali Linux''s
    IP:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Metasploit上启动RPC服务器。在指定的位置，输入你的Kali Linux的IP地址：
- en: '[PRE40]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'You should see the following:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到如下内容：
- en: '[PRE41]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'In a Terminal of your Kali Linux machine, run `python3 DeepExploit.py -t "Metasploitable2
    ip" -m train` to train `DeepExploit`. The beginning of the training should look
    as follows:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你的Kali Linux机器的终端中，运行`python3 DeepExploit.py -t "Metasploitable2 ip" -m train`来训练`DeepExploit`。训练开始时应该如下所示：
- en: '![](assets/b2fccab6-e290-47a0-b863-7b447bb02774.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/b2fccab6-e290-47a0-b863-7b447bb02774.png)'
- en: 'Whenever `DeepExploit` finds a vulnerability, you will see a `BINGO!!!` notification,
    as in the following screenshot:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 每当`DeepExploit`发现漏洞时，你会看到一个`BINGO!!!`的通知，如下图所示：
- en: '![](assets/b63f382c-1202-4166-9c8c-fb3fc19f2119.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/b63f382c-1202-4166-9c8c-fb3fc19f2119.png)'
- en: 'Upon conclusion of the training, the learning is saved. You can see the completion
    screen here:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 培训结束时，学习内容会被保存。你可以在此处看到完成屏幕：
- en: '![](assets/e312ea67-43e8-4c15-bb3f-1e50298d61ea.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/e312ea67-43e8-4c15-bb3f-1e50298d61ea.png)'
- en: Test `Metasploitable2` for vulnerabilities using `DeepExploit`. In a Terminal,
    run `python DeepExploit.py -t "Metasploitable2 ip" -m test`.
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`DeepExploit`测试`Metasploitable2`的漏洞。在终端中，运行`python DeepExploit.py -t "Metasploitable2
    ip" -m test`。
- en: 'Check the report of the pen test as shown:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查渗透测试的报告，如下所示：
- en: '[PRE42]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'We''ll get the following as the output:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们会得到以下输出：
- en: '![](assets/840efb2f-5ed7-433e-8226-ef3474486359.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/840efb2f-5ed7-433e-8226-ef3474486359.png)'
- en: How it works…
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它的工作原理是…
- en: This recipe requires a large amount of preparation and configuration. The initial
    steps are to set up a victim virtual machine (*steps 1 and 2*). In *step 3*, we
    determine the IP address of the victim VM. Note that the credentials of `Metasploitable2`
    are `msfadmin/msfadmin`. You can use the credentials to log in and then use `ifconfig`
    to obtain your `Metasploitable2` IP. If you are using a Kali Linux VM and a `Metasploitable2`
    VM on the same host, make sure that the two can communicate. For instance, put
    both VMs on a Host-Only Adapter and ping from your Kali Linux machine to the Metasploitable2
    machine. Proceeding, we now configure `DeepExploit` so we can target the victim
    VM (*steps 4*-*8*). In *steps 9* and *10*, we open up Metasploit, which is used
    as a submodule by `DeepExploit`. Metasploit is a major penetration testing framework.
    Having finished all the preparation, we can now start to train our model. In *step
    11*, we train `DeepExploit` on the `Metasploitable2` VM. The model utilizes the
    **Asynchronous Actor-Critic Agents** (`A3C`) algorithm, released by Google's DeepMind
    group a few years back, famous for outperforming the `deep Q-network` (`DQN`)
    approach. Next, we test our model (*step 12*) and print out the results of its
    analysis in a report (*step 13*). As you can see from the long report, a large
    number of vulnerabilities were found by `DeepExploit`. Speaking from a high level,
    the application of reinforcement learning to penetration testing suggests that
    extremely efficient automated penetration testing is on the horizon.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: Web server vulnerability scanner using machine learning (GyoiThon)
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**GyoiThon** is an intelligence-gathering tool for web servers. It executes
    remote access to a target web server and identifies products operated on the server,
    such as the **Content Management System** (**CMS**), web server software, framework,
    and programming language. In addition, it can execute exploit modules for the
    identified products using Metasploit.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the main features of GyoiThon are as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '**Remote access/Fully automatic**: GyoiThon can automatically gather information
    on a target web server using only remote access. You only execute GyoiThon once
    for your operation.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Non-destructive test**:GyoiThon can gather information on the target web
    server using only normal access. A feature permits GyoiThon to access abnormally,
    such as by sending exploit modules.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Gathering varied information**: GyoiThon has a number of intelligence gathering
    engines such as a web crawler, the Google Custom Search API, Censys, an explorer
    of default contents, and the examination of cloud services. By analyzing gathered
    information using string pattern matching and machine learning, GyoiThon can identify
    a product/version/CVE number operated on the target web server, HTML comments/debug
    messages, login pages, and other information.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Examination of real vulnerabilities**: GyoiThon can execute exploit modules
    on identified products using Metasploit. As a result, it can determine the real
    vulnerabilities of the target web server.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You will now be guided through the steps for installing and running GyoiThon:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Download and set up Kali Linux. You can find VM images online at [https://www.offensive-security.com/kali-linux-vm-vmware-virtualbox-image-download/](https://www.offensive-security.com/kali-linux-vm-vmware-virtualbox-image-download/). The
    following steps all take place in your Kali Linux box.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Install `git` in the Terminal by running the following:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Install `python` in the Terminal by running the following command:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Clone the Git repository into your Linux box in the Terminal by running the
    following command:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Open the `GyoiThon` directory in the Terminal by running the following command:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Install the prerequisites for DeepExploit in the Terminal by running the following:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: (Optional.) Substitute the `Gyoi_CveExplorerNVD` file in modules with the one
    available in the repository for this book. In some cases, the original code has
    malfunctioned and the modified code available in the repository for this book
    may address this problem.
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, you will use DeepExploit to compromise a victim virtual machine:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: Download a `Metasploitable2` VM image.
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run a `Metasploitable2` instance on a VM.
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Obtain the IP address of your `Metasploitable2`.
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In your Kali Linux machine, you should be able to see your `Metasploitable2''s`
    website instance by typing `Metasploitable2''s ip address:80` into a web browser:'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/71464351-549d-4a10-9759-c96489711565.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
- en: In a Terminal, run `ifconfig` to obtain your Kali Linux's IP. Edit `config.ini`
    (for example, using `vim`) by setting `proxy` to `empty`, `server host` to your
    `Kali Linux IP`, `LHOST` to your `Metasploitable2 IP`, and `LPORT` to `80`.
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the host file and add the `Metasploitable2` web server address by typing
    in `http:Metasploitable2 ip:80/`.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In a Terminal of your Kali Linux machine, run `python3 Gyoithon.py` to begin
    the attack.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Upon the conclusion of the attack, check the report of the pen test in the
    folder report:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/efb44d52-8217-4d81-beae-0e222e914e69.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
- en: How it works…
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Steps 1-3* are no different than in the recipe for DeepExploit, where we prepared
    a victim VM. The credentials of `Metasploitable2` are `msfadmin/msfadmin`. You
    can use the credentials to log in and then use `ifconfig` to obtain your `Metasploitable2`
    IP. If you are using a Kali Linux VM and `Metasploitable2` VM on the same host,
    make sure that the two can communicate. For instance, put both VMs on a Host-only
    Adapter and ping from your Kali Linux machine to the Metasploitable2 machine.
    Next, we verify that the environment has been properly set up by checking that
    we are able to access the victim VM''s web page in *step 4*. In *step 5* and *step
    6*, we configure GyoiThon in preparation for our pen test. Having finished setting
    up our environments, we are now ready to perform the pen test. In *step 7*, we
    utilize GyoiThon to search for vulnerabilities. We then output a full report of
    the vulnerabilities detected (*step 8*). Looking at the report, we can see that
    GyoiThon was able to find a large number of vulnerabilities. Having now determined
    the vulnerabilities of the victim box, we can go ahead and exploit these, using,
    for example, Metasploit, to hack the victim box.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: Deanonymizing Tor using machine learning
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tor is a free, open source software for enabling anonymous communication. In
    addition, websites accessible only when using the Tor browser exist, and are part
    of the **dark web** ecosystem – the name given to the part of the internet that
    is hidden from the average user. In this recipe, we will deanonymize Tor traffic
    by collecting enough features and information from individual sessions to be able
    to identify the activity of anonymized users. This recipe utilizes the **conmarap/website-fingerprinting**
    repository.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You will now be guided through the steps needed to set up Tor and the Lynx
    web browser:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: Set up an Ubuntu VM.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Install `git` in the Terminal by running the following command:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Clone the code repository in the Terminal by running the following command:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Install `tor` and `lynx` in the Terminal by running the following command:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: How to do it…
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe consists of three parts. The first part consists of the data collection
    of Tor traffic. The second consists of training a classifier on this data. And
    the final part consists of using the classifier to predict the type of traffic
    being observed.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: Collecting data
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following steps need to be followed for data collection:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: 'List the classes of traffic you wish to classify in `config.json`:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/5c3ccb28-410d-41c7-bb0b-f8f7c8577d14.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
- en: 'Collect an additional data point for one of the classes, say `duckduckgo.com`,
    in a Terminal, from the website-fingerprinting directory by running the following
    command:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Open another Terminal, and run the following command:'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Your two Terminals should look as follows, at this point:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ecfa12db-50fc-48f7-b06e-fa36a7cbdbdb.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
- en: Once you have finished the browsing session, end the capture by pressing *Q*
    twice.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When a sufficient amount of training data has been gathered, we are ready to
    train a classifier.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: Training
  id: totrans-247
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To train a classifier on the data, run the following script using Python:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: The result is a file classifier: `nb.dmp`.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: Predicting
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s use the classifier to predict the type of traffic being observed:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: To predict a new instance of traffic, collect the `pcap` file.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Using Python, run the `predict.py` script with the `pcap` file as an argument:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/3ed74252-6025-48bc-b427-eea3b88220cd.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
- en: 'The clustering by the author looks like this:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/63bfbc53-5589-47b6-a81a-a8a28fe1d895.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
- en: The preceding diagram shows that the features do indeed differentiate between
    the type of traffic, despite it being anonymous.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  id: totrans-259
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We start constructing our classifier by creating a catalog of all of the websites
    we wish to profile (*step 1*). The more there are, the more likely the target
    is to visit one of these. On the other hand, the fewer there are, the smaller
    the training dataset will have to be. In *steps 2*-*4*, we perform the steps required
    to collect a data point for our classifier. Specifically, we do so by visiting
    one of the websites defined in *step 1* and then capture the packets for that
    visit. By repeating these steps for different browsing sessions, we are able to
    construct a robust dataset. In *step 5*, we train a classifier on our data, which
    we have collected up until now. We are now ready to test out our classifier. In
    *step 6*, we visit a website and collect its `pcap`, just as we did when collecting
    our training data. We then employ the classifier to classify this visit (*step
    7*). We see that it did, indeed, correctly determine which web page the user visited,
    despite the user using Tor.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: In summary, in this recipe, scikit-learn was used to write a k-nearest neighbors
    classifier that would classify Tor `pcap` files. In practice, traffic is never
    as *clean*, so accuracy is likely to decrease on a real dataset of the same size.
    However, an entity with large amounts of resources can create a very accurate
    classifier. This means that it is entirely possible to use a method like this
    to accurately compromise anonymized users.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: IoT device type identification using machine learning
  id: totrans-262
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the advent of IoT, the attack surfaces on any given target have increased
    exponentially. With new technology comes new risks, and, in the case of IoT, one
    such risk to an organization is the addition of a malicious IoT device connected
    to the organization's network. It is essential to be able to tell when such a
    device has been added to a network and to understand its nature. In this recipe,
    we'll build a machine learning model to classify network IoT devices by type.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The preparation for this recipe consists of installing the `sklearn`, `pandas`,
    and `xgboost` packages in `pip`. The instructions are as follows:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: A dataset has been provided for you in the `iot_train.csv` and `iot_test.csv`
    files.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  id: totrans-268
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, we''ll train and test a classifier on IoT network information:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `pandas` and `os` and read in the training and testing data:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The data contains 298 features, as shown in the following screenshot:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/9c50983f-be84-4f46-9db7-6d554bbccf6e.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
- en: 'Create a training and testing dataset, where the target is the device category:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: The device categories are security camera, TV, smoke detector, thermostat, water
    sensor, watch, baby monitor, motion sensor, lights, and socket.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: 'Encode the class categories into numerical form:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Instantiate an `xgboost` classifier:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Train and test the `xgboost` classifier:'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'The output is as follows:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: How it works...
  id: totrans-285
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An important motivation for this recipe is that we can't rely on the IP address
    as an identifier of the device, since this value can be spoofed. Consequently,
    we would like to analyze the traffic's high-level data, that is, the metadata
    and traffic statistics, rather than content, to determine whether the device belongs
    to the network. We begin by reading in the training and testing datasets. We go
    on to featurize these and perform a quick data exploration step by observing the
    classification labels (*step 2*). To feed these into our classifier, we convert
    these categorical labels into numerical ones to be used to train our machine learning
    classifier (*step 3*). Having featurized the data in *step 4* and *step 5*, we
    instantiate, train and test an `xgboost` classifier, obtaining a score of `0.66`
    on the testing set. There are 10 categories of IoT devices in the associated data.
    The baseline of randomly guessing between the 10 would yield an accuracy of 0.1\.
    The `XGBoost` classifier trained here attains an accuracy of 0.66, suggesting
    that it is indeed a promising approach to classify IoT devices successfully based
    on high-level traffic data.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: Keystroke dynamics
  id: totrans-287
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Keystroke dynamics, aka typing biometrics, is the study of recognizing a person
    by the way they type. One important use case is recognizing which user is logging
    in using a given credential, for example, who is logging in as root? Another use
    case is recognizing when a different user has typed a sequence of keystrokes.
    In this recipe, we'll show how to use a machine learning-based keystroke dynamics
    algorithm.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-289
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This recipe will require a Linux virtual or real machine. In preparation, do
    the following:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: Install `git` on your device.
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In a Terminal, run the following command:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Clone the `git` repository containing the code for the keystroke dynamics algorithm:'
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: How to do it...
  id: totrans-296
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, we''ll train the model on two users'' typing patterns
    and then use the model to recognize one of the user''s typing patterns. The recipe
    should be run on a Linux virtual or real machine:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: 'Run `example.py`:'
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Train on the keystrokes of user 1 by selecting option 1 and then typing in
    the text:'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/209f8806-a477-4839-b1e1-221d511f8a53.png)'
  id: totrans-301
  prefs: []
  type: TYPE_IMG
- en: 'Run `example.py` and train on the keystrokes of user 2 by selecting option
    1 and then having user 2 type in the text:'
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/b69bbb11-e7fb-4448-b4c9-fb5081e45a08.png)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
- en: Run `example.py` and, this time, select option 2.
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Have one of the users type the text again. The algorithm will match the keyboard
    dynamics to the most similar typist from the training data:'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/04dfcca1-d472-4c2a-a11e-b4c06a74d71f.png)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
- en: How it works...
  id: totrans-307
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Analyzing keystroke dynamics utilizes the rhythm and pace at which a user types
    on a keyboard to verify that individual's identity. We begin by setting up some
    baselines. In *step 1* and *step 2*, we set up the keystroke dynamics system to
    learn the typing pattern of the first user. We then do the same for the second
    user (*step 3*). This establishes our *normal* users, as well as their typing
    patterns. In *step 4* and *step 5*, we utilize our trained model (trained in *steps
    1*-*3*), to determine who the current user is. As you can see, the classifier
    outputs a similarity score and a prediction of who the current user is from its
    catalog of saved users. This allows us to detect unauthorized users, as well as
    to simply keep track of system usage.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: Malicious URL detector
  id: totrans-309
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Malicious URLs cause billions of dollars of damage every year by hosting spam,
    malware, and exploits, as well as stealing information. Traditionally, defenses
    against these have relied on blacklists and whitelists – lists of URLs that are
    considered malicious, and lists of URLs that are considered safe. However, blacklists
    suffer from a lack of generality and an inability to defend against previously
    unseen malicious URLs. To remedy the situation, machine learning techniques have
    been developed. In this recipe, we'll run a malicious URL detector using character-level
    recurrent neural networks with Keras. The code is based on [https://github.com/chen0040/keras-malicious-url-detector](https://github.com/chen0040/keras-malicious-url-detector).
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-311
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The preparation for this recipe consists of installing a number of packages
    in `pip`. The instructions are as follows:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'In addition, clone the following `git` repository:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: How to do it…
  id: totrans-316
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Train the bidirectional LSTM model:'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'The training screen should look something like this:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/84819f8a-6cdb-44bc-92b1-ddf7aaae7375.png)'
  id: totrans-320
  prefs: []
  type: TYPE_IMG
- en: 'Test the classifier:'
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The testing screen should look like the following:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/9c1798ae-4ed4-4b4c-9241-67f07a4fd2cb.png)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
- en: 'Finally, you can see the results under the `reports` folder:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/44212e52-6f14-44fd-864b-1937f0dbf77b.png)'
  id: totrans-326
  prefs: []
  type: TYPE_IMG
- en: How it works…
  id: totrans-327
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is a relatively simple recipe but serves as a good starting point for
    a more high-powered malicious URL detector. The dataset consists of URLs with
    the labels 0 and 1, depending on whether they are malicious or benign:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: In *step 1*, we train a bidirectional LSTM model. By digging deeper into the
    code, you can adjust the network to your needs. Having trained our model, it is
    important to assess its performance and perform some sanity checks. We do so in
    *step 2*, the testing step, consisting of displaying the results of the classifier
    on a random selection of 20 URLs. In general, a bidirectional LSTM is a recurrent
    neural network architecture that shows great promise, due to its ability to remember
    information and analyze data from both beginning to end, and end to beginning.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: Deep-pwning
  id: totrans-331
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deep-pwning is a framework for evaluating the robustness of machine learning
    tools against adversarial attacks. It has become widely known in the data science
    community that naive machine learning models, such as deep neural networks trained
    with the sole aim of classifying images, are very easily fooled.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows Explaining and Harnessing Adversarial Examples,
    I. J. Goodfellow et al:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/9ac0d85b-0396-4dcd-af64-85b1d4e362f1.png)'
  id: totrans-334
  prefs: []
  type: TYPE_IMG
- en: Cybersecurity being an adversarial field of battle, a machine learning model
    used to secure from attackers ought to be robust against adversaries. As a consequence,
    it is important to not only report the usual performance metrics, such as accuracy,
    precision, and recall, but also to have some measure of the adversarial robustness
    of the model. The deep-pwning framework is a simple toolkit for doing so.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-336
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In preparation for this recipe, follow these steps:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: Install `git` on your device.
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Download or clone the repository using Git by using the following:'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Install the requirements for the repo.
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In a Terminal, go to the root directory of your repository and run the following
    command:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: How to do it…
  id: totrans-344
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, you will utilize deep-pwning to attack LeNet5 on the
    MNIST digits dataset:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: 'From the directory down, run the MNIST driver using the following command:'
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'The result should appear like this:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/850ff85a-8a0e-4458-80f8-9b13406ba064.png)'
  id: totrans-349
  prefs: []
  type: TYPE_IMG
- en: How it works…
  id: totrans-350
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In *step 1*, we create a large dataset of adversarial samples; namely, 150,000
    adversarial samples are created, almost all of which are able to fool LeNet5 on
    digits. To examine these adversarial samples, unpickle the pickle in the output
    directory, like so:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bb8fd2b2-dd3f-4dbf-906c-6c8e2af2fdf7.png)'
  id: totrans-352
  prefs: []
  type: TYPE_IMG
- en: 'Under `utils`, a file named `mnist_read_pickle.py` takes as an argument the
    `pickle` file. Running it displays one of the adversarial samples. The following
    image tricks LeNet5 into thinking that it is seeing the number 1:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/d48b2dcf-0f92-4bb1-a4a8-fdf33014de85.png)'
  id: totrans-354
  prefs: []
  type: TYPE_IMG
- en: The deep-pwning framework is designed to be modular, so a user plugs in and
    modifies pieces to suit their needs. For instance, replacing the MNIST dataset
    and the LeNet5 architecture.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning-based system for the automatic detection of software vulnerabilities
  id: totrans-356
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Experts in information security can usually identify potentially exploitable
    pieces of code. Yet, the work is intensive and costly, and may not be sufficient
    to make a program secure. One of the great advantages of deep learning over traditional
    machine learning is that features can be automatically discovered. This allows
    us to alleviate the need for a human expert on vulnerabilities, as well as to
    produce more effective systems. In this recipe, we'll utilize a modified version
    of *VulDeePecker : **A Deep Learning-Based System for Vulnerability Detection* ([https://arxiv.org/pdf/1801.01681.pdf](https://arxiv.org/pdf/1801.01681.pdf)),
    to automatically detect buffer error vulnerabilities and resource management errors
    in C/C++ software.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-358
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The preparation for this recipe consists of installing the `pandas`, `gensim`,
    `keras`, `tensorflow`, and `sklearn` packages in `pip`. The instructions are as
    follows:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'In addition, for this recipe, clone the repository for VulDeePecker:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: 'Install `git` and then, in a Terminal, run the following command:'
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: Two datasets are available in the `datasets` folder, `cwe119_cgd.7z` and `cwe399_cgd.7z`.
    If you wish to use them for this recipe, extract them.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  id: totrans-365
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Collect a training dataset of gadgets and place it under `datasets`. Two datasets
    are available in the `datasets` folder, and they are of this form:'
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/5bbdf15e-6406-47bc-8453-6fb22a8ac5f2.png)'
  id: totrans-367
  prefs: []
  type: TYPE_IMG
- en: Train and test the deep learning model on your dataset.
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This is accomplished by running the following command:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'The output is displayed in the following screenshot:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/714ed965-843e-4b21-9bd8-1d3c857a5f23.png)'
  id: totrans-372
  prefs: []
  type: TYPE_IMG
- en: 'Collect the dataset you would like to predict on and place it under `datasets`:'
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/86517346-69b4-49ec-97f7-9d758835d94b.png)'
  id: totrans-374
  prefs: []
  type: TYPE_IMG
- en: 'Use your trained model to predict whether these are vulnerable pieces of code
    by running the following command:'
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '![](assets/0422d9eb-52b2-4079-a859-beecd558e5de.png)'
  id: totrans-377
  prefs: []
  type: TYPE_IMG
- en: How it works…
  id: totrans-378
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For machine learning to work for vulnerability detection, you need to find
    representations of the software programs that are amenable to learning. For this
    purpose, we use code gadgets, which are transformed into vectors. A code gadget
    is a selection of lines of code that are semantically related to each other. In
    *step 1*, we collect such code gadgets for training. You can see an image of three
    code gadgets, along with labels. Here, a label of 1 indicates a vulnerability,
    while a label of 0 indicates no vulnerability. To extract gadgets from the desired
    program, it is advised to use the commercial product Checkmarx to extract program
    slices, and then assemble them into code gadgets. Another dataset is available.
    That dataset, `cwe-119`, corresponds to buffer error vulnerabilities. Next, we
    train a deep learning model on our vulnerability dataset (*step 2*). The deep
    learning model used is a **Bidirectional Long Short-Term Memory** (**BLSTM**),
    whose architecture is given as follows:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: Note that the training phase automatically saves the model as `[base-name-of-training-dataset]_model.h5`.
    We are now ready to look for new vulnerabilities. So, we place a testing set in
    `datasets` (*step 3*) and then put our neural network to use by predicting vulnerabilities
    in this new set (*step 4*).
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
