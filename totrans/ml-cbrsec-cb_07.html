<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Securing and Attacking Data with Machine Learning</h1>
                </header>
            
            <article>
                
<p><span>In this chapter, we will learn how to employ <strong>machine learning</strong> (<strong>ML</strong>) to secure and attack data. We will cover how to assess the strength of a password using ML, and conversely, how to crack passwords using deep learning. Similarly, we will cover how to hide messages in plain sight using steganography, as well as how to detect steganography using ML. In addition, we will apply ML with hardware security to attack <strong>physically unclonable functions</strong> (<strong>PUFs</strong>) using AI.<br/></span></p>
<p class="mce-root">In this chapter, we will cover the following recipes:</p>
<ul>
<li class="mce-root">Assessing password security using ML</li>
<li class="mce-root">Deep learning for password cracking</li>
<li class="mce-root">Deep steganography</li>
<li class="mce-root">ML-based steganalysis</li>
<li class="mce-root">ML attacks on PUFs</li>
<li class="mce-root">Encryption using deep learning</li>
<li class="mce-root">HIPAA data breaches <span>–</span> data exploration and visualization</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>In this chapter, we will be using the following technologies:</p>
<ul>
<li>PyTorch</li>
<li>TensorBoardX</li>
<li>XGBoost</li>
<li>scikit-learn</li>
<li>pandas</li>
<li>TensorFlow</li>
<li>Keras</li>
<li>Octave</li>
</ul>
<p><span>The code and datasets for this chapter can be found at <a href="https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/tree/master/Chapter07">https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/tree/master/Chapter07</a>.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Assessing password security using ML</h1>
                </header>
            
            <article>
                
<p><strong>Password cracking</strong> is the systematic endeavor of discovering the password of a secure system. Cracking can involve using common passwords, cleverly generated candidate passwords (for example, replacing the letter O with the number 0 or writing a word backward), or just using a plain bruteforce exhaustive search. To make it more difficult to crack a password, a strong password must be chosen.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<div class="a-b-r">
<div class="a-b-r-Tl a-b-va-Zf">
<div class="a-b-r-Ec a-b-tb-Ce">
<div class="a-b-r-x">
<div class="a-b-r">
<div class="a-b-r-Tl a-b-va-Zf">
<div class="a-b-r-Ec a-b-tb-Ce">
<div class="a-b-r-x">
<p>To prepare for this recipe, we need to install <kbd>pandas</kbd>, <kbd>sklearn</kbd>, and <kbd>xgboost</kbd> in <kbd>pip</kbd>. Use the following code to do so:</p>
<pre><strong>pip install pandas sklearn xgboost</strong></pre>
<p>In addition, extract the archived dataset, that is, <kbd>PasswordDataset.7z</kbd>.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it…</h1>
                </header>
            
            <article>
                
<p>In the following steps, we will read in a dataset of passwords, along with labels for their strength, and build a classifier to assess password strength. Let's get started:</p>
<ol>
<li>Import <kbd>pandas</kbd> and read in the passwords into a dataframe:</li>
</ol>
<pre style="padding-left: 60px">import pandas as pd<br/><br/>df = pd.read_csv(<br/>    "passwordDataset.csv", dtype={"password": "str", "strength": "int"}, index_col=None<br/>)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="2">
<li>Shuffle the data at random:</li>
</ol>
<pre style="padding-left: 60px">df = df.sample(frac=1)</pre>
<ol start="3">
<li>Split the dataframe into two separate dataframes, one for training and one for testing:</li>
</ol>
<pre style="padding-left: 60px">l = len(df.index)<br/>train_df = df.head(int(l * 0.8))<br/>test_df = df.tail(int(l * 0.2))</pre>
<ol start="4">
<li>Create the required labels and featured data:</li>
</ol>
<pre style="padding-left: 60px">y_train = train_df.pop("strength").values<br/>y_test = test_df.pop("strength").values<br/>X_train = train_df.values.flatten()<br/>X_test = test_df.values.flatten()</pre>
<ol start="5">
<li>Define a function that splits a string into its characters:</li>
</ol>
<pre style="padding-left: 60px">def character_tokens(input_string):<br/>    """Break string into characters."""<br/>    return [x for x in input_string]</pre>
<ol start="6">
<li>Create a pipeline to perform <span>TF-IDF</span> on the characters of the passwords, followed by gradient boosting:</li>
</ol>
<pre style="padding-left: 60px">from sklearn.pipeline import Pipeline<br/>from sklearn.feature_extraction.text import TfidfVectorizer<br/>from xgboost import XGBClassifier<br/><br/>password_clf = Pipeline(<br/>    [("vect", TfidfVectorizer(tokenizer=character_tokens)), ("clf", XGBClassifier()),]<br/>)</pre>
<ol start="7">
<li>Train and test the pipeline:</li>
</ol>
<pre style="padding-left: 60px">password_clf.fit(X_train, y_train)<br/>password_clf.score(X_test, y_test)</pre>
<p style="padding-left: 60px">The following is the output:</p>
<pre style="padding-left: 60px" class="western">0.9137365878426307</pre>
<ol start="8">
<li>Set one variable as a commonly used password and one as a computer-generated, high-entropy password:</li>
</ol>
<pre style="padding-left: 60px" class="western">common_password = "qwerty"<br/>strong_computer_generated_password = "c9lCwLBFmdLbG6iWla4H"</pre>
<ol start="9">
<li>Check what the classifier predicts for the strength of the two passwords:</li>
</ol>
<pre style="padding-left: 60px">password_clf.predict([common_password, strong_computer_generated_password])</pre>
<p style="padding-left: 60px">The following is the output:</p>
<pre style="padding-left: 60px">array([0, 2])</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works…</h1>
                </header>
            
            <article>
                
<p>We start by importing <kbd>pandas</kbd> and then reading our data into a dataframe (<em>step 1</em>). There are two fields in this data: password and password strength. Password strength consists of three levels of difficulty. We shuffle the data to create more robust training in <em>step 2</em>. In <em>step 3</em>, we split the dataframe via an 80-20 split, and then distribute the features and labels into arrays (<em>step 4</em>). In <em>step 5</em>, we define a function that splits the password strings into characters in order to tokenize passwords into characters, rather than into words. This will allow the classifier to learn fine-grained information about the password dataset. In <em>step 6</em>, we define a pipeline to perform NLP on the characters of a password, followed by using an XGBoost classifier. Next, we train and test our classifier (<em>step 7</em>). For a somewhat subjective task such as this, the performance of a classifier will not necessarily be reflected in a high or low score.</p>
<p>Having finished the training, we perform a sanity check/demonstration of the efficacy of the classifier. We choose one of the most common passwords and one that was generated using a password management system in <em>step 8</em>. In <em>step 9</em>, we can see that the classifier indeed classified the common password as weak (strength 0) and the strong password as strong (strength 2). Success.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deep learning for password cracking</h1>
                </header>
            
            <article>
                
<p>Modern password cracking tools, such as <strong>John the Ripper</strong>, allow a hacker to test billions of potential passwords in a matter of seconds. Not only do such tools allow a hacker to try out every password in a dictionary of common passwords, but they can also automatically transform these passwords by using concatenation (for example, <kbd>password1234</kbd>), leetspeak (<kbd>p4s5w0rd</kbd>), and other promising techniques. Though these techniques are promising, finding additional promising transformations is a difficult task. The ML system known as PassGAN uses a <strong>generative adversarial network</strong> (<strong>GAN</strong>) to automatically learn such rules by observing large datasets of real passwords (gathered from a corpus of actual password leaks) and to generate high-probability password candidates. In this recipe, you will train PassGAN on a corpus of leaked passwords and use it to generate password guesses.</p>
<p>This project will require a machine with a GPU.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>In preparation for this recipe, perform the following steps:</p>
<ol>
<li>Clone the <kbd>PassGAN</kbd> repository using the following command:</li>
</ol>
<pre style="padding-left: 60px"><strong>git clone https://github.com/emmanueltsukerman/PassGAN.git</strong><a href="https://github.com/emmanueltsukerman/PassGAN.git"/></pre>
<ol start="2">
<li>Place a dataset under the <kbd>data</kbd> folder. For example, you may download the famous <kbd>rockyou</kbd> password dataset using the following command:</li>
</ol>
<pre style="padding-left: 60px"><strong>curl -L -o data/train.txt https://github.com/brannondorsey/PassGAN/releases/download/data/rockyou-train.txt</strong></pre>
<p>You should see something like the following when running the password dataset:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1131 image-border" src="assets/d1dc04f5-2f2a-4e10-99a0-1755cca13225.png" style="width:96.25em;height:9.83em;"/></p>
<p>In addition, this recipe requires CUDA 8 to be preinstalled. The required <kbd>pip</kbd> packages can be installed by running the following command:</p>
<pre><strong>pip install -r requirements.txt</strong></pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it…</h1>
                </header>
            
            <article>
                
<p>In the following steps, we will train PassGAN on a corpus of leaked passwords and then use it to generate new password guesses. Let's get started:</p>
<ol>
<li>Train your neural network on the dataset by running the following command:</li>
</ol>
<pre style="padding-left: 60px"><strong>python train.py --output-dir output --training-data data/train.txt</strong></pre>
<ol start="2">
<li>Generate a list of (100,000) password guesses by running the following command:</li>
</ol>
<pre style="padding-left: 60px"><strong>python sample.py \</strong><br/><strong>--input-dir pretrained \</strong><br/><strong>--checkpoint pretrained/checkpoints/195000.ckpt \</strong><br/><strong>--output gen_passwords.txt \</strong><br/><strong>--batch-size 1024 \</strong><br/><strong>--num-samples 100000</strong></pre>
<p>Your Terminal should look something like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1132 image-border" src="assets/7197b71e-53dd-4103-8677-89b8d6530faf.png" style="width:38.42em;height:29.67em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works…</h1>
                </header>
            
            <article>
                
<p>We hit the ground running in this recipe by training our neural network straight away in <em>step 1</em>. Several additional flags are available to customize training, depending on our needs. Now that we've trained our model, we need to output a list of 100,000 passwords, all of which have been generated by the model (<em>step 2</em>). These serve as intelligent guesses of likely passwords. By examining the output of <em>step 2</em>, we can see that the passwords appear as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1133 image-border" src="assets/accc3663-4d95-4391-b435-b6b3147a87b2.png" style="width:37.75em;height:12.33em;"/></p>
<p>Now, we can use these as candidates for cracking passwords.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more</h1>
                </header>
            
            <article>
                
<p>The original paper describing PassGAN can be found at <a href="https://arxiv.org/abs/1709.00440">https://arxiv.org/abs/1709.00440</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deep steganography</h1>
                </header>
            
            <article>
                
<p>Steganography is the practice of hiding a message (that is, the secret<span>)</span> within another medium, such as a file, text, image, or video (that is, the cover<span>)</span>. When the secret is embedded into the cover, the result is called the <strong>container</strong><span>.</span> In this recipe, we will use deep neural networks to create the hiding and revealing processes. Unlike common steganographic methods, which encode the secret in the LSB of the cover, deep learning distributes the secret across all bits.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>In this recipe, you will need access to a GPU.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it…</h1>
                </header>
            
            <article>
                
<ol>
<li>Clone the repository using the following command:</li>
</ol>
<pre style="padding-left: 60px"><strong>git clone https://github.com/emmanueltsukerman/PyTorch-Deep-Image-Steganography.git</strong></pre>
<ol start="2">
<li>Prepare a pretrained model:</li>
</ol>
<pre style="padding-left: 60px"><strong>cat ./checkPoint/netH.tar.gz* | tar -xzv -C ./checkPoint/</strong></pre>
<ol start="3">
<li>Prepare a secret image and a cover image in the <kbd>example_pics</kbd> folder:</li>
</ol>
<p style="padding-left: 60px">As you can see, we are using the following image as the cover image:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1134 image-border" src="assets/f2a3c562-1e86-4d91-a79f-289b6e59b284.png" style="width:17.67em;height:17.67em;"/></p>
<p style="padding-left: 60px">We are using the following image as the secret image:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1135 image-border" src="assets/35e17f89-b9a2-4a6a-9534-a3febfbbe528.png" style="width:18.92em;height:19.08em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref"/>
<ol start="4">
<li>Execute the pretrained model to produce a container image and a reconstructed secret:</li>
</ol>
<pre style="padding-left: 60px"><strong>CUDA_VISIBLE_DEVICES=0 python main.py –test=./example_pics</strong></pre>
<p style="padding-left: 60px">The first part of the output is displayed in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/a5e2086c-f527-44cd-80cf-fd202b5bc819.png"/></p>
<p style="padding-left: 60px">The second part of the output is displayed in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/1b1e7753-0f80-4cbc-bd1d-cf6c916d4dc6.png"/></p>
<p style="padding-left: 60px">The final part of the output is displayed in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/98320e7f-704f-44e9-b4dc-f38e585e6103.png"/></p>
<ol start="5">
<li>Examine your results under the training folder. You should see the following image:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/d2cfcfb2-9eb9-4b12-ac11-e61602d58d83.png" style="width:9.75em;height:38.92em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref"><span>Row 1: cover. Row 2: container. Row 3: secret. Row 4: reconstructed secret</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works…</h1>
                </header>
            
            <article>
                
<p>In <em>step 1</em>, we simply clone the repository for the deep steganography project. Some background on the theory and implementation of this project can be found in the paper <em>Hiding Images in Plain Sight: Deep Steganography</em> (<a href="https://papers.nips.cc/paper/6802-hiding-images-in-plain-sight-deep-steganography">https://papers.nips.cc/paper/6802-hiding-images-in-plain-sight-deep-steganography</a>).</p>
<p class="mce-root"/>
<p>The basic idea is that there is a <strong>hiding network</strong> (<strong>H-net</strong>) and a <strong>reveal network</strong> (<strong>R-net</strong>), both of which are trained adversarially. Continuing to <em>step 2</em>, we prepare our pretrained model. The model that we used here was trained on 45,000 images from ImageNet, and evaluated on 5,000 images. All of the images were resized to 256 × 256 without normalization and the task took 24 hours of training on a single NVIDIA GTX 1080 Ti. Next, we pick two images of our choosing to serve as a cover and a secret (<em>step 3</em>). Feel free to use your own pair of images. In <em>steps 4</em> and <em>5</em>, we run the model, create a container image (the one containing the hidden secret), and produce an image showing our results. As you can see, the container image and cover image are indistinguishable to the human eye, meaning that no one will be able to tell that you have hidden a secret in the cover image.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">ML-based steganalysis</h1>
                </header>
            
            <article>
                
<p><span>One of the main techniques in</span> <span>steganography</span> is hiding messages in images by altering the <strong>least significant bits</strong> (<strong>LSB</strong>) of the pixels with those of the message bits. The result is an image with a message hidden in it that the human eye cannot distinguish from the original image. This is because, on changing the LSB in the pixels of an image, the pixel values are only altered by a small amount, resulting in a visually similar image.</p>
<p>There are two prominent methods for LSB:</p>
<ul>
<li>The naïve method is called LSB replacement. In this method, the LSB bit remains unchanged if the message bit is the same as the LSB; otherwise, the bit is altered. Hence, the odd pixels are reduced by 1 in intensity, whereas the even pixel values are incremented by 1. However, this causes an imbalance in the image histogram, which can be easily detected by statistical methods for steganalysis.</li>
<li>The second method of LSB steganography, LSB matching, solves this issue by randomly incrementing or decrementing the pixel values by 1 in the case of an LSB bit mismatch. This avoids the issue of histogram imbalance and makes it difficult to perform steganalysis by using simple statistical methods alone.</li>
</ul>
<p>The following images showcase an instance of LSB steganography.</p>
<p>The following image will be represented as the cover image:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/5bd5edf5-8377-4c3b-9da4-d7ee6d1e17df.png" style="width:35.58em;height:20.00em;"/></p>
<p>The following image will be represented as the secret image:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/7367064b-4bb2-43e9-9e47-2a5a0aa99418.jpg" style="width:22.33em;height:22.50em;"/></div>
<p class="mce-root">The following image will be represented as the container image:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/5bd5edf5-8377-4c3b-9da4-d7ee6d1e17df.png" style="width:42.00em;height:23.58em;"/></p>
<p>The following image will be shown as the recovered secret image:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/14495d48-9d6f-4046-84d7-771a68b60620.png" style="width:30.75em;height:17.33em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>It is recommended that you complete this recipe on a Linux machine. Follow these steps to get everything set up:</p>
<ol>
<li>Install <kbd>octave</kbd>, as well as its packages, <kbd>image</kbd> and <kbd>signal</kbd>:</li>
</ol>
<pre style="padding-left: 60px"><strong>sudo apt-get install octave octave-image octave-signal</strong></pre>
<ol start="2">
<li>Clone the repository for <kbd>aletheia</kbd>, as shown in the following code:</li>
</ol>
<pre style="padding-left: 60px"><strong>git clone https://github.com/emmanueltsukerman/aletheia.git</strong></pre>
<ol start="3">
<li>Download a <kbd>BOSS</kbd> dataset, which you can download via the following link:</li>
</ol>
<pre style="padding-left: 60px"><strong>wget http://dde.binghamton.edu/download/ImageDB/BOSSbase_1.01.zip</strong></pre>
<p style="padding-left: 60px">This will retrieve a database of grayscale images.</p>
<ol start="4">
<li>Unzip the dataset and rename the <kbd>BOSSbase</kbd> <span>folder</span>:</li>
</ol>
<pre style="padding-left: 60px"><strong>unzip BOSSbase_1.01.zip</strong></pre>
<p><span>For your convenience, the processed datasets, na</span>mely <kbd>bossbase.7z</kbd> and <kbd>bossbase_lsb.7z</kbd><span>, can be found in this book's repository.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>In this recipe, we will curate an LSB dataset and then train and test an ML model to detect the presence of LSB steganography in an image. Let's get started:</p>
<ol>
<li>Create an LSB database using the following command:</li>
</ol>
<pre style="padding-left: 60px"><strong>python aletheia.py lsbm-sim bossbase 0.40 bossbase_lsb</strong></pre>
<p style="padding-left: 60px">The result is a new folder named <kbd>bossbase_lsb</kbd>, which contains the BOSS images with embeddings. It does this using an LSB matching simulator.</p>
<ol start="2">
<li>Featurize the <kbd>BOSS</kbd> dataset, as shown in the following code:</li>
</ol>
<pre style="padding-left: 60px"><strong>./aletheia.py srm bossbase bossbase.fea</strong></pre>
<ol start="3">
<li>Featurize the LSB dataset, as shown in the following code:</li>
</ol>
<pre style="padding-left: 60px"><strong>./aletheia.py srm bossbase_lsb bossbase_lsb.fea</strong></pre>
<p style="padding-left: 60px">The remaining steps can be run in a Python environment for your convenience.</p>
<ol start="4">
<li>Create some variables that point to the path of the extracted features:</li>
</ol>
<pre style="padding-left: 60px">bossbase_features_path = "bossbase.fea"<br/>bossbase_lsb_features_path = "bossbase_lsb.fea"<br/>features_with_labels = [(bossbase_features_path, 0), (bossbase_lsb_features_path, 1)]</pre>
<ol start="5">
<li>Collect the features and labels and put them in arrays:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">X = []<br/>y = []<br/>for feature_path, label in features_with_labels:<br/>    with open(feature_path, "r") as f:<br/>        for line in f:<br/>            fv = line.split()<br/>            X.append(fv)<br/>            y.append(label)</pre>
<ol start="6">
<li>Perform a train-test split:</li>
</ol>
<pre style="padding-left: 60px">from sklearn.model_selection import train_test_split<br/><br/>X_train, X_test, y_train, y_test = train_test_split(<br/>    X, y, test_size=0.2, random_state=11<br/>)</pre>
<ol start="7">
<li>Instantiate a <kbd>RandomForestClassifier</kbd> and train it:</li>
</ol>
<pre style="padding-left: 60px">from sklearn.ensemble import RandomForestClassifier<br/><br/>clf = RandomForestClassifier()<br/>clf = clf.fit(X_train, y_train)</pre>
<ol start="8">
<li>Score the classifier on the test set:</li>
</ol>
<pre style="padding-left: 60px">print(clf.score(X_test, y_test))</pre>
<p style="padding-left: 60px">The following is the output:</p>
<pre style="padding-left: 60px" class="mce-root"><strong>0.825</strong></pre>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works…</h1>
                </header>
            
            <article>
                
<p>We start this recipe by creating a large dataset of LSB steganography container images using the software known as Aletheia (<em>step 1</em>). Aletheia offers a wide array of functionality. Run the following command with no arguments:</p>
<pre>$ ./aletheia.py</pre>
<p>The preceding command prints out the following information about <kbd>aletheia</kbd>:</p>
<pre class="mce-root">./aletheia.py &lt;command&gt;<br/>COMMANDS:<br/>Attacks to LSB replacement:<br/>- spa: Sample Pairs Analysis.<br/>- rs: RS attack.<br/>ML-based detectors:<br/>- esvm-predict: Predict using eSVM.<br/>- e4s-predict: Predict using EC.<br/>Feature extractors:<br/>- srm: Full Spatial Rich Models.<br/>- hill-maxsrm: Selection-Channel-Aware Spatial Rich Models for HILL.<br/>- srmq1: Spatial Rich Models with fixed quantization q=1c.<br/>- scrmq1: Spatial Color Rich Models with fixed quantization q=1c.<br/>- gfr: JPEG steganalysis with 2D Gabor Filters.<br/>Embedding simulators:<br/>- lsbr-sim: Embedding using LSB replacement simulator.<br/>- lsbm-sim: Embedding using LSB matching simulator.<br/>- hugo-sim: Embedding using HUGO simulator.<br/>- wow-sim: Embedding using WOW simulator.<br/>- s-uniward-sim: Embedding using S-UNIWARD simulator.<br/>- j-uniward-sim: Embedding using J-UNIWARD simulator.<br/>- j-uniward-color-sim: Embedding using J-UNIWARD color simulator.<br/>- hill-sim: Embedding using HILL simulator.<br/>- ebs-sim: Embedding using EBS simulator.<br/>- ebs-color-sim: Embedding using EBS color simulator.<br/>- ued-sim: Embedding using UED simulator.<br/>- ued-color-sim: Embedding using UED color simulator.<br/>- nsf5-sim: Embedding using nsF5 simulator.<br/>- nsf5-color-sim: Embedding using nsF5 color simulator.<br/>Model training:<br/>- esvm: Ensemble of Support Vector Machines.<br/>- e4s: Ensemble Classifiers for Steganalysis.<br/>- xu-net: Convolutional Neural Network for Steganalysis.<br/>Unsupervised attacks:<br/>- ats: Artificial Training Sets.<br/>Naive attacks:<br/>- brute-force: Brute force attack using a list of passwords.<br/>- hpf: High-pass filter.<br/>- imgdiff: Differences between two images.<br/>- imgdiff-pixels: Differences between two images (show pixel values).<br/>- rm-alpha: Opacity of the alpha channel to 255.</pre>
<p>In <em>steps 2</em> and <em>3</em>, we employ the <kbd>srm</kbd> command of Aletheia to extract features of the plain images and container images. The <kbd>srm</kbd> command extracts a full and spatially rich feature set. Other alternative feature sets are available as well. Next, we create variables pointing to the paths of our dataset (<em>step 4</em>) and then collect our features and our labels into arrays (<em>step 5</em>). In <em>steps 6</em>-<em>8</em>, we create a train-test split, train a classifier, and then test it. Looking at the performance of 80% on the balanced dataset, we can see that the features do help us to distinguish between plain and container images. In other words, we can conclude that ML can detect steganography.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">ML attacks on PUFs</h1>
                </header>
            
            <article>
                
<p>Classical cryptography offers several measures for securing electronic devices. These mainly rely on a secret key and expensive resources due to the device permanently storing a piece of digital information that's unknown to our adversaries. In practice, it is difficult to keep this information confidential. This problem motivated the invention of PUF <span>– </span>physical devices that produce an output that's quick to evaluate yet hard to predict.</p>
<p>To authenticate using a PUF, we need to construct a database of <strong>Challenge-Response Pairs (CRPs)</strong>. A challenge is a binary string (for example, 1100101...01) of length <em>n</em>, and a response is some other binary string of length <em>m</em>. To find out whether an unknown device is the aforementioned PUF, we need to issue it a number of challenges, verifying that it produces the correct responses until we reach the desired probability that it is indeed the same PUF. Note that PUFs themselves are not 100% reliable, and the same challenge may yield different responses due to varying environmental conditions and noise:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/66824f3c-08c0-42ca-9e80-269d0a8574d3.png" style="width:17.92em;height:13.25em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref"> <span><span>Figure 8: PUF-based commercial RFID tag</span></span></div>
<p>In this recipe, we will be attacking a specific PUF using ML. Note that the field is ever-evolving, and other, more secure, PUFs have been proposed, as well as methods to increase the reliability and security of PUFs using ML.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<div class="a-b-r">
<div class="a-b-r-Tl a-b-va-Zf">
<div class="a-b-r-Ec a-b-tb-Ce">
<div class="a-b-r-x">
<div class="a-b-r">
<div class="a-b-r-Tl a-b-va-Zf">
<div class="a-b-r-Ec a-b-tb-Ce">
<div class="a-b-r-x">
<p>For this recipe, we need to install <kbd>pandas</kbd>, <kbd>sklearn</kbd>, and <kbd>xgboost</kbd> in <kbd>pip</kbd>. Use the following code to do so:</p>
<pre><strong>pip install pandas sklearn xgboost</strong></pre>
<p>In addition, the <kbd>CRPDataset.csv</kbd> dataset has been provided for this recipe.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>Let's learn how to crack a PUF with ML:</p>
<ol>
<li>Load a CRP dataset, in this case, <kbd>CRPDataset.csv</kbd>:</li>
</ol>
<pre style="padding-left: 60px">import pandas as pd<br/><br/>df = pd.read_csv("CRPdataset.csv")</pre>
<p style="padding-left: 60px">The data is made up of pairs (<em>x</em>,<em>y</em>), where <em>x</em> is a binary string that's 64 in length and <em>y</em> is a binary digit. Here, <em>x</em> is a challenge and <em>y</em> is a response.</p>
<ol start="2">
<li>Convert the <kbd>pandas</kbd> dataframe into a NumPy array of features and labels:</li>
</ol>
<pre style="padding-left: 60px">y = df.pop("Label").values<br/>X = df.values</pre>
<ol start="3">
<li>Perform a train-test split:</li>
</ol>
<pre style="padding-left: 60px">from sklearn.model_selection import train_test_split<br/><br/>X_train, X_test, y_train, y_test = train_test_split(<br/>    X, y, test_size=0.25, random_state=11<br/>)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="4">
<li>Instantiate and train an XGBoost classifier:</li>
</ol>
<pre style="padding-left: 60px">from xgboost import XGBClassifier<br/><br/>clf = XGBClassifier()<br/>clf.fit(X_train, y_train)<br/>print(clf.score(X_train, y_train))</pre>
<p style="padding-left: 60px">The following is the output:</p>
<pre style="padding-left: 60px" class="mce-root"><strong>0.6405208333333333</strong></pre>
<ol start="5">
<li>Test the classifier, as shown in the following code:</li>
</ol>
<pre style="padding-left: 60px">clf.score(X_test, y_test)</pre>
<p style="padding-left: 60px">The following is the output:</p>
<pre style="padding-left: 60px" class="mce-root"><strong>0.6270833333333333</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works…</h1>
                </header>
            
            <article>
                
<p>We start by reading a CRP dataset into a dataframe (<em>step 1</em>). In <em>step 2</em>, we create x and y NumPy arrays to hold the features and labels. Next, we train-test split our data (<em>step 3</em>) and then train and test a classifier for CRPs (<em>steps 4</em> and <em>5</em>). Based on performance, we can see that ML can accurately predict responses to PUF challenges. The implications are that, while using our trained model, we can build a software clone of the PUF and use it to (falsely) authenticate.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more</h1>
                </header>
            
            <article>
                
<p>The original unprocessed dataset for this recipe can be found at <a href="https://archive.ics.uci.edu/ml/datasets/Physical+Unclonable+Functions">https://archive.ics.uci.edu/ml/datasets/Physical+Unclonable+Functions</a>. Additional background information can be found in the paper, <em>A Machine Learning-Based Security Vulnerability Study</em> <em>on XOR PUFs for Resource-Constraint Internet of Things</em>, by <span>Aseeri, A. O., Zhuang, Y., and Alkatheiri, M. S. (July 2018) </span>in 2018 IEEE International Congress on Internet of Things (ICIOT) (pp. 49-56). IEEE.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Encryption using deep learning</h1>
                </header>
            
            <article>
                
<p>Encryption is the process of converting information into code to prevent unauthorized access. In this recipe, we will utilize a convolutional neural network to encrypt and decrypt data.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>For this recipe, you will need to install the <kbd>click</kbd>, <kbd>keras</kbd>, <kbd>tensorflow</kbd>, and <kbd>tqdm</kbd> packages in <kbd>pip</kbd>. Use the following code to do so:</p>
<pre><strong>pip install click keras tensorflow tqdm</strong></pre>
<p>Additionally, clone the repository using the following command:</p>
<pre><strong>git clone https://github.com/emmanueltsukerman/convcrypt.git</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The following steps will guide you through how to use ConvCrypt in order to encrypt an image. Let's get started:</p>
<ol>
<li>
<p>Run the <kbd>encrypt.py</kbd> script against the image or file you would like to encrypt:</p>
</li>
</ol>
<pre style="padding-left: 60px"><strong>python encrypt.py --input_file "input file path" --output_file "encrypted file path" --key_file "key file name"</strong></pre>
<p style="padding-left: 60px">The output of the preceding code is displayed in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/30ee7e0b-5535-40d2-99a1-07f8799ed0a9.png"/></p>
<p style="padding-left: 60px">To see that the file has been encrypted, attempt to open it. We will see that it cannot be opened due to it being encrypted:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/3ea4a5e5-e897-46ae-aa0a-c93e60eb77e4.png" style="width:27.92em;height:10.17em;"/></p>
<ol start="2">
<li>
<p>To decrypt the file, execute the <kbd>decrypt.py</kbd> script against the encrypted file and the key file:</p>
</li>
</ol>
<pre style="padding-left: 60px"><strong>python decrypt.py --input_file "encrypted file path" --output_file "reconstructed file path" --key_file "key file name"</strong></pre>
<p>The result is the original file.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>We begin this recipe by encrypting our image using ConvCrypt (<em>step 1</em>). ConvCrypt is a proof-of-concept experimental encryption algorithm that uses <em>n</em>-dimensional convolutional neural networks. Currently, it only supports three-dimensional convolutions. Then, in <em>step 2</em>, we reverse the encryption and test it to ensure that the result is the original file. Success!</p>
<p>For those of you who are interested, the first thing the ConvCrypt algorithm does is separate the data into blocks. Then, a key is generated for 3D convolutions; this is a randomly generated cube of bits that are the same size as a data block. Lastly, a convolutional neural network is trained to convolve the key into each data block so that each data block gets its own trained network. The resulting encrypted data is the weights of each of the networks (the values of the kernel tensors).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">HIPAA data breaches – data exploration and visualization</h1>
                </header>
            
            <article>
                
<p>Data exploration is the initial step in data analysis, whereby visual exploration is used to understand a dataset and the characteristics of the data. Data visualization helps us understand the data by placing it in an optical context so that our powerful visual processing centers can quickly find patterns and correlations in the data.</p>
<p>In this recipe, you will explore and visualize a public domain dataset regarding breaches of HIPAA confidential information.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>For this recipe, you will need to install <kbd>pandas</kbd> and <kbd>sklearn</kbd> in <kbd>pip</kbd>. Use the following code to do so:</p>
<pre><strong>pip install pandas sklearn</strong></pre>
<p class="mce-root">In addition, the <kbd>HIPAA-breach-report-2009-to-2017.csv</kbd> dataset has been provided so that you can use it in this recipe.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it…</h1>
                </header>
            
            <article>
                
<p>In the following steps, you will visualize the HIPAA breaches dataset in pandas and use <span>TF-IDF</span> to extract important keywords from the descriptions of the breaches. Let's get started:</p>
<ol>
<li>
<p> Load and clean the HIPAA breaches dataset using <kbd>pandas</kbd>:</p>
</li>
</ol>
<pre style="padding-left: 60px">import pandas as pd<br/> <br/> df = pd.read_csv("HIPAA-breach-report-2009-to-2017.csv")<br/> df = df.dropna()</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p style="padding-left: 60px">The output of the preceding code is shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/133b7dea-b456-493c-8e1b-cbe49fc4d724.png"/></p>
<ol start="2">
<li>
<p>Plot a histogram of the number of individuals who have been affected by a breach against the frequency of such breaches by using the following code:</p>
</li>
</ol>
<pre style="padding-left: 60px">%matplotlib inline<br/> def_fig_size = (15, 6)<br/> df["Individuals Affected"].plot(<br/> kind="hist", figsize=def_fig_size, log=True, title="Breach Size Distribution"<br/> )</pre>
<p style="padding-left: 60px">The following output shows the <strong>Breach Size Distribution</strong>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/ccf17feb-3001-4bcd-96df-3078bd46ed04.png"/></p>
<ol start="3">
<li>
<p>Plot the average breach size based on the entity type:</p>
</li>
</ol>
<pre style="padding-left: 60px">df.groupby("Covered Entity Type").mean().plot(<br/> kind="bar", figsize=def_fig_size, title="Average Breach Size by Entity Type"<br/> )</pre>
<p style="padding-left: 60px">The following screenshot shows the output of the <strong>Average Breach Size by Entity Type</strong>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/f2334834-2312-4aa3-b473-605bed345fa0.png"/></p>
<ol start="4">
<li>
<p>Plot a pie chart that shows the number of individuals affected by breaches per state, filtered by the top 20 states:</p>
</li>
</ol>
<pre style="padding-left: 60px">df.groupby("State").sum().nlargest(20, "Individuals Affected").plot.pie(<br/> y="Individuals Affected", figsize=def_fig_size, legend=False<br/> )</pre>
<p style="padding-left: 60px">The following chart shows us those individuals who are affected by breaches per state:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/15bcd509-6467-4dee-bea0-d8c5661a70fa.png" style="width:28.92em;height:28.08em;"/></p>
<ol start="5">
<li>
<p>Plot the average breach size against the type of breach (theft, loss, hacking, and so on):</p>
</li>
</ol>
<pre style="padding-left: 60px">df.groupby("Type of Breach").mean().plot(<br/> kind="bar", figsize=def_fig_size, title="Average Breach Size by Entity Type"<br/> )</pre>
<p style="padding-left: 60px">The following graph shows the <strong>Type of Breach</strong>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/9f179346-054d-4a70-b5c8-49e184c2daac.png"/></p>
<ol start="6">
<li>
<p> Instantiate a TF-IDF vectorizer:</p>
</li>
</ol>
<pre style="padding-left: 60px">from sklearn.feature_extraction.text import TfidfVectorizer<br/> <br/> vectorizer = TfidfVectorizer()</pre>
<ol start="7">
<li>
<p>Fit the vectorizer to the breach descriptions and vectorize them:</p>
</li>
</ol>
<pre style="padding-left: 60px">df["Web Description"] = df["Web Description"].str.replace("\r", " ")<br/> X = df["Web Description"].values<br/> X_transformed = vectorizer.fit_transform(X)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="8">
<li>
<p>Select the 15 most important features in the breach descriptions based on <span>TF-IDF:</span></p>
</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">import numpy as np<br/> <br/> feature_array = np.array(vectorizer.get_feature_names())<br/> tfidf_sorting = np.argsort(X_transformed.toarray()).flatten()[::-1]<br/> n = 15<br/> top_n = feature_array[tfidf_sorting][:n]<br/> print(top_n)</pre>
<p style="padding-left: 60px">The output is as follows:</p>
<pre style="padding-left: 60px">['this' 'review' '842' 'south' 'ransomware' 'memorial' 'specific' 'birthdates' 'consolidated' 'malware' 'license' 'driver' 'found' 'clinic' 'information']</pre>
<ol start="9">
<li>
<p>Print out a couple of breach descriptions containing the <kbd>review</kbd> keyword:</p>
</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">k = 2<br/> i = 0<br/> for x in df["Web Description"].values:<br/> if "review" in x:<br/> i += 1<br/> print(x)<br/> print()<br/> if i == k:<br/> break</pre>
<p style="padding-left: 60px">The following are some of the snippets of the output:</p>
<pre style="padding-left: 60px">A laptop was lost by an employee... all employees received additional security training.<br/>The covered entity's (CE) business associate (BA) incorrectly... BA to safeguard all PHI.</pre>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works…</h1>
                </header>
            
            <article>
                
<p>We begin by reading the HIPAA dataset into a dataframe and dropping any rows that contain NAs (<em>step 1</em>). Next, in <em>step 2</em>, we can see that most breaches are relatively small scale, but a small number of breaches are massive. This is consistent with Pareto's principle. In <em>step 3</em>, we plot breaches by sector to ensure that the largest breaches occur in Business Associates. Then, we examine which states have the most HIPAA breaches in <em>step 4</em>. In <em>step 5</em>, we learn that the cause of the largest breaches is usually unknown! In <em>steps 6</em> and <em>7</em>, we perform a basic NLP on the descriptions of the breaches. This will allow us to extract additional information of interest. In <em>step 8</em>, we can see that TF-IDF was able to find some very informative keywords, such as <em>ransomware</em> and <em>driver</em>. Finally, in <em>step 9</em>, we print out breach description containing the keyword <em>review</em>. The word, review turns out to be an extremely important word as it appears as part of quality control and as an incidence response tool.</p>


            </article>

            
        </section>
    </body></html>