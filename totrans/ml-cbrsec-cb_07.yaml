- en: Securing and Attacking Data with Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will learn how to employ **machine learning** (**ML**) to
    secure and attack data. We will cover how to assess the strength of a password
    using ML, and conversely, how to crack passwords using deep learning. Similarly,
    we will cover how to hide messages in plain sight using steganography, as well
    as how to detect steganography using ML. In addition, we will apply ML with hardware
    security to attack **physically unclonable functions** (**PUFs**) using AI.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Assessing password security using ML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep learning for password cracking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep steganography
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ML-based steganalysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ML attacks on PUFs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Encryption using deep learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HIPAA data breaches – data exploration and visualization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will be using the following technologies:'
  prefs: []
  type: TYPE_NORMAL
- en: PyTorch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorBoardX
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: XGBoost
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: scikit-learn
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: pandas
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorFlow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keras
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Octave
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code and datasets for this chapter can be found at [https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/tree/master/Chapter07](https://github.com/PacktPublishing/Machine-Learning-for-Cybersecurity-Cookbook/tree/master/Chapter07).
  prefs: []
  type: TYPE_NORMAL
- en: Assessing password security using ML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Password cracking** is the systematic endeavor of discovering the password
    of a secure system. Cracking can involve using common passwords, cleverly generated
    candidate passwords (for example, replacing the letter O with the number 0 or
    writing a word backward), or just using a plain bruteforce exhaustive search.
    To make it more difficult to crack a password, a strong password must be chosen.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To prepare for this recipe, we need to install `pandas`, `sklearn`, and `xgboost`
    in `pip`. Use the following code to do so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In addition, extract the archived dataset, that is, `PasswordDataset.7z`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, we will read in a dataset of passwords, along with
    labels for their strength, and build a classifier to assess password strength.
    Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `pandas` and read in the passwords into a dataframe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Shuffle the data at random:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Split the dataframe into two separate dataframes, one for training and one
    for testing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the required labels and featured data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a function that splits a string into its characters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a pipeline to perform TF-IDF on the characters of the passwords, followed
    by gradient boosting:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Train and test the pipeline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Set one variable as a commonly used password and one as a computer-generated,
    high-entropy password:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Check what the classifier predicts for the strength of the two passwords:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We start by importing `pandas` and then reading our data into a dataframe (*step
    1*). There are two fields in this data: password and password strength. Password
    strength consists of three levels of difficulty. We shuffle the data to create
    more robust training in *step 2*. In *step 3*, we split the dataframe via an 80-20
    split, and then distribute the features and labels into arrays (*step 4*). In
    *step 5*, we define a function that splits the password strings into characters
    in order to tokenize passwords into characters, rather than into words. This will
    allow the classifier to learn fine-grained information about the password dataset.
    In *step 6*, we define a pipeline to perform NLP on the characters of a password,
    followed by using an XGBoost classifier. Next, we train and test our classifier
    (*step 7*). For a somewhat subjective task such as this, the performance of a
    classifier will not necessarily be reflected in a high or low score.'
  prefs: []
  type: TYPE_NORMAL
- en: Having finished the training, we perform a sanity check/demonstration of the
    efficacy of the classifier. We choose one of the most common passwords and one
    that was generated using a password management system in *step 8*. In *step 9*,
    we can see that the classifier indeed classified the common password as weak (strength
    0) and the strong password as strong (strength 2). Success.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning for password cracking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Modern password cracking tools, such as **John the Ripper**, allow a hacker
    to test billions of potential passwords in a matter of seconds. Not only do such
    tools allow a hacker to try out every password in a dictionary of common passwords,
    but they can also automatically transform these passwords by using concatenation
    (for example, `password1234`), leetspeak (`p4s5w0rd`), and other promising techniques.
    Though these techniques are promising, finding additional promising transformations
    is a difficult task. The ML system known as PassGAN uses a **generative adversarial
    network** (**GAN**) to automatically learn such rules by observing large datasets
    of real passwords (gathered from a corpus of actual password leaks) and to generate
    high-probability password candidates. In this recipe, you will train PassGAN on
    a corpus of leaked passwords and use it to generate password guesses.
  prefs: []
  type: TYPE_NORMAL
- en: This project will require a machine with a GPU.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In preparation for this recipe, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Clone the `PassGAN` repository using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Place a dataset under the `data` folder. For example, you may download the
    famous `rockyou` password dataset using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see something like the following when running the password dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/d1dc04f5-2f2a-4e10-99a0-1755cca13225.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In addition, this recipe requires CUDA 8 to be preinstalled. The required `pip`
    packages can be installed by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, we will train PassGAN on a corpus of leaked passwords
    and then use it to generate new password guesses. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Train your neural network on the dataset by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Generate a list of (100,000) password guesses by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Your Terminal should look something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/7197b71e-53dd-4103-8677-89b8d6530faf.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We hit the ground running in this recipe by training our neural network straight
    away in *step 1*. Several additional flags are available to customize training,
    depending on our needs. Now that we''ve trained our model, we need to output a
    list of 100,000 passwords, all of which have been generated by the model (*step
    2*). These serve as intelligent guesses of likely passwords. By examining the
    output of *step 2*, we can see that the passwords appear as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/accc3663-4d95-4391-b435-b6b3147a87b2.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, we can use these as candidates for cracking passwords.
  prefs: []
  type: TYPE_NORMAL
- en: There's more
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The original paper describing PassGAN can be found at [https://arxiv.org/abs/1709.00440](https://arxiv.org/abs/1709.00440).
  prefs: []
  type: TYPE_NORMAL
- en: Deep steganography
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Steganography is the practice of hiding a message (that is, the secret) within
    another medium, such as a file, text, image, or video (that is, the cover). When
    the secret is embedded into the cover, the result is called the **container**.
    In this recipe, we will use deep neural networks to create the hiding and revealing
    processes. Unlike common steganographic methods, which encode the secret in the
    LSB of the cover, deep learning distributes the secret across all bits.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will need access to a GPU.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Clone the repository using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Prepare a pretrained model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Prepare a secret image and a cover image in the `example_pics` folder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'As you can see, we are using the following image as the cover image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/f2a3c562-1e86-4d91-a79f-289b6e59b284.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We are using the following image as the secret image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/35e17f89-b9a2-4a6a-9534-a3febfbbe528.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Execute the pretrained model to produce a container image and a reconstructed
    secret:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The first part of the output is displayed in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/a5e2086c-f527-44cd-80cf-fd202b5bc819.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The second part of the output is displayed in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/1b1e7753-0f80-4cbc-bd1d-cf6c916d4dc6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The final part of the output is displayed in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/98320e7f-704f-44e9-b4dc-f38e585e6103.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Examine your results under the training folder. You should see the following
    image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/d2cfcfb2-9eb9-4b12-ac11-e61602d58d83.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Row 1: cover. Row 2: container. Row 3: secret. Row 4: reconstructed secret'
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In *step 1*, we simply clone the repository for the deep steganography project.
    Some background on the theory and implementation of this project can be found
    in the paper *Hiding Images in Plain Sight: Deep Steganography* ([https://papers.nips.cc/paper/6802-hiding-images-in-plain-sight-deep-steganography](https://papers.nips.cc/paper/6802-hiding-images-in-plain-sight-deep-steganography)).'
  prefs: []
  type: TYPE_NORMAL
- en: The basic idea is that there is a **hiding network** (**H-net**) and a **reveal
    network** (**R-net**), both of which are trained adversarially. Continuing to
    *step 2*, we prepare our pretrained model. The model that we used here was trained
    on 45,000 images from ImageNet, and evaluated on 5,000 images. All of the images
    were resized to 256 × 256 without normalization and the task took 24 hours of
    training on a single NVIDIA GTX 1080 Ti. Next, we pick two images of our choosing
    to serve as a cover and a secret (*step 3*). Feel free to use your own pair of
    images. In *steps 4* and *5*, we run the model, create a container image (the
    one containing the hidden secret), and produce an image showing our results. As
    you can see, the container image and cover image are indistinguishable to the
    human eye, meaning that no one will be able to tell that you have hidden a secret
    in the cover image.
  prefs: []
  type: TYPE_NORMAL
- en: ML-based steganalysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the main techniques in steganography is hiding messages in images by
    altering the **least significant bits** (**LSB**) of the pixels with those of
    the message bits. The result is an image with a message hidden in it that the
    human eye cannot distinguish from the original image. This is because, on changing
    the LSB in the pixels of an image, the pixel values are only altered by a small
    amount, resulting in a visually similar image.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two prominent methods for LSB:'
  prefs: []
  type: TYPE_NORMAL
- en: The naïve method is called LSB replacement. In this method, the LSB bit remains
    unchanged if the message bit is the same as the LSB; otherwise, the bit is altered.
    Hence, the odd pixels are reduced by 1 in intensity, whereas the even pixel values
    are incremented by 1\. However, this causes an imbalance in the image histogram,
    which can be easily detected by statistical methods for steganalysis.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second method of LSB steganography, LSB matching, solves this issue by randomly
    incrementing or decrementing the pixel values by 1 in the case of an LSB bit mismatch.
    This avoids the issue of histogram imbalance and makes it difficult to perform
    steganalysis by using simple statistical methods alone.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The following images showcase an instance of LSB steganography.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following image will be represented as the cover image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/5bd5edf5-8377-4c3b-9da4-d7ee6d1e17df.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following image will be represented as the secret image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/7367064b-4bb2-43e9-9e47-2a5a0aa99418.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following image will be represented as the container image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/5bd5edf5-8377-4c3b-9da4-d7ee6d1e17df.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following image will be shown as the recovered secret image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/14495d48-9d6f-4046-84d7-771a68b60620.png)'
  prefs: []
  type: TYPE_IMG
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is recommended that you complete this recipe on a Linux machine. Follow
    these steps to get everything set up:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Install `octave`, as well as its packages, `image` and `signal`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Clone the repository for `aletheia`, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Download a `BOSS` dataset, which you can download via the following link:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: This will retrieve a database of grayscale images.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unzip the dataset and rename the `BOSSbase` folder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: For your convenience, the processed datasets, namely `bossbase.7z` and `bossbase_lsb.7z`,
    can be found in this book's repository.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, we will curate an LSB dataset and then train and test an ML
    model to detect the presence of LSB steganography in an image. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create an LSB database using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The result is a new folder named `bossbase_lsb`, which contains the BOSS images
    with embeddings. It does this using an LSB matching simulator.
  prefs: []
  type: TYPE_NORMAL
- en: 'Featurize the `BOSS` dataset, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Featurize the LSB dataset, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The remaining steps can be run in a Python environment for your convenience.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create some variables that point to the path of the extracted features:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Collect the features and labels and put them in arrays:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Perform a train-test split:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Instantiate a `RandomForestClassifier` and train it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Score the classifier on the test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We start this recipe by creating a large dataset of LSB steganography container
    images using the software known as Aletheia (*step 1*). Aletheia offers a wide
    array of functionality. Run the following command with no arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command prints out the following information about `aletheia`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: In *steps 2* and *3*, we employ the `srm` command of Aletheia to extract features
    of the plain images and container images. The `srm` command extracts a full and
    spatially rich feature set. Other alternative feature sets are available as well.
    Next, we create variables pointing to the paths of our dataset (*step 4*) and
    then collect our features and our labels into arrays (*step 5*). In *steps 6*-*8*,
    we create a train-test split, train a classifier, and then test it. Looking at
    the performance of 80% on the balanced dataset, we can see that the features do
    help us to distinguish between plain and container images. In other words, we
    can conclude that ML can detect steganography.
  prefs: []
  type: TYPE_NORMAL
- en: ML attacks on PUFs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Classical cryptography offers several measures for securing electronic devices.
    These mainly rely on a secret key and expensive resources due to the device permanently
    storing a piece of digital information that's unknown to our adversaries. In practice,
    it is difficult to keep this information confidential. This problem motivated
    the invention of PUF – physical devices that produce an output that's quick to
    evaluate yet hard to predict.
  prefs: []
  type: TYPE_NORMAL
- en: 'To authenticate using a PUF, we need to construct a database of **Challenge-Response
    Pairs (CRPs)**. A challenge is a binary string (for example, 1100101...01) of
    length *n*, and a response is some other binary string of length *m*. To find
    out whether an unknown device is the aforementioned PUF, we need to issue it a
    number of challenges, verifying that it produces the correct responses until we
    reach the desired probability that it is indeed the same PUF. Note that PUFs themselves
    are not 100% reliable, and the same challenge may yield different responses due
    to varying environmental conditions and noise:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/66824f3c-08c0-42ca-9e80-269d0a8574d3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: PUF-based commercial RFID tag'
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will be attacking a specific PUF using ML. Note that the
    field is ever-evolving, and other, more secure, PUFs have been proposed, as well
    as methods to increase the reliability and security of PUFs using ML.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this recipe, we need to install `pandas`, `sklearn`, and `xgboost` in `pip`.
    Use the following code to do so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: In addition, the `CRPDataset.csv` dataset has been provided for this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s learn how to crack a PUF with ML:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Load a CRP dataset, in this case, `CRPDataset.csv`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: The data is made up of pairs (*x*,*y*), where *x* is a binary string that's
    64 in length and *y* is a binary digit. Here, *x* is a challenge and *y* is a
    response.
  prefs: []
  type: TYPE_NORMAL
- en: 'Convert the `pandas` dataframe into a NumPy array of features and labels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Perform a train-test split:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Instantiate and train an XGBoost classifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Test the classifier, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We start by reading a CRP dataset into a dataframe (*step 1*). In *step 2*,
    we create x and y NumPy arrays to hold the features and labels. Next, we train-test
    split our data (*step 3*) and then train and test a classifier for CRPs (*steps
    4* and *5*). Based on performance, we can see that ML can accurately predict responses
    to PUF challenges. The implications are that, while using our trained model, we
    can build a software clone of the PUF and use it to (falsely) authenticate.
  prefs: []
  type: TYPE_NORMAL
- en: There's more
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The original unprocessed dataset for this recipe can be found at [https://archive.ics.uci.edu/ml/datasets/Physical+Unclonable+Functions](https://archive.ics.uci.edu/ml/datasets/Physical+Unclonable+Functions).
    Additional background information can be found in the paper, *A Machine Learning-Based
    Security Vulnerability Study* *on XOR PUFs for Resource-Constraint Internet of
    Things*, by Aseeri, A. O., Zhuang, Y., and Alkatheiri, M. S. (July 2018) in 2018
    IEEE International Congress on Internet of Things (ICIOT) (pp. 49-56). IEEE.
  prefs: []
  type: TYPE_NORMAL
- en: Encryption using deep learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Encryption is the process of converting information into code to prevent unauthorized
    access. In this recipe, we will utilize a convolutional neural network to encrypt
    and decrypt data.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this recipe, you will need to install the `click`, `keras`, `tensorflow`,
    and `tqdm` packages in `pip`. Use the following code to do so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Additionally, clone the repository using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following steps will guide you through how to use ConvCrypt in order to
    encrypt an image. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the `encrypt.py` script against the image or file you would like to encrypt:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding code is displayed in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/30ee7e0b-5535-40d2-99a1-07f8799ed0a9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To see that the file has been encrypted, attempt to open it. We will see that
    it cannot be opened due to it being encrypted:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/3ea4a5e5-e897-46ae-aa0a-c93e60eb77e4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To decrypt the file, execute the `decrypt.py` script against the encrypted
    file and the key file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: The result is the original file.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We begin this recipe by encrypting our image using ConvCrypt (*step 1*). ConvCrypt
    is a proof-of-concept experimental encryption algorithm that uses *n*-dimensional
    convolutional neural networks. Currently, it only supports three-dimensional convolutions.
    Then, in *step 2*, we reverse the encryption and test it to ensure that the result
    is the original file. Success!
  prefs: []
  type: TYPE_NORMAL
- en: For those of you who are interested, the first thing the ConvCrypt algorithm
    does is separate the data into blocks. Then, a key is generated for 3D convolutions;
    this is a randomly generated cube of bits that are the same size as a data block.
    Lastly, a convolutional neural network is trained to convolve the key into each
    data block so that each data block gets its own trained network. The resulting
    encrypted data is the weights of each of the networks (the values of the kernel
    tensors).
  prefs: []
  type: TYPE_NORMAL
- en: HIPAA data breaches – data exploration and visualization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data exploration is the initial step in data analysis, whereby visual exploration
    is used to understand a dataset and the characteristics of the data. Data visualization
    helps us understand the data by placing it in an optical context so that our powerful
    visual processing centers can quickly find patterns and correlations in the data.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, you will explore and visualize a public domain dataset regarding
    breaches of HIPAA confidential information.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this recipe, you will need to install `pandas` and `sklearn` in `pip`.
    Use the following code to do so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: In addition, the `HIPAA-breach-report-2009-to-2017.csv` dataset has been provided
    so that you can use it in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following steps, you will visualize the HIPAA breaches dataset in pandas
    and use TF-IDF to extract important keywords from the descriptions of the breaches.
    Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Load and clean the HIPAA breaches dataset using `pandas`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding code is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/133b7dea-b456-493c-8e1b-cbe49fc4d724.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Plot a histogram of the number of individuals who have been affected by a breach
    against the frequency of such breaches by using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The following output shows the **Breach Size Distribution**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ccf17feb-3001-4bcd-96df-3078bd46ed04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Plot the average breach size based on the entity type:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot shows the output of the **Average Breach Size by Entity
    Type**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/f2334834-2312-4aa3-b473-605bed345fa0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Plot a pie chart that shows the number of individuals affected by breaches
    per state, filtered by the top 20 states:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'The following chart shows us those individuals who are affected by breaches
    per state:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/15bcd509-6467-4dee-bea0-d8c5661a70fa.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Plot the average breach size against the type of breach (theft, loss, hacking,
    and so on):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The following graph shows the **Type of Breach**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/9f179346-054d-4a70-b5c8-49e184c2daac.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Instantiate a TF-IDF vectorizer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Fit the vectorizer to the breach descriptions and vectorize them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Select the 15 most important features in the breach descriptions based on TF-IDF:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Print out a couple of breach descriptions containing the `review` keyword:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'The following are some of the snippets of the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We begin by reading the HIPAA dataset into a dataframe and dropping any rows
    that contain NAs (*step 1*). Next, in *step 2*, we can see that most breaches
    are relatively small scale, but a small number of breaches are massive. This is
    consistent with Pareto's principle. In *step 3*, we plot breaches by sector to
    ensure that the largest breaches occur in Business Associates. Then, we examine
    which states have the most HIPAA breaches in *step 4*. In *step 5*, we learn that
    the cause of the largest breaches is usually unknown! In *steps 6* and *7*, we
    perform a basic NLP on the descriptions of the breaches. This will allow us to
    extract additional information of interest. In *step 8*, we can see that TF-IDF
    was able to find some very informative keywords, such as *ransomware* and *driver*.
    Finally, in *step 9*, we print out breach description containing the keyword *review*.
    The word, review turns out to be an extremely important word as it appears as
    part of quality control and as an incidence response tool.
  prefs: []
  type: TYPE_NORMAL
